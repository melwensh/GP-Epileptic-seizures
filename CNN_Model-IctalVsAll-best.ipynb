{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe4750f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BINARY CLASSIFICATION SETUP\n",
      "============================================================\n",
      "Original classes: ['ICTAL' 'INTERICTAL' 'NORMAL']\n",
      "Binary encoding: 1 (ICTAL) vs 0 (ALL: NORMAL+INTERICTAL)\n",
      "Binary labels distribution: {np.int64(1600): np.int64(0), np.int64(400): np.int64(1)}\n",
      "============================================================\n",
      "Dataset shape: (2000, 868, 1)\n",
      "Class weights (adjusted): {0: np.float64(0.625), 1: np.float64(3.75)}\n",
      "ğŸ² Random state used for this run: 8213\n",
      "\n",
      "============================================================\n",
      " FOLD 1\n",
      "============================================================\n",
      "\n",
      "Train: 1360, Val: 240, Test: 400\n",
      "Test set distribution: {np.int64(320): np.int64(0), np.int64(80): np.int64(1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\n",
      "============================================================\n",
      "MODEL ARCHITECTURE\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">868</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">868</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">868</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">868</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ se_block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SEBlock</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">868</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">630</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">434</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ spatial_dropout1d               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">434</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">434</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,136</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">434</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">434</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ se_block_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SEBlock</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">434</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,412</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">217</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ spatial_dropout1d_1             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">217</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">217</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,992</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">217</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">217</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ se_block_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SEBlock</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">217</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,240</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ spatial_dropout1d_2             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">61,600</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)       â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ se_block_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SEBlock</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)       â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,580</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ spatial_dropout1d_3             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">57,600</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m868\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m868\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚           \u001b[38;5;34m384\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m868\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚           \u001b[38;5;34m192\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m868\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ se_block (\u001b[38;5;33mSEBlock\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m868\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚           \u001b[38;5;34m630\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m434\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ spatial_dropout1d               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m434\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m434\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚        \u001b[38;5;34m23,136\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m434\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚           \u001b[38;5;34m384\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m434\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ se_block_1 (\u001b[38;5;33mSEBlock\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m434\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚         \u001b[38;5;34m2,412\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m217\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ spatial_dropout1d_1             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m217\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m217\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m36,992\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m217\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m217\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ se_block_2 (\u001b[38;5;33mSEBlock\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m217\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚         \u001b[38;5;34m4,240\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ spatial_dropout1d_2             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m160\u001b[0m)       â”‚        \u001b[38;5;34m61,600\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m160\u001b[0m)       â”‚           \u001b[38;5;34m640\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m160\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ se_block_3 (\u001b[38;5;33mSEBlock\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m160\u001b[0m)       â”‚         \u001b[38;5;34m6,580\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m160\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ spatial_dropout1d_3             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m160\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m57,600\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m33\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,575</span> (787.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m201,575\u001b[0m (787.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200,711</span> (784.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m200,711\u001b[0m (784.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">864</span> (3.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m864\u001b[0m (3.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "\n",
      "ğŸš€ Training Fold 1...\n",
      "ğŸ“Š Using data augmentation with real-time generator\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5870 - loss: 1.4517\n",
      "Epoch 1: val_accuracy improved from None to 0.80000, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5971 - loss: 1.4492 - val_accuracy: 0.8000 - val_loss: 1.3550 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6284 - loss: 1.4020\n",
      "Epoch 2: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6603 - loss: 1.3982 - val_accuracy: 0.8000 - val_loss: 1.3129 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7249 - loss: 1.3458\n",
      "Epoch 3: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7110 - loss: 1.3582 - val_accuracy: 0.8000 - val_loss: 1.2709 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7052 - loss: 1.3273\n",
      "Epoch 4: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.7051 - loss: 1.3238 - val_accuracy: 0.8000 - val_loss: 1.2320 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6912 - loss: 1.2993\n",
      "Epoch 5: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.7118 - loss: 1.2898 - val_accuracy: 0.8000 - val_loss: 1.1947 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7266 - loss: 1.2646\n",
      "Epoch 6: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.7390 - loss: 1.2500 - val_accuracy: 0.8000 - val_loss: 1.1570 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7715 - loss: 1.2240\n",
      "Epoch 7: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.7588 - loss: 1.2172 - val_accuracy: 0.8000 - val_loss: 1.1203 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7738 - loss: 1.1741\n",
      "Epoch 8: val_accuracy improved from 0.80000 to 0.80417, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7522 - loss: 1.1867 - val_accuracy: 0.8042 - val_loss: 1.0860 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7734 - loss: 1.1442\n",
      "Epoch 9: val_accuracy did not improve from 0.80417\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7713 - loss: 1.1448 - val_accuracy: 0.8042 - val_loss: 1.0529 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7720 - loss: 1.1127\n",
      "Epoch 10: val_accuracy did not improve from 0.80417\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7699 - loss: 1.1062 - val_accuracy: 0.8042 - val_loss: 1.0217 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7874 - loss: 1.0894\n",
      "Epoch 11: val_accuracy improved from 0.80417 to 0.81250, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7860 - loss: 1.0831 - val_accuracy: 0.8125 - val_loss: 0.9942 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7965 - loss: 1.0477\n",
      "Epoch 12: val_accuracy improved from 0.81250 to 0.82500, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.7838 - loss: 1.0563 - val_accuracy: 0.8250 - val_loss: 0.9653 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7698 - loss: 1.0331\n",
      "Epoch 13: val_accuracy did not improve from 0.82500\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7735 - loss: 1.0198 - val_accuracy: 0.8250 - val_loss: 0.9418 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8000 - loss: 0.9916\n",
      "Epoch 14: val_accuracy improved from 0.82500 to 0.83333, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.7860 - loss: 1.0005 - val_accuracy: 0.8333 - val_loss: 0.9141 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7870 - loss: 0.9696\n",
      "Epoch 15: val_accuracy improved from 0.83333 to 0.83750, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7779 - loss: 0.9730 - val_accuracy: 0.8375 - val_loss: 0.8898 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7695 - loss: 0.9545\n",
      "Epoch 16: val_accuracy improved from 0.83750 to 0.84167, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7787 - loss: 0.9469 - val_accuracy: 0.8417 - val_loss: 0.8765 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7805 - loss: 0.9114\n",
      "Epoch 17: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7816 - loss: 0.9275 - val_accuracy: 0.8250 - val_loss: 0.8540 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7858 - loss: 0.9016\n",
      "Epoch 18: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7765 - loss: 0.9024 - val_accuracy: 0.8292 - val_loss: 0.8281 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8033 - loss: 0.8521\n",
      "Epoch 19: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.7912 - loss: 0.8702 - val_accuracy: 0.8375 - val_loss: 0.8133 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8031 - loss: 0.8309\n",
      "Epoch 20: val_accuracy improved from 0.84167 to 0.85000, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.7949 - loss: 0.8496 - val_accuracy: 0.8500 - val_loss: 0.7924 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7796 - loss: 0.8382\n",
      "Epoch 21: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.7772 - loss: 0.8346 - val_accuracy: 0.8458 - val_loss: 0.7874 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8034 - loss: 0.8041\n",
      "Epoch 22: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7875 - loss: 0.8070 - val_accuracy: 0.8375 - val_loss: 0.7577 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7525 - loss: 0.8131\n",
      "Epoch 23: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7500 - loss: 0.7981 - val_accuracy: 0.8333 - val_loss: 0.7311 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7761 - loss: 0.8056\n",
      "Epoch 24: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.7882 - loss: 0.7874 - val_accuracy: 0.8333 - val_loss: 0.7174 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7976 - loss: 0.7460\n",
      "Epoch 25: val_accuracy improved from 0.85000 to 0.85833, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.7941 - loss: 0.7547 - val_accuracy: 0.8583 - val_loss: 0.7029 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7928 - loss: 0.7447\n",
      "Epoch 26: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.7949 - loss: 0.7433 - val_accuracy: 0.8417 - val_loss: 0.7030 - learning_rate: 1.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7990 - loss: 0.7212\n",
      "Epoch 27: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7897 - loss: 0.7253 - val_accuracy: 0.8458 - val_loss: 0.6705 - learning_rate: 1.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7761 - loss: 0.7372\n",
      "Epoch 28: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8015 - loss: 0.7176 - val_accuracy: 0.8542 - val_loss: 0.6515 - learning_rate: 1.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8148 - loss: 0.6893\n",
      "Epoch 29: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8118 - loss: 0.6884 - val_accuracy: 0.8542 - val_loss: 0.6421 - learning_rate: 1.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7885 - loss: 0.6937\n",
      "Epoch 30: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.8096 - loss: 0.6822 - val_accuracy: 0.8500 - val_loss: 0.6384 - learning_rate: 1.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8357 - loss: 0.6541\n",
      "Epoch 31: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.8301 - loss: 0.6512 - val_accuracy: 0.8500 - val_loss: 0.6343 - learning_rate: 1.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7957 - loss: 0.6655\n",
      "Epoch 32: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7993 - loss: 0.6559 - val_accuracy: 0.8583 - val_loss: 0.5771 - learning_rate: 1.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7887 - loss: 0.6547\n",
      "Epoch 33: val_accuracy improved from 0.85833 to 0.87500, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.8140 - loss: 0.6507 - val_accuracy: 0.8750 - val_loss: 0.5744 - learning_rate: 1.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8313 - loss: 0.6175\n",
      "Epoch 34: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8316 - loss: 0.6207 - val_accuracy: 0.8750 - val_loss: 0.5588 - learning_rate: 1.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8375 - loss: 0.6051\n",
      "Epoch 35: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8272 - loss: 0.6075 - val_accuracy: 0.8708 - val_loss: 0.5392 - learning_rate: 1.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8376 - loss: 0.5925\n",
      "Epoch 36: val_accuracy improved from 0.87500 to 0.88333, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8471 - loss: 0.5878 - val_accuracy: 0.8833 - val_loss: 0.5305 - learning_rate: 1.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8325 - loss: 0.5777\n",
      "Epoch 37: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8147 - loss: 0.5844 - val_accuracy: 0.8833 - val_loss: 0.5177 - learning_rate: 1.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8112 - loss: 0.5710\n",
      "Epoch 38: val_accuracy improved from 0.88333 to 0.90000, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8309 - loss: 0.5719 - val_accuracy: 0.9000 - val_loss: 0.4878 - learning_rate: 1.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8324 - loss: 0.5637\n",
      "Epoch 39: val_accuracy improved from 0.90000 to 0.91250, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8449 - loss: 0.5531 - val_accuracy: 0.9125 - val_loss: 0.4838 - learning_rate: 1.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8376 - loss: 0.5529\n",
      "Epoch 40: val_accuracy improved from 0.91250 to 0.92500, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.8441 - loss: 0.5586 - val_accuracy: 0.9250 - val_loss: 0.4468 - learning_rate: 1.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8594 - loss: 0.5402\n",
      "Epoch 41: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8750 - loss: 0.5387 - val_accuracy: 0.8958 - val_loss: 0.4563 - learning_rate: 1.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8563 - loss: 0.5365\n",
      "Epoch 42: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.8625 - loss: 0.5276 - val_accuracy: 0.9208 - val_loss: 0.4346 - learning_rate: 1.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8494 - loss: 0.5173\n",
      "Epoch 43: val_accuracy improved from 0.92500 to 0.93750, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.8728 - loss: 0.5054 - val_accuracy: 0.9375 - val_loss: 0.4216 - learning_rate: 1.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8859 - loss: 0.5021\n",
      "Epoch 44: val_accuracy improved from 0.93750 to 0.95417, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8897 - loss: 0.5061 - val_accuracy: 0.9542 - val_loss: 0.4025 - learning_rate: 1.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8719 - loss: 0.5049\n",
      "Epoch 45: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.8662 - loss: 0.5021 - val_accuracy: 0.9542 - val_loss: 0.3910 - learning_rate: 1.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9005 - loss: 0.4735\n",
      "Epoch 46: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8824 - loss: 0.4815 - val_accuracy: 0.9125 - val_loss: 0.4119 - learning_rate: 1.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8792 - loss: 0.4752\n",
      "Epoch 47: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.8801 - loss: 0.4742 - val_accuracy: 0.9500 - val_loss: 0.3873 - learning_rate: 1.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8667 - loss: 0.4562\n",
      "Epoch 48: val_accuracy improved from 0.95417 to 0.97083, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.8713 - loss: 0.4684 - val_accuracy: 0.9708 - val_loss: 0.3706 - learning_rate: 1.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9111 - loss: 0.4537\n",
      "Epoch 49: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9169 - loss: 0.4361 - val_accuracy: 0.9708 - val_loss: 0.3684 - learning_rate: 1.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8880 - loss: 0.4715\n",
      "Epoch 50: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.8853 - loss: 0.4615 - val_accuracy: 0.9667 - val_loss: 0.3617 - learning_rate: 1.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8848 - loss: 0.4655\n",
      "Epoch 51: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.8926 - loss: 0.4456 - val_accuracy: 0.9708 - val_loss: 0.3510 - learning_rate: 1.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8989 - loss: 0.4296\n",
      "Epoch 52: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9000 - loss: 0.4287 - val_accuracy: 0.9708 - val_loss: 0.3486 - learning_rate: 1.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8967 - loss: 0.4143\n",
      "Epoch 53: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.8971 - loss: 0.4372 - val_accuracy: 0.9708 - val_loss: 0.3371 - learning_rate: 1.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9243 - loss: 0.3965\n",
      "Epoch 54: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9235 - loss: 0.4007 - val_accuracy: 0.9667 - val_loss: 0.3395 - learning_rate: 1.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9351 - loss: 0.3874\n",
      "Epoch 55: val_accuracy improved from 0.97083 to 0.98333, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9162 - loss: 0.4303 - val_accuracy: 0.9833 - val_loss: 0.3242 - learning_rate: 1.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9007 - loss: 0.4262\n",
      "Epoch 56: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9066 - loss: 0.4119 - val_accuracy: 0.9625 - val_loss: 0.3244 - learning_rate: 1.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9086 - loss: 0.4165\n",
      "Epoch 57: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9110 - loss: 0.4106 - val_accuracy: 0.9833 - val_loss: 0.3121 - learning_rate: 1.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9379 - loss: 0.3757\n",
      "Epoch 58: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9338 - loss: 0.3788 - val_accuracy: 0.9792 - val_loss: 0.3078 - learning_rate: 1.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9306 - loss: 0.3724\n",
      "Epoch 59: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9235 - loss: 0.3933 - val_accuracy: 0.9500 - val_loss: 0.3194 - learning_rate: 1.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9242 - loss: 0.3665\n",
      "Epoch 60: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9272 - loss: 0.3733 - val_accuracy: 0.9667 - val_loss: 0.3047 - learning_rate: 1.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9244 - loss: 0.3593\n",
      "Epoch 61: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9250 - loss: 0.3712 - val_accuracy: 0.9750 - val_loss: 0.2822 - learning_rate: 1.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9115 - loss: 0.3783\n",
      "Epoch 62: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9235 - loss: 0.3653 - val_accuracy: 0.9625 - val_loss: 0.2952 - learning_rate: 1.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8786 - loss: 0.3963\n",
      "Epoch 63: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9103 - loss: 0.3815 - val_accuracy: 0.9833 - val_loss: 0.2869 - learning_rate: 1.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9255 - loss: 0.4004\n",
      "Epoch 64: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9243 - loss: 0.3877 - val_accuracy: 0.9833 - val_loss: 0.2816 - learning_rate: 1.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9240 - loss: 0.3563\n",
      "Epoch 65: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9184 - loss: 0.3651 - val_accuracy: 0.9833 - val_loss: 0.2737 - learning_rate: 1.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9256 - loss: 0.3635\n",
      "Epoch 66: val_accuracy improved from 0.98333 to 0.98750, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9346 - loss: 0.3468 - val_accuracy: 0.9875 - val_loss: 0.2658 - learning_rate: 1.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9315 - loss: 0.3540\n",
      "Epoch 67: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9382 - loss: 0.3536 - val_accuracy: 0.9833 - val_loss: 0.2623 - learning_rate: 1.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9129 - loss: 0.3529\n",
      "Epoch 68: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9176 - loss: 0.3543 - val_accuracy: 0.9833 - val_loss: 0.2580 - learning_rate: 1.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9330 - loss: 0.3238\n",
      "Epoch 69: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9382 - loss: 0.3468 - val_accuracy: 0.9833 - val_loss: 0.2534 - learning_rate: 1.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9158 - loss: 0.3466\n",
      "Epoch 70: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9228 - loss: 0.3373 - val_accuracy: 0.9833 - val_loss: 0.2510 - learning_rate: 1.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9345 - loss: 0.3309\n",
      "Epoch 71: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9176 - loss: 0.3460 - val_accuracy: 0.9833 - val_loss: 0.2498 - learning_rate: 1.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9380 - loss: 0.3221\n",
      "Epoch 72: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9324 - loss: 0.3251 - val_accuracy: 0.9792 - val_loss: 0.2522 - learning_rate: 1.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9432 - loss: 0.3390\n",
      "Epoch 73: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9316 - loss: 0.3438 - val_accuracy: 0.9875 - val_loss: 0.2468 - learning_rate: 1.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9285 - loss: 0.3307\n",
      "Epoch 74: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9287 - loss: 0.3287 - val_accuracy: 0.9792 - val_loss: 0.2429 - learning_rate: 1.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9589 - loss: 0.3030\n",
      "Epoch 75: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9441 - loss: 0.3210 - val_accuracy: 0.9792 - val_loss: 0.2439 - learning_rate: 1.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9381 - loss: 0.3057\n",
      "Epoch 76: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9368 - loss: 0.3178 - val_accuracy: 0.9833 - val_loss: 0.2444 - learning_rate: 1.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9459 - loss: 0.3024\n",
      "Epoch 77: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9449 - loss: 0.3117 - val_accuracy: 0.9833 - val_loss: 0.2380 - learning_rate: 1.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9446 - loss: 0.3056\n",
      "Epoch 78: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9529 - loss: 0.2866 - val_accuracy: 0.9792 - val_loss: 0.2471 - learning_rate: 1.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9461 - loss: 0.2949\n",
      "Epoch 79: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9353 - loss: 0.3132 - val_accuracy: 0.9833 - val_loss: 0.2324 - learning_rate: 1.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9296 - loss: 0.3097\n",
      "Epoch 80: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9338 - loss: 0.3046 - val_accuracy: 0.9875 - val_loss: 0.2252 - learning_rate: 1.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9324 - loss: 0.3208\n",
      "Epoch 81: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9316 - loss: 0.3125 - val_accuracy: 0.9750 - val_loss: 0.2347 - learning_rate: 1.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9437 - loss: 0.3170\n",
      "Epoch 82: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9382 - loss: 0.3140 - val_accuracy: 0.9833 - val_loss: 0.2185 - learning_rate: 1.0000e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9506 - loss: 0.3101\n",
      "Epoch 83: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9471 - loss: 0.3038 - val_accuracy: 0.9875 - val_loss: 0.2174 - learning_rate: 1.0000e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9628 - loss: 0.2627\n",
      "Epoch 84: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9596 - loss: 0.2698 - val_accuracy: 0.9792 - val_loss: 0.2231 - learning_rate: 1.0000e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9506 - loss: 0.2829\n",
      "Epoch 85: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9551 - loss: 0.2817 - val_accuracy: 0.9875 - val_loss: 0.2196 - learning_rate: 1.0000e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9390 - loss: 0.2886\n",
      "Epoch 86: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9456 - loss: 0.2953 - val_accuracy: 0.9792 - val_loss: 0.2127 - learning_rate: 1.0000e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9535 - loss: 0.3067\n",
      "Epoch 87: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9529 - loss: 0.2993 - val_accuracy: 0.9833 - val_loss: 0.2073 - learning_rate: 1.0000e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9421 - loss: 0.2817\n",
      "Epoch 88: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9500 - loss: 0.2698 - val_accuracy: 0.9792 - val_loss: 0.2082 - learning_rate: 1.0000e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9574 - loss: 0.2648\n",
      "Epoch 89: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9449 - loss: 0.2700 - val_accuracy: 0.9833 - val_loss: 0.2045 - learning_rate: 1.0000e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9579 - loss: 0.2821\n",
      "Epoch 90: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9522 - loss: 0.2851 - val_accuracy: 0.9833 - val_loss: 0.2006 - learning_rate: 1.0000e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9339 - loss: 0.2997\n",
      "Epoch 91: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9397 - loss: 0.2918 - val_accuracy: 0.9875 - val_loss: 0.1982 - learning_rate: 1.0000e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9530 - loss: 0.2494\n",
      "Epoch 92: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9574 - loss: 0.2454 - val_accuracy: 0.9833 - val_loss: 0.1991 - learning_rate: 1.0000e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9578 - loss: 0.2650\n",
      "Epoch 93: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9500 - loss: 0.2673 - val_accuracy: 0.9875 - val_loss: 0.1907 - learning_rate: 1.0000e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9496 - loss: 0.2476\n",
      "Epoch 94: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9485 - loss: 0.2510 - val_accuracy: 0.9833 - val_loss: 0.1912 - learning_rate: 1.0000e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9464 - loss: 0.2564\n",
      "Epoch 95: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9500 - loss: 0.2563 - val_accuracy: 0.9792 - val_loss: 0.1942 - learning_rate: 1.0000e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9491 - loss: 0.2450\n",
      "Epoch 96: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9522 - loss: 0.2538 - val_accuracy: 0.9833 - val_loss: 0.1846 - learning_rate: 1.0000e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9603 - loss: 0.2906\n",
      "Epoch 97: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9632 - loss: 0.2610 - val_accuracy: 0.9792 - val_loss: 0.1864 - learning_rate: 1.0000e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9549 - loss: 0.2487\n",
      "Epoch 98: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9463 - loss: 0.2643 - val_accuracy: 0.9875 - val_loss: 0.1898 - learning_rate: 1.0000e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9464 - loss: 0.2517\n",
      "Epoch 99: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9529 - loss: 0.2470 - val_accuracy: 0.9792 - val_loss: 0.1832 - learning_rate: 1.0000e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9491 - loss: 0.2402\n",
      "Epoch 100: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9566 - loss: 0.2332 - val_accuracy: 0.9833 - val_loss: 0.1819 - learning_rate: 1.0000e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9520 - loss: 0.2557\n",
      "Epoch 101: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9529 - loss: 0.2464 - val_accuracy: 0.9875 - val_loss: 0.1855 - learning_rate: 1.0000e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9520 - loss: 0.2565\n",
      "Epoch 102: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9522 - loss: 0.2474 - val_accuracy: 0.9833 - val_loss: 0.1766 - learning_rate: 1.0000e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9593 - loss: 0.2269\n",
      "Epoch 103: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9603 - loss: 0.2313 - val_accuracy: 0.9833 - val_loss: 0.1750 - learning_rate: 1.0000e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9523 - loss: 0.2421\n",
      "Epoch 104: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9566 - loss: 0.2310 - val_accuracy: 0.9792 - val_loss: 0.1797 - learning_rate: 1.0000e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9715 - loss: 0.2066\n",
      "Epoch 105: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9610 - loss: 0.2215 - val_accuracy: 0.9792 - val_loss: 0.1801 - learning_rate: 1.0000e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9733 - loss: 0.2160\n",
      "Epoch 106: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9654 - loss: 0.2272 - val_accuracy: 0.9792 - val_loss: 0.1698 - learning_rate: 1.0000e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9690 - loss: 0.2192\n",
      "Epoch 107: val_accuracy improved from 0.98750 to 0.99167, saving model to results\\model_fold1.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9632 - loss: 0.2213 - val_accuracy: 0.9917 - val_loss: 0.1714 - learning_rate: 1.0000e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9396 - loss: 0.2383\n",
      "Epoch 108: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9456 - loss: 0.2407 - val_accuracy: 0.9792 - val_loss: 0.1727 - learning_rate: 1.0000e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9653 - loss: 0.2245\n",
      "Epoch 109: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9640 - loss: 0.2360 - val_accuracy: 0.9875 - val_loss: 0.1657 - learning_rate: 1.0000e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9577 - loss: 0.2276\n",
      "Epoch 110: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9625 - loss: 0.2199 - val_accuracy: 0.9792 - val_loss: 0.1687 - learning_rate: 1.0000e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9574 - loss: 0.2536\n",
      "Epoch 111: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9559 - loss: 0.2321 - val_accuracy: 0.9792 - val_loss: 0.1662 - learning_rate: 1.0000e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9660 - loss: 0.2355\n",
      "Epoch 112: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9640 - loss: 0.2300 - val_accuracy: 0.9792 - val_loss: 0.1709 - learning_rate: 1.0000e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9645 - loss: 0.2214\n",
      "Epoch 113: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9647 - loss: 0.2136 - val_accuracy: 0.9875 - val_loss: 0.1616 - learning_rate: 1.0000e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9425 - loss: 0.2459\n",
      "Epoch 114: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9551 - loss: 0.2236 - val_accuracy: 0.9792 - val_loss: 0.1704 - learning_rate: 1.0000e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9617 - loss: 0.2122\n",
      "Epoch 115: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9713 - loss: 0.1975 - val_accuracy: 0.9833 - val_loss: 0.1597 - learning_rate: 1.0000e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9496 - loss: 0.2316\n",
      "Epoch 116: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9551 - loss: 0.2280 - val_accuracy: 0.9833 - val_loss: 0.1621 - learning_rate: 1.0000e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9607 - loss: 0.2075\n",
      "Epoch 117: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9610 - loss: 0.2067 - val_accuracy: 0.9792 - val_loss: 0.1596 - learning_rate: 1.0000e-04\n",
      "Epoch 118/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9691 - loss: 0.2021\n",
      "Epoch 118: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9684 - loss: 0.1993 - val_accuracy: 0.9792 - val_loss: 0.1667 - learning_rate: 1.0000e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9605 - loss: 0.2040\n",
      "Epoch 119: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9640 - loss: 0.2085 - val_accuracy: 0.9792 - val_loss: 0.1607 - learning_rate: 1.0000e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9656 - loss: 0.2127\n",
      "Epoch 120: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9618 - loss: 0.2095 - val_accuracy: 0.9917 - val_loss: 0.1587 - learning_rate: 1.0000e-04\n",
      "Epoch 121/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9582 - loss: 0.2038\n",
      "Epoch 121: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9640 - loss: 0.1982 - val_accuracy: 0.9792 - val_loss: 0.1590 - learning_rate: 1.0000e-04\n",
      "Epoch 122/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9473 - loss: 0.2726\n",
      "Epoch 122: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9566 - loss: 0.2277 - val_accuracy: 0.9792 - val_loss: 0.1558 - learning_rate: 1.0000e-04\n",
      "Epoch 123/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9732 - loss: 0.1955\n",
      "Epoch 123: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9676 - loss: 0.1964 - val_accuracy: 0.9833 - val_loss: 0.1555 - learning_rate: 1.0000e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9631 - loss: 0.2022\n",
      "Epoch 124: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9566 - loss: 0.2074 - val_accuracy: 0.9833 - val_loss: 0.1502 - learning_rate: 1.0000e-04\n",
      "Epoch 125/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9684 - loss: 0.2037\n",
      "Epoch 125: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9669 - loss: 0.2050 - val_accuracy: 0.9833 - val_loss: 0.1466 - learning_rate: 1.0000e-04\n",
      "Epoch 126/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9707 - loss: 0.1862\n",
      "Epoch 126: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9662 - loss: 0.1943 - val_accuracy: 0.9875 - val_loss: 0.1480 - learning_rate: 1.0000e-04\n",
      "Epoch 127/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9533 - loss: 0.2105\n",
      "Epoch 127: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9596 - loss: 0.2027 - val_accuracy: 0.9833 - val_loss: 0.1431 - learning_rate: 1.0000e-04\n",
      "Epoch 128/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9673 - loss: 0.1879\n",
      "Epoch 128: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9669 - loss: 0.1878 - val_accuracy: 0.9833 - val_loss: 0.1459 - learning_rate: 1.0000e-04\n",
      "Epoch 129/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9543 - loss: 0.2350\n",
      "Epoch 129: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9618 - loss: 0.2143 - val_accuracy: 0.9833 - val_loss: 0.1433 - learning_rate: 1.0000e-04\n",
      "Epoch 130/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9673 - loss: 0.1989\n",
      "Epoch 130: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9757 - loss: 0.1886 - val_accuracy: 0.9875 - val_loss: 0.1433 - learning_rate: 1.0000e-04\n",
      "Epoch 131/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9736 - loss: 0.1939\n",
      "Epoch 131: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9654 - loss: 0.2008 - val_accuracy: 0.9833 - val_loss: 0.1456 - learning_rate: 1.0000e-04\n",
      "Epoch 132/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9767 - loss: 0.1780\n",
      "Epoch 132: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9684 - loss: 0.1925 - val_accuracy: 0.9917 - val_loss: 0.1378 - learning_rate: 1.0000e-04\n",
      "Epoch 133/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9636 - loss: 0.1748\n",
      "Epoch 133: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9647 - loss: 0.1756 - val_accuracy: 0.9833 - val_loss: 0.1386 - learning_rate: 1.0000e-04\n",
      "Epoch 134/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9725 - loss: 0.1840\n",
      "Epoch 134: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9728 - loss: 0.1845 - val_accuracy: 0.9833 - val_loss: 0.1411 - learning_rate: 1.0000e-04\n",
      "Epoch 135/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9741 - loss: 0.1775\n",
      "Epoch 135: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9713 - loss: 0.1820 - val_accuracy: 0.9833 - val_loss: 0.1353 - learning_rate: 1.0000e-04\n",
      "Epoch 136/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9623 - loss: 0.1778\n",
      "Epoch 136: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9610 - loss: 0.1799 - val_accuracy: 0.9792 - val_loss: 0.1448 - learning_rate: 1.0000e-04\n",
      "Epoch 137/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9772 - loss: 0.1631\n",
      "Epoch 137: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9765 - loss: 0.1717 - val_accuracy: 0.9792 - val_loss: 0.1438 - learning_rate: 1.0000e-04\n",
      "Epoch 138/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9720 - loss: 0.1698\n",
      "Epoch 138: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9669 - loss: 0.1768 - val_accuracy: 0.9792 - val_loss: 0.1371 - learning_rate: 1.0000e-04\n",
      "Epoch 139/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9749 - loss: 0.1700\n",
      "Epoch 139: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9728 - loss: 0.1852 - val_accuracy: 0.9833 - val_loss: 0.1352 - learning_rate: 1.0000e-04\n",
      "Epoch 140/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9623 - loss: 0.1728\n",
      "Epoch 140: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9669 - loss: 0.1769 - val_accuracy: 0.9833 - val_loss: 0.1343 - learning_rate: 1.0000e-04\n",
      "Epoch 141/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9731 - loss: 0.1685\n",
      "Epoch 141: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9706 - loss: 0.1719 - val_accuracy: 0.9792 - val_loss: 0.1370 - learning_rate: 1.0000e-04\n",
      "Epoch 142/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9499 - loss: 0.2099\n",
      "Epoch 142: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9640 - loss: 0.1907 - val_accuracy: 0.9792 - val_loss: 0.1360 - learning_rate: 1.0000e-04\n",
      "Epoch 143/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9789 - loss: 0.1729\n",
      "Epoch 143: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9757 - loss: 0.1710 - val_accuracy: 0.9792 - val_loss: 0.1424 - learning_rate: 1.0000e-04\n",
      "Epoch 144/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9841 - loss: 0.1597\n",
      "Epoch 144: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9721 - loss: 0.1657 - val_accuracy: 0.9792 - val_loss: 0.1367 - learning_rate: 1.0000e-04\n",
      "Epoch 145/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9677 - loss: 0.1856\n",
      "Epoch 145: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9676 - loss: 0.1852 - val_accuracy: 0.9833 - val_loss: 0.1302 - learning_rate: 1.0000e-04\n",
      "Epoch 146/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9772 - loss: 0.1523\n",
      "Epoch 146: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9765 - loss: 0.1600 - val_accuracy: 0.9833 - val_loss: 0.1311 - learning_rate: 1.0000e-04\n",
      "Epoch 147/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9810 - loss: 0.1568\n",
      "Epoch 147: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9691 - loss: 0.1663 - val_accuracy: 0.9875 - val_loss: 0.1307 - learning_rate: 1.0000e-04\n",
      "Epoch 148/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9485 - loss: 0.1955\n",
      "Epoch 148: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9588 - loss: 0.1852 - val_accuracy: 0.9792 - val_loss: 0.1390 - learning_rate: 1.0000e-04\n",
      "Epoch 149/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9718 - loss: 0.1650\n",
      "Epoch 149: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9750 - loss: 0.1593 - val_accuracy: 0.9792 - val_loss: 0.1357 - learning_rate: 1.0000e-04\n",
      "Epoch 150/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9655 - loss: 0.1979\n",
      "Epoch 150: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9669 - loss: 0.1707 - val_accuracy: 0.9875 - val_loss: 0.1280 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 150.\n",
      "\n",
      "âœ… Fold 1 Results:\n",
      "  Test Accuracy: 0.9850\n",
      "  Test AUC: 0.9991\n",
      "  Test Loss: 0.1802\n",
      "ğŸŒŸ New best model! Fold 1 with accuracy: 0.9850\n",
      "\n",
      "Fold 1 Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "ALL (NORMAL+INTERICTAL)     0.9816    1.0000    0.9907       320\n",
      "        ICTAL (SEIZURE)     1.0000    0.9250    0.9610        80\n",
      "\n",
      "               accuracy                         0.9850       400\n",
      "              macro avg     0.9908    0.9625    0.9759       400\n",
      "           weighted avg     0.9853    0.9850    0.9848       400\n",
      "\n",
      "\n",
      "============================================================\n",
      " FOLD 2\n",
      "============================================================\n",
      "\n",
      "Train: 1360, Val: 240, Test: 400\n",
      "Test set distribution: {np.int64(320): np.int64(0), np.int64(80): np.int64(1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Fold 2...\n",
      "ğŸ“Š Using data augmentation with real-time generator\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7096 - loss: 1.4789\n",
      "Epoch 1: val_accuracy improved from None to 0.80000, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.7176 - loss: 1.4562 - val_accuracy: 0.8000 - val_loss: 1.3556 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7059 - loss: 1.4458\n",
      "Epoch 2: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7118 - loss: 1.4190 - val_accuracy: 0.8000 - val_loss: 1.3214 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7163 - loss: 1.4058\n",
      "Epoch 3: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7184 - loss: 1.3872 - val_accuracy: 0.8000 - val_loss: 1.2907 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7325 - loss: 1.3718\n",
      "Epoch 4: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7419 - loss: 1.3556 - val_accuracy: 0.8000 - val_loss: 1.2608 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7586 - loss: 1.3252\n",
      "Epoch 5: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 1.3170 - val_accuracy: 0.8000 - val_loss: 1.2304 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7415 - loss: 1.3074\n",
      "Epoch 6: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 1.2925 - val_accuracy: 0.8000 - val_loss: 1.1959 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7871 - loss: 1.2446\n",
      "Epoch 7: val_accuracy improved from 0.80000 to 0.80417, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.7647 - loss: 1.2601 - val_accuracy: 0.8042 - val_loss: 1.1638 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7781 - loss: 1.2272\n",
      "Epoch 8: val_accuracy improved from 0.80417 to 0.82917, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7669 - loss: 1.2339 - val_accuracy: 0.8292 - val_loss: 1.1312 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7542 - loss: 1.2140\n",
      "Epoch 9: val_accuracy improved from 0.82917 to 0.83333, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7662 - loss: 1.2003 - val_accuracy: 0.8333 - val_loss: 1.1006 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7617 - loss: 1.1834\n",
      "Epoch 10: val_accuracy improved from 0.83333 to 0.85417, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7654 - loss: 1.1737 - val_accuracy: 0.8542 - val_loss: 1.0697 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7801 - loss: 1.1280\n",
      "Epoch 11: val_accuracy did not improve from 0.85417\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7684 - loss: 1.1421 - val_accuracy: 0.8500 - val_loss: 1.0428 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7801 - loss: 1.1228\n",
      "Epoch 12: val_accuracy did not improve from 0.85417\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7809 - loss: 1.1163 - val_accuracy: 0.8542 - val_loss: 1.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7636 - loss: 1.1011\n",
      "Epoch 13: val_accuracy improved from 0.85417 to 0.85833, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7735 - loss: 1.0941 - val_accuracy: 0.8583 - val_loss: 0.9887 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7473 - loss: 1.0791\n",
      "Epoch 14: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7596 - loss: 1.0703 - val_accuracy: 0.8542 - val_loss: 0.9635 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7639 - loss: 1.0575\n",
      "Epoch 15: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7684 - loss: 1.0430 - val_accuracy: 0.8542 - val_loss: 0.9394 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7581 - loss: 1.0404\n",
      "Epoch 16: val_accuracy improved from 0.85833 to 0.86667, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7662 - loss: 1.0207 - val_accuracy: 0.8667 - val_loss: 0.9159 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7695 - loss: 1.0149\n",
      "Epoch 17: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.7699 - loss: 0.9924 - val_accuracy: 0.8625 - val_loss: 0.8929 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7806 - loss: 0.9983\n",
      "Epoch 18: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.7985 - loss: 0.9725 - val_accuracy: 0.8667 - val_loss: 0.8709 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7981 - loss: 0.9281\n",
      "Epoch 19: val_accuracy improved from 0.86667 to 0.87500, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.7846 - loss: 0.9521 - val_accuracy: 0.8750 - val_loss: 0.8457 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7911 - loss: 0.9356\n",
      "Epoch 20: val_accuracy improved from 0.87500 to 0.87917, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.7941 - loss: 0.9147 - val_accuracy: 0.8792 - val_loss: 0.8241 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8041 - loss: 0.9055\n",
      "Epoch 21: val_accuracy did not improve from 0.87917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8007 - loss: 0.8983 - val_accuracy: 0.8750 - val_loss: 0.8077 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7831 - loss: 0.8886\n",
      "Epoch 22: val_accuracy did not improve from 0.87917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7757 - loss: 0.8777 - val_accuracy: 0.8792 - val_loss: 0.7852 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7893 - loss: 0.8727\n",
      "Epoch 23: val_accuracy improved from 0.87917 to 0.89167, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.7824 - loss: 0.8613 - val_accuracy: 0.8917 - val_loss: 0.7587 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7971 - loss: 0.8574\n",
      "Epoch 24: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.8066 - loss: 0.8473 - val_accuracy: 0.8833 - val_loss: 0.7435 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7809 - loss: 0.8685\n",
      "Epoch 25: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7897 - loss: 0.8347 - val_accuracy: 0.8750 - val_loss: 0.7301 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8004 - loss: 0.8174\n",
      "Epoch 26: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8007 - loss: 0.8048 - val_accuracy: 0.8750 - val_loss: 0.7089 - learning_rate: 1.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8082 - loss: 0.7946\n",
      "Epoch 27: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8066 - loss: 0.7808 - val_accuracy: 0.8917 - val_loss: 0.6917 - learning_rate: 1.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8052 - loss: 0.7747\n",
      "Epoch 28: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8029 - loss: 0.7656 - val_accuracy: 0.8667 - val_loss: 0.6841 - learning_rate: 1.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8192 - loss: 0.7645\n",
      "Epoch 29: val_accuracy improved from 0.89167 to 0.90000, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.8184 - loss: 0.7486 - val_accuracy: 0.9000 - val_loss: 0.6572 - learning_rate: 1.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8109 - loss: 0.7518\n",
      "Epoch 30: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.8044 - loss: 0.7368 - val_accuracy: 0.8708 - val_loss: 0.6477 - learning_rate: 1.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8214 - loss: 0.7332\n",
      "Epoch 31: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8301 - loss: 0.7150 - val_accuracy: 0.8958 - val_loss: 0.6116 - learning_rate: 1.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8462 - loss: 0.6833\n",
      "Epoch 32: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8353 - loss: 0.6947 - val_accuracy: 0.8750 - val_loss: 0.6201 - learning_rate: 1.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8141 - loss: 0.6735\n",
      "Epoch 33: val_accuracy improved from 0.90000 to 0.90417, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8382 - loss: 0.6698 - val_accuracy: 0.9042 - val_loss: 0.5919 - learning_rate: 1.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8447 - loss: 0.6598\n",
      "Epoch 34: val_accuracy did not improve from 0.90417\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8456 - loss: 0.6480 - val_accuracy: 0.9000 - val_loss: 0.5899 - learning_rate: 1.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8433 - loss: 0.6526\n",
      "Epoch 35: val_accuracy improved from 0.90417 to 0.94583, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8309 - loss: 0.6489 - val_accuracy: 0.9458 - val_loss: 0.5396 - learning_rate: 1.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8642 - loss: 0.6302\n",
      "Epoch 36: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.8493 - loss: 0.6378 - val_accuracy: 0.9375 - val_loss: 0.5223 - learning_rate: 1.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8830 - loss: 0.6165\n",
      "Epoch 37: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8824 - loss: 0.6067 - val_accuracy: 0.9375 - val_loss: 0.5201 - learning_rate: 1.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8545 - loss: 0.6084\n",
      "Epoch 38: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8625 - loss: 0.6036 - val_accuracy: 0.9208 - val_loss: 0.5298 - learning_rate: 1.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8574 - loss: 0.5962\n",
      "Epoch 39: val_accuracy improved from 0.94583 to 0.96250, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8669 - loss: 0.5863 - val_accuracy: 0.9625 - val_loss: 0.4913 - learning_rate: 1.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8683 - loss: 0.5893\n",
      "Epoch 40: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.8765 - loss: 0.5776 - val_accuracy: 0.9625 - val_loss: 0.4761 - learning_rate: 1.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8652 - loss: 0.5609\n",
      "Epoch 41: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8721 - loss: 0.5594 - val_accuracy: 0.9542 - val_loss: 0.4734 - learning_rate: 1.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8924 - loss: 0.5556\n",
      "Epoch 42: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8956 - loss: 0.5528 - val_accuracy: 0.9417 - val_loss: 0.4762 - learning_rate: 1.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9050 - loss: 0.5269\n",
      "Epoch 43: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8838 - loss: 0.5386 - val_accuracy: 0.9417 - val_loss: 0.4764 - learning_rate: 1.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8703 - loss: 0.5309\n",
      "Epoch 44: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8809 - loss: 0.5371 - val_accuracy: 0.9625 - val_loss: 0.4380 - learning_rate: 1.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8899 - loss: 0.5223\n",
      "Epoch 45: val_accuracy improved from 0.96250 to 0.96667, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.8706 - loss: 0.5304 - val_accuracy: 0.9667 - val_loss: 0.4368 - learning_rate: 1.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8976 - loss: 0.5030\n",
      "Epoch 46: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8846 - loss: 0.5177 - val_accuracy: 0.9458 - val_loss: 0.4370 - learning_rate: 1.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8893 - loss: 0.5050\n",
      "Epoch 47: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9088 - loss: 0.4973 - val_accuracy: 0.9625 - val_loss: 0.4234 - learning_rate: 1.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9187 - loss: 0.4721\n",
      "Epoch 48: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9184 - loss: 0.4735 - val_accuracy: 0.9542 - val_loss: 0.4288 - learning_rate: 1.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8794 - loss: 0.4955\n",
      "Epoch 49: val_accuracy improved from 0.96667 to 0.97500, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8809 - loss: 0.4868 - val_accuracy: 0.9750 - val_loss: 0.3997 - learning_rate: 1.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9123 - loss: 0.4653\n",
      "Epoch 50: val_accuracy improved from 0.97500 to 0.97917, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9088 - loss: 0.4689 - val_accuracy: 0.9792 - val_loss: 0.3829 - learning_rate: 1.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8972 - loss: 0.4819\n",
      "Epoch 51: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9051 - loss: 0.4660 - val_accuracy: 0.9667 - val_loss: 0.3985 - learning_rate: 1.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9163 - loss: 0.4422\n",
      "Epoch 52: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9118 - loss: 0.4462 - val_accuracy: 0.9625 - val_loss: 0.4079 - learning_rate: 1.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9230 - loss: 0.4625\n",
      "Epoch 53: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9184 - loss: 0.4479 - val_accuracy: 0.9667 - val_loss: 0.3786 - learning_rate: 1.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9136 - loss: 0.4384\n",
      "Epoch 54: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9184 - loss: 0.4536 - val_accuracy: 0.9625 - val_loss: 0.3777 - learning_rate: 1.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9193 - loss: 0.4418\n",
      "Epoch 55: val_accuracy improved from 0.97917 to 0.98333, saving model to results\\model_fold2.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9125 - loss: 0.4469 - val_accuracy: 0.9833 - val_loss: 0.3521 - learning_rate: 1.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9290 - loss: 0.4311\n",
      "Epoch 56: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9250 - loss: 0.4340 - val_accuracy: 0.9792 - val_loss: 0.3549 - learning_rate: 1.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9252 - loss: 0.4170\n",
      "Epoch 57: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9169 - loss: 0.4156 - val_accuracy: 0.9667 - val_loss: 0.3634 - learning_rate: 1.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9025 - loss: 0.4214\n",
      "Epoch 58: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9066 - loss: 0.4108 - val_accuracy: 0.9667 - val_loss: 0.3565 - learning_rate: 1.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9266 - loss: 0.3895\n",
      "Epoch 59: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9213 - loss: 0.4043 - val_accuracy: 0.9625 - val_loss: 0.3593 - learning_rate: 1.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9284 - loss: 0.3948\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 60: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9279 - loss: 0.3942 - val_accuracy: 0.9708 - val_loss: 0.3598 - learning_rate: 1.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9127 - loss: 0.4317\n",
      "Epoch 61: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9162 - loss: 0.4213 - val_accuracy: 0.9708 - val_loss: 0.3423 - learning_rate: 5.0000e-05\n",
      "Epoch 62/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8955 - loss: 0.4046\n",
      "Epoch 62: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9147 - loss: 0.3981 - val_accuracy: 0.9833 - val_loss: 0.3279 - learning_rate: 5.0000e-05\n",
      "Epoch 63/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9542 - loss: 0.3630\n",
      "Epoch 63: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9434 - loss: 0.3836 - val_accuracy: 0.9708 - val_loss: 0.3329 - learning_rate: 5.0000e-05\n",
      "Epoch 64/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9269 - loss: 0.4014\n",
      "Epoch 64: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9272 - loss: 0.3970 - val_accuracy: 0.9708 - val_loss: 0.3324 - learning_rate: 5.0000e-05\n",
      "Epoch 65/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9287 - loss: 0.3869\n",
      "Epoch 65: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9235 - loss: 0.3911 - val_accuracy: 0.9708 - val_loss: 0.3317 - learning_rate: 5.0000e-05\n",
      "Epoch 66/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9114 - loss: 0.4097\n",
      "Epoch 66: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9154 - loss: 0.3994 - val_accuracy: 0.9750 - val_loss: 0.3267 - learning_rate: 5.0000e-05\n",
      "Epoch 67/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9180 - loss: 0.3907\n",
      "Epoch 67: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9184 - loss: 0.3943 - val_accuracy: 0.9708 - val_loss: 0.3234 - learning_rate: 5.0000e-05\n",
      "Epoch 68/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9329 - loss: 0.3735\n",
      "Epoch 68: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9368 - loss: 0.3727 - val_accuracy: 0.9750 - val_loss: 0.3228 - learning_rate: 5.0000e-05\n",
      "Epoch 69/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9141 - loss: 0.3868\n",
      "Epoch 69: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9199 - loss: 0.3772 - val_accuracy: 0.9708 - val_loss: 0.3212 - learning_rate: 5.0000e-05\n",
      "Epoch 70/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9295 - loss: 0.4123\n",
      "Epoch 70: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9360 - loss: 0.3928 - val_accuracy: 0.9750 - val_loss: 0.3089 - learning_rate: 5.0000e-05\n",
      "Epoch 71/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9514 - loss: 0.3495\n",
      "Epoch 71: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9463 - loss: 0.3616 - val_accuracy: 0.9750 - val_loss: 0.3033 - learning_rate: 5.0000e-05\n",
      "Epoch 72/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9377 - loss: 0.3601\n",
      "Epoch 72: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9375 - loss: 0.3560 - val_accuracy: 0.9792 - val_loss: 0.3144 - learning_rate: 5.0000e-05\n",
      "Epoch 73/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9376 - loss: 0.3703\n",
      "Epoch 73: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9382 - loss: 0.3623 - val_accuracy: 0.9792 - val_loss: 0.3086 - learning_rate: 5.0000e-05\n",
      "Epoch 74/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9403 - loss: 0.3567\n",
      "Epoch 74: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9324 - loss: 0.3601 - val_accuracy: 0.9792 - val_loss: 0.3069 - learning_rate: 5.0000e-05\n",
      "Epoch 75/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9435 - loss: 0.3602\n",
      "Epoch 75: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9301 - loss: 0.3717 - val_accuracy: 0.9750 - val_loss: 0.3132 - learning_rate: 5.0000e-05\n",
      "Epoch 76/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9211 - loss: 0.3589\n",
      "Epoch 76: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9309 - loss: 0.3638 - val_accuracy: 0.9792 - val_loss: 0.2975 - learning_rate: 5.0000e-05\n",
      "Epoch 77/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9293 - loss: 0.3435\n",
      "Epoch 77: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9360 - loss: 0.3370 - val_accuracy: 0.9750 - val_loss: 0.3036 - learning_rate: 5.0000e-05\n",
      "Epoch 78/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9516 - loss: 0.3643\n",
      "Epoch 78: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9471 - loss: 0.3586 - val_accuracy: 0.9708 - val_loss: 0.2979 - learning_rate: 5.0000e-05\n",
      "Epoch 79/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9545 - loss: 0.3409\n",
      "Epoch 79: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9493 - loss: 0.3447 - val_accuracy: 0.9708 - val_loss: 0.3006 - learning_rate: 5.0000e-05\n",
      "Epoch 80/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9312 - loss: 0.3622\n",
      "Epoch 80: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9382 - loss: 0.3652 - val_accuracy: 0.9750 - val_loss: 0.2968 - learning_rate: 5.0000e-05\n",
      "Epoch 81/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9354 - loss: 0.3688\n",
      "Epoch 81: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9449 - loss: 0.3552 - val_accuracy: 0.9750 - val_loss: 0.2903 - learning_rate: 5.0000e-05\n",
      "Epoch 82/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9586 - loss: 0.3350\n",
      "Epoch 82: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9574 - loss: 0.3434 - val_accuracy: 0.9750 - val_loss: 0.2865 - learning_rate: 5.0000e-05\n",
      "Epoch 83/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9361 - loss: 0.3482\n",
      "Epoch 83: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9419 - loss: 0.3417 - val_accuracy: 0.9750 - val_loss: 0.2964 - learning_rate: 5.0000e-05\n",
      "Epoch 84/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9419 - loss: 0.3492\n",
      "Epoch 84: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9463 - loss: 0.3400 - val_accuracy: 0.9750 - val_loss: 0.2847 - learning_rate: 5.0000e-05\n",
      "Epoch 85/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9566 - loss: 0.3240\n",
      "Epoch 85: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9596 - loss: 0.3287 - val_accuracy: 0.9750 - val_loss: 0.2845 - learning_rate: 5.0000e-05\n",
      "Epoch 86/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9316 - loss: 0.3533\n",
      "Epoch 86: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9316 - loss: 0.3510 - val_accuracy: 0.9792 - val_loss: 0.2715 - learning_rate: 5.0000e-05\n",
      "Epoch 87/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9366 - loss: 0.3312\n",
      "Epoch 87: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9382 - loss: 0.3296 - val_accuracy: 0.9750 - val_loss: 0.2838 - learning_rate: 5.0000e-05\n",
      "Epoch 88/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9578 - loss: 0.3493\n",
      "Epoch 88: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9529 - loss: 0.3366 - val_accuracy: 0.9750 - val_loss: 0.2744 - learning_rate: 5.0000e-05\n",
      "Epoch 89/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9406 - loss: 0.3181\n",
      "Epoch 89: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9419 - loss: 0.3340 - val_accuracy: 0.9750 - val_loss: 0.2643 - learning_rate: 5.0000e-05\n",
      "Epoch 90/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9461 - loss: 0.3228\n",
      "Epoch 90: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9500 - loss: 0.3285 - val_accuracy: 0.9750 - val_loss: 0.2869 - learning_rate: 5.0000e-05\n",
      "Epoch 91/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9544 - loss: 0.3181\n",
      "Epoch 91: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9507 - loss: 0.3129 - val_accuracy: 0.9750 - val_loss: 0.2793 - learning_rate: 5.0000e-05\n",
      "Epoch 92/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9501 - loss: 0.3178\n",
      "Epoch 92: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9463 - loss: 0.3297 - val_accuracy: 0.9750 - val_loss: 0.2584 - learning_rate: 5.0000e-05\n",
      "Epoch 93/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9555 - loss: 0.3208\n",
      "Epoch 93: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9485 - loss: 0.3175 - val_accuracy: 0.9750 - val_loss: 0.2684 - learning_rate: 5.0000e-05\n",
      "Epoch 94/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9578 - loss: 0.3164\n",
      "Epoch 94: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9522 - loss: 0.3164 - val_accuracy: 0.9792 - val_loss: 0.2633 - learning_rate: 5.0000e-05\n",
      "Epoch 95/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9387 - loss: 0.3293\n",
      "Epoch 95: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9397 - loss: 0.3336 - val_accuracy: 0.9792 - val_loss: 0.2490 - learning_rate: 5.0000e-05\n",
      "Epoch 96/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9471 - loss: 0.3143\n",
      "Epoch 96: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9456 - loss: 0.3218 - val_accuracy: 0.9792 - val_loss: 0.2560 - learning_rate: 5.0000e-05\n",
      "Epoch 97/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9397 - loss: 0.3291\n",
      "Epoch 97: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9441 - loss: 0.3215 - val_accuracy: 0.9833 - val_loss: 0.2502 - learning_rate: 5.0000e-05\n",
      "Epoch 98/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9647 - loss: 0.3021\n",
      "Epoch 98: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9596 - loss: 0.3007 - val_accuracy: 0.9792 - val_loss: 0.2598 - learning_rate: 5.0000e-05\n",
      "Epoch 99/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9559 - loss: 0.2983\n",
      "Epoch 99: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9419 - loss: 0.3104 - val_accuracy: 0.9833 - val_loss: 0.2491 - learning_rate: 5.0000e-05\n",
      "Epoch 100/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9504 - loss: 0.3033\n",
      "Epoch 100: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9485 - loss: 0.3062 - val_accuracy: 0.9833 - val_loss: 0.2450 - learning_rate: 5.0000e-05\n",
      "Epoch 101/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9613 - loss: 0.2843\n",
      "Epoch 101: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9559 - loss: 0.2871 - val_accuracy: 0.9792 - val_loss: 0.2590 - learning_rate: 5.0000e-05\n",
      "Epoch 102/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9547 - loss: 0.3087\n",
      "Epoch 102: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9522 - loss: 0.3256 - val_accuracy: 0.9792 - val_loss: 0.2523 - learning_rate: 5.0000e-05\n",
      "Epoch 103/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9624 - loss: 0.2855\n",
      "Epoch 103: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9566 - loss: 0.2899 - val_accuracy: 0.9750 - val_loss: 0.2541 - learning_rate: 5.0000e-05\n",
      "Epoch 104/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9677 - loss: 0.2805\n",
      "Epoch 104: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9603 - loss: 0.2831 - val_accuracy: 0.9833 - val_loss: 0.2379 - learning_rate: 5.0000e-05\n",
      "Epoch 105/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9538 - loss: 0.3015\n",
      "Epoch 105: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9449 - loss: 0.3039 - val_accuracy: 0.9833 - val_loss: 0.2436 - learning_rate: 5.0000e-05\n",
      "Epoch 106/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9493 - loss: 0.2848\n",
      "Epoch 106: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9463 - loss: 0.3020 - val_accuracy: 0.9792 - val_loss: 0.2407 - learning_rate: 5.0000e-05\n",
      "Epoch 107/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9482 - loss: 0.3311\n",
      "Epoch 107: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9478 - loss: 0.3142 - val_accuracy: 0.9750 - val_loss: 0.2442 - learning_rate: 5.0000e-05\n",
      "Epoch 108/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9535 - loss: 0.3050\n",
      "Epoch 108: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9515 - loss: 0.3081 - val_accuracy: 0.9750 - val_loss: 0.2366 - learning_rate: 5.0000e-05\n",
      "Epoch 109/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9689 - loss: 0.2724\n",
      "Epoch 109: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9610 - loss: 0.2851 - val_accuracy: 0.9792 - val_loss: 0.2307 - learning_rate: 5.0000e-05\n",
      "Epoch 110/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9511 - loss: 0.3017\n",
      "Epoch 110: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9529 - loss: 0.2942 - val_accuracy: 0.9750 - val_loss: 0.2411 - learning_rate: 5.0000e-05\n",
      "Epoch 111/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9546 - loss: 0.3089\n",
      "Epoch 111: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9647 - loss: 0.2821 - val_accuracy: 0.9750 - val_loss: 0.2468 - learning_rate: 5.0000e-05\n",
      "Epoch 112/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9514 - loss: 0.2988\n",
      "Epoch 112: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9566 - loss: 0.2953 - val_accuracy: 0.9792 - val_loss: 0.2483 - learning_rate: 5.0000e-05\n",
      "Epoch 113/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9368 - loss: 0.3187\n",
      "Epoch 113: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9485 - loss: 0.2995 - val_accuracy: 0.9792 - val_loss: 0.2290 - learning_rate: 5.0000e-05\n",
      "Epoch 114/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9552 - loss: 0.2835\n",
      "Epoch 114: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9551 - loss: 0.2907 - val_accuracy: 0.9833 - val_loss: 0.2291 - learning_rate: 5.0000e-05\n",
      "Epoch 115/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9594 - loss: 0.2855\n",
      "Epoch 115: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9603 - loss: 0.2835 - val_accuracy: 0.9792 - val_loss: 0.2355 - learning_rate: 5.0000e-05\n",
      "Epoch 116/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9663 - loss: 0.2620\n",
      "Epoch 116: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9654 - loss: 0.2723 - val_accuracy: 0.9792 - val_loss: 0.2199 - learning_rate: 5.0000e-05\n",
      "Epoch 117/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9616 - loss: 0.2807\n",
      "Epoch 117: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9581 - loss: 0.2798 - val_accuracy: 0.9750 - val_loss: 0.2276 - learning_rate: 5.0000e-05\n",
      "Epoch 118/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9578 - loss: 0.2843\n",
      "Epoch 118: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9581 - loss: 0.2906 - val_accuracy: 0.9792 - val_loss: 0.2185 - learning_rate: 5.0000e-05\n",
      "Epoch 119/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9543 - loss: 0.2767\n",
      "Epoch 119: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9574 - loss: 0.2721 - val_accuracy: 0.9792 - val_loss: 0.2263 - learning_rate: 5.0000e-05\n",
      "Epoch 120/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9730 - loss: 0.2560\n",
      "Epoch 120: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9640 - loss: 0.2726 - val_accuracy: 0.9792 - val_loss: 0.2171 - learning_rate: 5.0000e-05\n",
      "Epoch 121/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9619 - loss: 0.2538\n",
      "Epoch 121: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9588 - loss: 0.2613 - val_accuracy: 0.9833 - val_loss: 0.2164 - learning_rate: 5.0000e-05\n",
      "Epoch 122/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9538 - loss: 0.2832\n",
      "Epoch 122: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9537 - loss: 0.2771 - val_accuracy: 0.9833 - val_loss: 0.2266 - learning_rate: 5.0000e-05\n",
      "Epoch 123/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9527 - loss: 0.2678\n",
      "Epoch 123: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9596 - loss: 0.2590 - val_accuracy: 0.9792 - val_loss: 0.2243 - learning_rate: 5.0000e-05\n",
      "Epoch 124/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9642 - loss: 0.2732\n",
      "Epoch 124: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9662 - loss: 0.2510 - val_accuracy: 0.9750 - val_loss: 0.2314 - learning_rate: 5.0000e-05\n",
      "Epoch 125/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9596 - loss: 0.2765\n",
      "Epoch 125: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9566 - loss: 0.2702 - val_accuracy: 0.9833 - val_loss: 0.2215 - learning_rate: 5.0000e-05\n",
      "Epoch 126/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9546 - loss: 0.2506\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 126: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9596 - loss: 0.2527 - val_accuracy: 0.9792 - val_loss: 0.2264 - learning_rate: 5.0000e-05\n",
      "Epoch 127/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9579 - loss: 0.2518\n",
      "Epoch 127: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9522 - loss: 0.2591 - val_accuracy: 0.9792 - val_loss: 0.2204 - learning_rate: 2.5000e-05\n",
      "Epoch 128/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9597 - loss: 0.2621\n",
      "Epoch 128: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9596 - loss: 0.2601 - val_accuracy: 0.9792 - val_loss: 0.2242 - learning_rate: 2.5000e-05\n",
      "Epoch 129/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9637 - loss: 0.2533\n",
      "Epoch 129: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9706 - loss: 0.2478 - val_accuracy: 0.9792 - val_loss: 0.2208 - learning_rate: 2.5000e-05\n",
      "Epoch 130/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9583 - loss: 0.2600\n",
      "Epoch 130: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9603 - loss: 0.2684 - val_accuracy: 0.9792 - val_loss: 0.2152 - learning_rate: 2.5000e-05\n",
      "Epoch 131/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9696 - loss: 0.2412\n",
      "Epoch 131: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9632 - loss: 0.2549 - val_accuracy: 0.9792 - val_loss: 0.2177 - learning_rate: 2.5000e-05\n",
      "Epoch 132/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9487 - loss: 0.2514\n",
      "Epoch 132: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9574 - loss: 0.2480 - val_accuracy: 0.9792 - val_loss: 0.2151 - learning_rate: 2.5000e-05\n",
      "Epoch 133/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9477 - loss: 0.2526\n",
      "Epoch 133: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9559 - loss: 0.2490 - val_accuracy: 0.9792 - val_loss: 0.2177 - learning_rate: 2.5000e-05\n",
      "Epoch 134/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9596 - loss: 0.2683\n",
      "Epoch 134: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9581 - loss: 0.2469 - val_accuracy: 0.9792 - val_loss: 0.2174 - learning_rate: 2.5000e-05\n",
      "Epoch 135/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9753 - loss: 0.2308\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 135: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9691 - loss: 0.2446 - val_accuracy: 0.9792 - val_loss: 0.2227 - learning_rate: 2.5000e-05\n",
      "Epoch 136/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9649 - loss: 0.2484\n",
      "Epoch 136: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9654 - loss: 0.2477 - val_accuracy: 0.9833 - val_loss: 0.2096 - learning_rate: 1.2500e-05\n",
      "Epoch 137/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9726 - loss: 0.2293\n",
      "Epoch 137: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9647 - loss: 0.2433 - val_accuracy: 0.9833 - val_loss: 0.2181 - learning_rate: 1.2500e-05\n",
      "Epoch 138/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9685 - loss: 0.2514\n",
      "Epoch 138: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9610 - loss: 0.2606 - val_accuracy: 0.9833 - val_loss: 0.2196 - learning_rate: 1.2500e-05\n",
      "Epoch 139/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9546 - loss: 0.2434\n",
      "Epoch 139: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9507 - loss: 0.2502 - val_accuracy: 0.9833 - val_loss: 0.2128 - learning_rate: 1.2500e-05\n",
      "Epoch 140/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9597 - loss: 0.2450\n",
      "Epoch 140: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9588 - loss: 0.2434 - val_accuracy: 0.9833 - val_loss: 0.2137 - learning_rate: 1.2500e-05\n",
      "Epoch 141/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9587 - loss: 0.2510\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 141: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9669 - loss: 0.2381 - val_accuracy: 0.9792 - val_loss: 0.2211 - learning_rate: 1.2500e-05\n",
      "Epoch 142/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9643 - loss: 0.2379\n",
      "Epoch 142: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9676 - loss: 0.2396 - val_accuracy: 0.9833 - val_loss: 0.2119 - learning_rate: 6.2500e-06\n",
      "Epoch 143/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9726 - loss: 0.2395\n",
      "Epoch 143: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9728 - loss: 0.2406 - val_accuracy: 0.9833 - val_loss: 0.2152 - learning_rate: 6.2500e-06\n",
      "Epoch 144/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9693 - loss: 0.2332\n",
      "Epoch 144: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9654 - loss: 0.2334 - val_accuracy: 0.9833 - val_loss: 0.2184 - learning_rate: 6.2500e-06\n",
      "Epoch 145/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9622 - loss: 0.2736\n",
      "Epoch 145: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9603 - loss: 0.2528 - val_accuracy: 0.9833 - val_loss: 0.2122 - learning_rate: 6.2500e-06\n",
      "Epoch 146/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9640 - loss: 0.2435\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 146: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9647 - loss: 0.2400 - val_accuracy: 0.9833 - val_loss: 0.2105 - learning_rate: 6.2500e-06\n",
      "Epoch 147/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9703 - loss: 0.2327\n",
      "Epoch 147: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9654 - loss: 0.2484 - val_accuracy: 0.9833 - val_loss: 0.2095 - learning_rate: 3.1250e-06\n",
      "Epoch 148/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9466 - loss: 0.2711\n",
      "Epoch 148: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9603 - loss: 0.2536 - val_accuracy: 0.9833 - val_loss: 0.2102 - learning_rate: 3.1250e-06\n",
      "Epoch 149/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9623 - loss: 0.2537\n",
      "Epoch 149: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9662 - loss: 0.2490 - val_accuracy: 0.9833 - val_loss: 0.2056 - learning_rate: 3.1250e-06\n",
      "Epoch 150/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9700 - loss: 0.2399\n",
      "Epoch 150: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9640 - loss: 0.2536 - val_accuracy: 0.9833 - val_loss: 0.2050 - learning_rate: 3.1250e-06\n",
      "Restoring model weights from the end of the best epoch: 150.\n",
      "\n",
      "âœ… Fold 2 Results:\n",
      "  Test Accuracy: 0.9725\n",
      "  Test AUC: 0.9845\n",
      "  Test Loss: 0.3679\n",
      "\n",
      "Fold 2 Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "ALL (NORMAL+INTERICTAL)     0.9696    0.9969    0.9831       320\n",
      "        ICTAL (SEIZURE)     0.9859    0.8750    0.9272        80\n",
      "\n",
      "               accuracy                         0.9725       400\n",
      "              macro avg     0.9778    0.9359    0.9551       400\n",
      "           weighted avg     0.9729    0.9725    0.9719       400\n",
      "\n",
      "\n",
      "============================================================\n",
      " FOLD 3\n",
      "============================================================\n",
      "\n",
      "Train: 1360, Val: 240, Test: 400\n",
      "Test set distribution: {np.int64(320): np.int64(0), np.int64(80): np.int64(1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Fold 3...\n",
      "ğŸ“Š Using data augmentation with real-time generator\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5324 - loss: 1.4731\n",
      "Epoch 1: val_accuracy improved from None to 0.80000, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 65ms/step - accuracy: 0.5647 - loss: 1.4539 - val_accuracy: 0.8000 - val_loss: 1.3587 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6027 - loss: 1.4102\n",
      "Epoch 2: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.6368 - loss: 1.4087 - val_accuracy: 0.8000 - val_loss: 1.3161 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6593 - loss: 1.3937\n",
      "Epoch 3: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.6728 - loss: 1.3686 - val_accuracy: 0.8000 - val_loss: 1.2747 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7296 - loss: 1.3384\n",
      "Epoch 4: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.7132 - loss: 1.3324 - val_accuracy: 0.8000 - val_loss: 1.2379 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7204 - loss: 1.3031\n",
      "Epoch 5: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.7316 - loss: 1.2941 - val_accuracy: 0.8000 - val_loss: 1.2029 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7270 - loss: 1.2713\n",
      "Epoch 6: val_accuracy improved from 0.80000 to 0.80417, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.7316 - loss: 1.2646 - val_accuracy: 0.8042 - val_loss: 1.1664 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7225 - loss: 1.2446\n",
      "Epoch 7: val_accuracy did not improve from 0.80417\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.7426 - loss: 1.2268 - val_accuracy: 0.8000 - val_loss: 1.1297 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7518 - loss: 1.1951\n",
      "Epoch 8: val_accuracy improved from 0.80417 to 0.80833, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.7618 - loss: 1.1899 - val_accuracy: 0.8083 - val_loss: 1.0969 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7442 - loss: 1.1865\n",
      "Epoch 9: val_accuracy improved from 0.80833 to 0.82500, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.7632 - loss: 1.1644 - val_accuracy: 0.8250 - val_loss: 1.0691 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7670 - loss: 1.1399\n",
      "Epoch 10: val_accuracy improved from 0.82500 to 0.82917, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.7618 - loss: 1.1354 - val_accuracy: 0.8292 - val_loss: 1.0391 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7385 - loss: 1.1487\n",
      "Epoch 11: val_accuracy did not improve from 0.82917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.7551 - loss: 1.1008 - val_accuracy: 0.8250 - val_loss: 1.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7846 - loss: 1.0688\n",
      "Epoch 12: val_accuracy did not improve from 0.82917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.7824 - loss: 1.0685 - val_accuracy: 0.8250 - val_loss: 0.9832 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7828 - loss: 1.0313\n",
      "Epoch 13: val_accuracy improved from 0.82917 to 0.83750, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.7699 - loss: 1.0448 - val_accuracy: 0.8375 - val_loss: 0.9546 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7753 - loss: 1.0307\n",
      "Epoch 14: val_accuracy improved from 0.83750 to 0.84167, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.7691 - loss: 1.0154 - val_accuracy: 0.8417 - val_loss: 0.9319 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7803 - loss: 0.9883\n",
      "Epoch 15: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.7838 - loss: 0.9903 - val_accuracy: 0.8417 - val_loss: 0.9113 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7643 - loss: 0.9827\n",
      "Epoch 16: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.7743 - loss: 0.9815 - val_accuracy: 0.8417 - val_loss: 0.8796 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7661 - loss: 0.9514\n",
      "Epoch 17: val_accuracy improved from 0.84167 to 0.85833, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.7654 - loss: 0.9542 - val_accuracy: 0.8583 - val_loss: 0.8574 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7601 - loss: 0.9235\n",
      "Epoch 18: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.7794 - loss: 0.9195 - val_accuracy: 0.8458 - val_loss: 0.8444 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7672 - loss: 0.9080\n",
      "Epoch 19: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.7831 - loss: 0.9046 - val_accuracy: 0.8292 - val_loss: 0.8340 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7858 - loss: 0.8720\n",
      "Epoch 20: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.7956 - loss: 0.8725 - val_accuracy: 0.8583 - val_loss: 0.8013 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7896 - loss: 0.8725\n",
      "Epoch 21: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.7934 - loss: 0.8630 - val_accuracy: 0.8583 - val_loss: 0.7763 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7921 - loss: 0.8520\n",
      "Epoch 22: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.7949 - loss: 0.8401 - val_accuracy: 0.8500 - val_loss: 0.7658 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8145 - loss: 0.8127\n",
      "Epoch 23: val_accuracy improved from 0.85833 to 0.88333, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.7801 - loss: 0.8317 - val_accuracy: 0.8833 - val_loss: 0.7329 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7778 - loss: 0.8164\n",
      "Epoch 24: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.7831 - loss: 0.7954 - val_accuracy: 0.8667 - val_loss: 0.7330 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8089 - loss: 0.7632\n",
      "Epoch 25: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.7971 - loss: 0.7800 - val_accuracy: 0.8375 - val_loss: 0.7268 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8139 - loss: 0.7703\n",
      "Epoch 26: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.8066 - loss: 0.7577 - val_accuracy: 0.8542 - val_loss: 0.7103 - learning_rate: 1.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7948 - loss: 0.7349\n",
      "Epoch 27: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.7860 - loss: 0.7520 - val_accuracy: 0.8667 - val_loss: 0.6822 - learning_rate: 1.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7648 - loss: 0.7491\n",
      "Epoch 28: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.7978 - loss: 0.7435 - val_accuracy: 0.8292 - val_loss: 0.6870 - learning_rate: 1.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8022 - loss: 0.7340\n",
      "Epoch 29: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.8118 - loss: 0.7183 - val_accuracy: 0.8417 - val_loss: 0.6694 - learning_rate: 1.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8322 - loss: 0.6841\n",
      "Epoch 30: val_accuracy improved from 0.88333 to 0.90417, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.8368 - loss: 0.6939 - val_accuracy: 0.9042 - val_loss: 0.6004 - learning_rate: 1.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8429 - loss: 0.6815\n",
      "Epoch 31: val_accuracy improved from 0.90417 to 0.91250, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.8412 - loss: 0.6765 - val_accuracy: 0.9125 - val_loss: 0.5786 - learning_rate: 1.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8102 - loss: 0.6774\n",
      "Epoch 32: val_accuracy did not improve from 0.91250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.8140 - loss: 0.6710 - val_accuracy: 0.9083 - val_loss: 0.5735 - learning_rate: 1.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8634 - loss: 0.6298\n",
      "Epoch 33: val_accuracy did not improve from 0.91250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.8551 - loss: 0.6460 - val_accuracy: 0.9042 - val_loss: 0.5576 - learning_rate: 1.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8228 - loss: 0.6320\n",
      "Epoch 34: val_accuracy did not improve from 0.91250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.8324 - loss: 0.6327 - val_accuracy: 0.8917 - val_loss: 0.5588 - learning_rate: 1.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8598 - loss: 0.5984\n",
      "Epoch 35: val_accuracy did not improve from 0.91250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.8449 - loss: 0.6168 - val_accuracy: 0.8958 - val_loss: 0.5411 - learning_rate: 1.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8775 - loss: 0.5793\n",
      "Epoch 36: val_accuracy improved from 0.91250 to 0.94167, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.8515 - loss: 0.6061 - val_accuracy: 0.9417 - val_loss: 0.5088 - learning_rate: 1.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8566 - loss: 0.5914\n",
      "Epoch 37: val_accuracy improved from 0.94167 to 0.94583, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.8669 - loss: 0.5883 - val_accuracy: 0.9458 - val_loss: 0.4998 - learning_rate: 1.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8769 - loss: 0.5632\n",
      "Epoch 38: val_accuracy improved from 0.94583 to 0.95417, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.8794 - loss: 0.5675 - val_accuracy: 0.9542 - val_loss: 0.4858 - learning_rate: 1.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8777 - loss: 0.5652\n",
      "Epoch 39: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.8868 - loss: 0.5524 - val_accuracy: 0.9208 - val_loss: 0.4899 - learning_rate: 1.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9040 - loss: 0.5269\n",
      "Epoch 40: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9015 - loss: 0.5317 - val_accuracy: 0.9458 - val_loss: 0.4586 - learning_rate: 1.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8928 - loss: 0.5395\n",
      "Epoch 41: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.8860 - loss: 0.5381 - val_accuracy: 0.9458 - val_loss: 0.4589 - learning_rate: 1.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8948 - loss: 0.5096\n",
      "Epoch 42: val_accuracy improved from 0.95417 to 0.96250, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.8919 - loss: 0.5187 - val_accuracy: 0.9625 - val_loss: 0.4341 - learning_rate: 1.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9024 - loss: 0.5241\n",
      "Epoch 43: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9044 - loss: 0.5299 - val_accuracy: 0.9625 - val_loss: 0.4239 - learning_rate: 1.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8817 - loss: 0.5157\n",
      "Epoch 44: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.8956 - loss: 0.5072 - val_accuracy: 0.9458 - val_loss: 0.4312 - learning_rate: 1.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9174 - loss: 0.5053\n",
      "Epoch 45: val_accuracy improved from 0.96250 to 0.96667, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9066 - loss: 0.5065 - val_accuracy: 0.9667 - val_loss: 0.4077 - learning_rate: 1.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9143 - loss: 0.4848\n",
      "Epoch 46: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9051 - loss: 0.4930 - val_accuracy: 0.9417 - val_loss: 0.4211 - learning_rate: 1.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9034 - loss: 0.4822\n",
      "Epoch 47: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9022 - loss: 0.4796 - val_accuracy: 0.9542 - val_loss: 0.3955 - learning_rate: 1.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9108 - loss: 0.5043\n",
      "Epoch 48: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9125 - loss: 0.4895 - val_accuracy: 0.9583 - val_loss: 0.3819 - learning_rate: 1.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9234 - loss: 0.4564\n",
      "Epoch 49: val_accuracy improved from 0.96667 to 0.97500, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9110 - loss: 0.4656 - val_accuracy: 0.9750 - val_loss: 0.3740 - learning_rate: 1.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9299 - loss: 0.4425\n",
      "Epoch 50: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9184 - loss: 0.4579 - val_accuracy: 0.9458 - val_loss: 0.3722 - learning_rate: 1.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9212 - loss: 0.4374\n",
      "Epoch 51: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9272 - loss: 0.4479 - val_accuracy: 0.9500 - val_loss: 0.3746 - learning_rate: 1.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9255 - loss: 0.4406\n",
      "Epoch 52: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9221 - loss: 0.4360 - val_accuracy: 0.9583 - val_loss: 0.3718 - learning_rate: 1.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9228 - loss: 0.4487\n",
      "Epoch 53: val_accuracy improved from 0.97500 to 0.97917, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9221 - loss: 0.4386 - val_accuracy: 0.9792 - val_loss: 0.3471 - learning_rate: 1.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9216 - loss: 0.4610\n",
      "Epoch 54: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9176 - loss: 0.4464 - val_accuracy: 0.9667 - val_loss: 0.3456 - learning_rate: 1.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9350 - loss: 0.4222\n",
      "Epoch 55: val_accuracy improved from 0.97917 to 0.98750, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9324 - loss: 0.4167 - val_accuracy: 0.9875 - val_loss: 0.3327 - learning_rate: 1.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9201 - loss: 0.4159\n",
      "Epoch 56: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9132 - loss: 0.4185 - val_accuracy: 0.9792 - val_loss: 0.3327 - learning_rate: 1.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9144 - loss: 0.4441\n",
      "Epoch 57: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9221 - loss: 0.4249 - val_accuracy: 0.9583 - val_loss: 0.3577 - learning_rate: 1.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9479 - loss: 0.3965\n",
      "Epoch 58: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9397 - loss: 0.4058 - val_accuracy: 0.9625 - val_loss: 0.3332 - learning_rate: 1.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9534 - loss: 0.3887\n",
      "Epoch 59: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9419 - loss: 0.3999 - val_accuracy: 0.9458 - val_loss: 0.3465 - learning_rate: 1.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9432 - loss: 0.4037\n",
      "Epoch 60: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9309 - loss: 0.4093 - val_accuracy: 0.9583 - val_loss: 0.3303 - learning_rate: 1.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9397 - loss: 0.3847\n",
      "Epoch 61: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9390 - loss: 0.3804 - val_accuracy: 0.9833 - val_loss: 0.3119 - learning_rate: 1.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9444 - loss: 0.3526\n",
      "Epoch 62: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9404 - loss: 0.3629 - val_accuracy: 0.9833 - val_loss: 0.3053 - learning_rate: 1.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9223 - loss: 0.3858\n",
      "Epoch 63: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9265 - loss: 0.3865 - val_accuracy: 0.9833 - val_loss: 0.3011 - learning_rate: 1.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9108 - loss: 0.3814\n",
      "Epoch 64: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9243 - loss: 0.3750 - val_accuracy: 0.9583 - val_loss: 0.3186 - learning_rate: 1.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9194 - loss: 0.3864\n",
      "Epoch 65: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9294 - loss: 0.3742 - val_accuracy: 0.9833 - val_loss: 0.2903 - learning_rate: 1.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9358 - loss: 0.3666\n",
      "Epoch 66: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9331 - loss: 0.3732 - val_accuracy: 0.9792 - val_loss: 0.2949 - learning_rate: 1.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9258 - loss: 0.3629\n",
      "Epoch 67: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - accuracy: 0.9419 - loss: 0.3520 - val_accuracy: 0.9750 - val_loss: 0.2861 - learning_rate: 1.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9355 - loss: 0.3471\n",
      "Epoch 68: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9338 - loss: 0.3525 - val_accuracy: 0.9583 - val_loss: 0.2938 - learning_rate: 1.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9449 - loss: 0.3261\n",
      "Epoch 69: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9390 - loss: 0.3404 - val_accuracy: 0.9833 - val_loss: 0.2743 - learning_rate: 1.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9358 - loss: 0.3517\n",
      "Epoch 70: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9346 - loss: 0.3458 - val_accuracy: 0.9833 - val_loss: 0.2627 - learning_rate: 1.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9245 - loss: 0.3415\n",
      "Epoch 71: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9287 - loss: 0.3586 - val_accuracy: 0.9833 - val_loss: 0.2703 - learning_rate: 1.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9318 - loss: 0.3525\n",
      "Epoch 72: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9434 - loss: 0.3500 - val_accuracy: 0.9708 - val_loss: 0.2732 - learning_rate: 1.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9512 - loss: 0.3172\n",
      "Epoch 73: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9434 - loss: 0.3316 - val_accuracy: 0.9792 - val_loss: 0.2586 - learning_rate: 1.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9399 - loss: 0.3291\n",
      "Epoch 74: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9360 - loss: 0.3333 - val_accuracy: 0.9833 - val_loss: 0.2546 - learning_rate: 1.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9219 - loss: 0.3574\n",
      "Epoch 75: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9353 - loss: 0.3379 - val_accuracy: 0.9833 - val_loss: 0.2435 - learning_rate: 1.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9589 - loss: 0.3020\n",
      "Epoch 76: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9559 - loss: 0.3004 - val_accuracy: 0.9875 - val_loss: 0.2408 - learning_rate: 1.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9473 - loss: 0.3157\n",
      "Epoch 77: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9441 - loss: 0.3201 - val_accuracy: 0.9667 - val_loss: 0.2467 - learning_rate: 1.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9372 - loss: 0.3183\n",
      "Epoch 78: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9375 - loss: 0.3250 - val_accuracy: 0.9750 - val_loss: 0.2394 - learning_rate: 1.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9496 - loss: 0.3206\n",
      "Epoch 79: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9471 - loss: 0.3237 - val_accuracy: 0.9708 - val_loss: 0.2397 - learning_rate: 1.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9602 - loss: 0.2970\n",
      "Epoch 80: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9551 - loss: 0.3057 - val_accuracy: 0.9875 - val_loss: 0.2275 - learning_rate: 1.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9359 - loss: 0.3035\n",
      "Epoch 81: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9456 - loss: 0.3033 - val_accuracy: 0.9792 - val_loss: 0.2326 - learning_rate: 1.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9350 - loss: 0.3236\n",
      "Epoch 82: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9397 - loss: 0.3133 - val_accuracy: 0.9875 - val_loss: 0.2266 - learning_rate: 1.0000e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9582 - loss: 0.2942\n",
      "Epoch 83: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9493 - loss: 0.3017 - val_accuracy: 0.9708 - val_loss: 0.2346 - learning_rate: 1.0000e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9563 - loss: 0.2926\n",
      "Epoch 84: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9610 - loss: 0.2894 - val_accuracy: 0.9875 - val_loss: 0.2202 - learning_rate: 1.0000e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9361 - loss: 0.3438\n",
      "Epoch 85: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9419 - loss: 0.3073 - val_accuracy: 0.9792 - val_loss: 0.2246 - learning_rate: 1.0000e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9559 - loss: 0.2827\n",
      "Epoch 86: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9574 - loss: 0.2987 - val_accuracy: 0.9750 - val_loss: 0.2240 - learning_rate: 1.0000e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9424 - loss: 0.2920\n",
      "Epoch 87: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9515 - loss: 0.2908 - val_accuracy: 0.9833 - val_loss: 0.2157 - learning_rate: 1.0000e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9609 - loss: 0.2743\n",
      "Epoch 88: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9603 - loss: 0.2810 - val_accuracy: 0.9833 - val_loss: 0.2160 - learning_rate: 1.0000e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9588 - loss: 0.2704\n",
      "Epoch 89: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9588 - loss: 0.2765 - val_accuracy: 0.9833 - val_loss: 0.2124 - learning_rate: 1.0000e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9666 - loss: 0.2673\n",
      "Epoch 90: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9559 - loss: 0.2808 - val_accuracy: 0.9875 - val_loss: 0.2066 - learning_rate: 1.0000e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9474 - loss: 0.2951\n",
      "Epoch 91: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9441 - loss: 0.2952 - val_accuracy: 0.9792 - val_loss: 0.2131 - learning_rate: 1.0000e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9567 - loss: 0.2617\n",
      "Epoch 92: val_accuracy improved from 0.98750 to 0.99583, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9618 - loss: 0.2672 - val_accuracy: 0.9958 - val_loss: 0.2011 - learning_rate: 1.0000e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9482 - loss: 0.2946\n",
      "Epoch 93: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9478 - loss: 0.2838 - val_accuracy: 0.9917 - val_loss: 0.2004 - learning_rate: 1.0000e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9606 - loss: 0.2553\n",
      "Epoch 94: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9625 - loss: 0.2576 - val_accuracy: 0.9875 - val_loss: 0.1983 - learning_rate: 1.0000e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9738 - loss: 0.2471\n",
      "Epoch 95: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9691 - loss: 0.2461 - val_accuracy: 0.9917 - val_loss: 0.1921 - learning_rate: 1.0000e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9551 - loss: 0.2552\n",
      "Epoch 96: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9618 - loss: 0.2584 - val_accuracy: 0.9875 - val_loss: 0.1953 - learning_rate: 1.0000e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9553 - loss: 0.2789\n",
      "Epoch 97: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9500 - loss: 0.2689 - val_accuracy: 0.9917 - val_loss: 0.1935 - learning_rate: 1.0000e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9554 - loss: 0.2632\n",
      "Epoch 98: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9500 - loss: 0.2607 - val_accuracy: 0.9917 - val_loss: 0.1893 - learning_rate: 1.0000e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9575 - loss: 0.2566\n",
      "Epoch 99: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9559 - loss: 0.2568 - val_accuracy: 0.9917 - val_loss: 0.1880 - learning_rate: 1.0000e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9585 - loss: 0.2598\n",
      "Epoch 100: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9588 - loss: 0.2604 - val_accuracy: 0.9833 - val_loss: 0.1906 - learning_rate: 1.0000e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9504 - loss: 0.2600\n",
      "Epoch 101: val_accuracy improved from 0.99583 to 1.00000, saving model to results\\model_fold3.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9566 - loss: 0.2505 - val_accuracy: 1.0000 - val_loss: 0.1831 - learning_rate: 1.0000e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9687 - loss: 0.2451\n",
      "Epoch 102: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9676 - loss: 0.2467 - val_accuracy: 0.9958 - val_loss: 0.1800 - learning_rate: 1.0000e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9591 - loss: 0.2422\n",
      "Epoch 103: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9596 - loss: 0.2480 - val_accuracy: 0.9917 - val_loss: 0.1825 - learning_rate: 1.0000e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9668 - loss: 0.2442\n",
      "Epoch 104: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9596 - loss: 0.2416 - val_accuracy: 0.9750 - val_loss: 0.1835 - learning_rate: 1.0000e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9472 - loss: 0.2423\n",
      "Epoch 105: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9596 - loss: 0.2359 - val_accuracy: 0.9917 - val_loss: 0.1768 - learning_rate: 1.0000e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9498 - loss: 0.2476\n",
      "Epoch 106: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9574 - loss: 0.2380 - val_accuracy: 0.9792 - val_loss: 0.1850 - learning_rate: 1.0000e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9320 - loss: 0.2790\n",
      "Epoch 107: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9478 - loss: 0.2623 - val_accuracy: 0.9875 - val_loss: 0.1776 - learning_rate: 1.0000e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9585 - loss: 0.2493\n",
      "Epoch 108: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9596 - loss: 0.2423 - val_accuracy: 0.9917 - val_loss: 0.1738 - learning_rate: 1.0000e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9711 - loss: 0.2260\n",
      "Epoch 109: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9699 - loss: 0.2286 - val_accuracy: 0.9875 - val_loss: 0.1749 - learning_rate: 1.0000e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9751 - loss: 0.2114\n",
      "Epoch 110: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9654 - loss: 0.2276 - val_accuracy: 0.9833 - val_loss: 0.1757 - learning_rate: 1.0000e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9637 - loss: 0.2354\n",
      "Epoch 111: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9640 - loss: 0.2296 - val_accuracy: 0.9917 - val_loss: 0.1741 - learning_rate: 1.0000e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9585 - loss: 0.2290\n",
      "Epoch 112: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9588 - loss: 0.2300 - val_accuracy: 0.9833 - val_loss: 0.1673 - learning_rate: 1.0000e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9598 - loss: 0.2265\n",
      "Epoch 113: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9632 - loss: 0.2307 - val_accuracy: 0.9875 - val_loss: 0.1695 - learning_rate: 1.0000e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9656 - loss: 0.2219\n",
      "Epoch 114: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9632 - loss: 0.2327 - val_accuracy: 0.9833 - val_loss: 0.1681 - learning_rate: 1.0000e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9764 - loss: 0.2044\n",
      "Epoch 115: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9669 - loss: 0.2249 - val_accuracy: 0.9917 - val_loss: 0.1696 - learning_rate: 1.0000e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9553 - loss: 0.2139\n",
      "Epoch 116: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9632 - loss: 0.2144 - val_accuracy: 0.9958 - val_loss: 0.1582 - learning_rate: 1.0000e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9539 - loss: 0.2053\n",
      "Epoch 117: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9588 - loss: 0.2170 - val_accuracy: 0.9958 - val_loss: 0.1586 - learning_rate: 1.0000e-04\n",
      "Epoch 118/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9677 - loss: 0.2183\n",
      "Epoch 118: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9713 - loss: 0.2105 - val_accuracy: 0.9958 - val_loss: 0.1566 - learning_rate: 1.0000e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9620 - loss: 0.2247\n",
      "Epoch 119: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9632 - loss: 0.2261 - val_accuracy: 0.9917 - val_loss: 0.1601 - learning_rate: 1.0000e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9546 - loss: 0.2254\n",
      "Epoch 120: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9596 - loss: 0.2151 - val_accuracy: 0.9875 - val_loss: 0.1556 - learning_rate: 1.0000e-04\n",
      "Epoch 121/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9584 - loss: 0.2555\n",
      "Epoch 121: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9669 - loss: 0.2120 - val_accuracy: 0.9958 - val_loss: 0.1525 - learning_rate: 1.0000e-04\n",
      "Epoch 122/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9648 - loss: 0.2016\n",
      "Epoch 122: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9654 - loss: 0.2031 - val_accuracy: 0.9958 - val_loss: 0.1534 - learning_rate: 1.0000e-04\n",
      "Epoch 123/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9675 - loss: 0.2076\n",
      "Epoch 123: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9669 - loss: 0.2014 - val_accuracy: 0.9875 - val_loss: 0.1514 - learning_rate: 1.0000e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9494 - loss: 0.2103\n",
      "Epoch 124: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9632 - loss: 0.2015 - val_accuracy: 1.0000 - val_loss: 0.1474 - learning_rate: 1.0000e-04\n",
      "Epoch 125/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9729 - loss: 0.1932\n",
      "Epoch 125: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9713 - loss: 0.1994 - val_accuracy: 0.9958 - val_loss: 0.1493 - learning_rate: 1.0000e-04\n",
      "Epoch 126/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9757 - loss: 0.1813\n",
      "Epoch 126: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9706 - loss: 0.1845 - val_accuracy: 1.0000 - val_loss: 0.1443 - learning_rate: 1.0000e-04\n",
      "Epoch 127/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9675 - loss: 0.1885\n",
      "Epoch 127: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9699 - loss: 0.1945 - val_accuracy: 0.9917 - val_loss: 0.1536 - learning_rate: 1.0000e-04\n",
      "Epoch 128/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9570 - loss: 0.1999\n",
      "Epoch 128: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9625 - loss: 0.1970 - val_accuracy: 0.9958 - val_loss: 0.1441 - learning_rate: 1.0000e-04\n",
      "Epoch 129/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9701 - loss: 0.1867\n",
      "Epoch 129: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9735 - loss: 0.1907 - val_accuracy: 0.9917 - val_loss: 0.1441 - learning_rate: 1.0000e-04\n",
      "Epoch 130/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9715 - loss: 0.1857\n",
      "Epoch 130: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9654 - loss: 0.1925 - val_accuracy: 0.9875 - val_loss: 0.1464 - learning_rate: 1.0000e-04\n",
      "Epoch 131/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9744 - loss: 0.1781\n",
      "Epoch 131: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9676 - loss: 0.1822 - val_accuracy: 0.9875 - val_loss: 0.1428 - learning_rate: 1.0000e-04\n",
      "Epoch 132/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9841 - loss: 0.1707\n",
      "Epoch 132: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9787 - loss: 0.1866 - val_accuracy: 0.9875 - val_loss: 0.1423 - learning_rate: 1.0000e-04\n",
      "Epoch 133/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9723 - loss: 0.1840\n",
      "Epoch 133: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9794 - loss: 0.1781 - val_accuracy: 0.9958 - val_loss: 0.1367 - learning_rate: 1.0000e-04\n",
      "Epoch 134/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9687 - loss: 0.2091\n",
      "Epoch 134: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9801 - loss: 0.1811 - val_accuracy: 0.9917 - val_loss: 0.1416 - learning_rate: 1.0000e-04\n",
      "Epoch 135/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9613 - loss: 0.1900\n",
      "Epoch 135: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9647 - loss: 0.1905 - val_accuracy: 0.9833 - val_loss: 0.1386 - learning_rate: 1.0000e-04\n",
      "Epoch 136/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9676 - loss: 0.1987\n",
      "Epoch 136: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9669 - loss: 0.1963 - val_accuracy: 0.9917 - val_loss: 0.1409 - learning_rate: 1.0000e-04\n",
      "Epoch 137/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9769 - loss: 0.1763\n",
      "Epoch 137: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9721 - loss: 0.1810 - val_accuracy: 0.9875 - val_loss: 0.1379 - learning_rate: 1.0000e-04\n",
      "Epoch 138/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9679 - loss: 0.1870\n",
      "Epoch 138: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9735 - loss: 0.1792 - val_accuracy: 0.9917 - val_loss: 0.1352 - learning_rate: 1.0000e-04\n",
      "Epoch 139/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9748 - loss: 0.1727\n",
      "Epoch 139: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9713 - loss: 0.1840 - val_accuracy: 0.9917 - val_loss: 0.1390 - learning_rate: 1.0000e-04\n",
      "Epoch 140/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9755 - loss: 0.1908\n",
      "Epoch 140: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9794 - loss: 0.1822 - val_accuracy: 0.9917 - val_loss: 0.1389 - learning_rate: 1.0000e-04\n",
      "Epoch 141/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9832 - loss: 0.1721\n",
      "Epoch 141: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9824 - loss: 0.1763 - val_accuracy: 0.9917 - val_loss: 0.1352 - learning_rate: 1.0000e-04\n",
      "Epoch 142/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9767 - loss: 0.1655\n",
      "Epoch 142: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9787 - loss: 0.1677 - val_accuracy: 0.9917 - val_loss: 0.1320 - learning_rate: 1.0000e-04\n",
      "Epoch 143/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9774 - loss: 0.1657\n",
      "Epoch 143: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9654 - loss: 0.1815 - val_accuracy: 0.9917 - val_loss: 0.1309 - learning_rate: 1.0000e-04\n",
      "Epoch 144/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9652 - loss: 0.1809\n",
      "Epoch 144: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9669 - loss: 0.1838 - val_accuracy: 0.9917 - val_loss: 0.1327 - learning_rate: 1.0000e-04\n",
      "Epoch 145/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9787 - loss: 0.1689\n",
      "Epoch 145: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9772 - loss: 0.1675 - val_accuracy: 0.9875 - val_loss: 0.1305 - learning_rate: 1.0000e-04\n",
      "Epoch 146/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9724 - loss: 0.1773\n",
      "Epoch 146: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.9721 - loss: 0.1768 - val_accuracy: 0.9917 - val_loss: 0.1281 - learning_rate: 1.0000e-04\n",
      "Epoch 147/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9686 - loss: 0.1656\n",
      "Epoch 147: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9684 - loss: 0.1692 - val_accuracy: 0.9917 - val_loss: 0.1259 - learning_rate: 1.0000e-04\n",
      "Epoch 148/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9736 - loss: 0.1595\n",
      "Epoch 148: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9735 - loss: 0.1576 - val_accuracy: 0.9958 - val_loss: 0.1235 - learning_rate: 1.0000e-04\n",
      "Epoch 149/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9755 - loss: 0.1607\n",
      "Epoch 149: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9669 - loss: 0.1797 - val_accuracy: 0.9917 - val_loss: 0.1349 - learning_rate: 1.0000e-04\n",
      "Epoch 150/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9657 - loss: 0.2164\n",
      "Epoch 150: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - accuracy: 0.9684 - loss: 0.1931 - val_accuracy: 0.9833 - val_loss: 0.1310 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 148.\n",
      "\n",
      "âœ… Fold 3 Results:\n",
      "  Test Accuracy: 0.9900\n",
      "  Test AUC: 0.9996\n",
      "  Test Loss: 0.1866\n",
      "ğŸŒŸ New best model! Fold 3 with accuracy: 0.9900\n",
      "\n",
      "Fold 3 Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "ALL (NORMAL+INTERICTAL)     0.9877    1.0000    0.9938       320\n",
      "        ICTAL (SEIZURE)     1.0000    0.9500    0.9744        80\n",
      "\n",
      "               accuracy                         0.9900       400\n",
      "              macro avg     0.9938    0.9750    0.9841       400\n",
      "           weighted avg     0.9901    0.9900    0.9899       400\n",
      "\n",
      "\n",
      "============================================================\n",
      " FOLD 4\n",
      "============================================================\n",
      "\n",
      "Train: 1360, Val: 240, Test: 400\n",
      "Test set distribution: {np.int64(320): np.int64(0), np.int64(80): np.int64(1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Fold 4...\n",
      "ğŸ“Š Using data augmentation with real-time generator\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5253 - loss: 1.4805\n",
      "Epoch 1: val_accuracy improved from None to 0.80000, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 63ms/step - accuracy: 0.5610 - loss: 1.4713 - val_accuracy: 0.8000 - val_loss: 1.3625 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6539 - loss: 1.4309\n",
      "Epoch 2: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.6596 - loss: 1.4217 - val_accuracy: 0.8000 - val_loss: 1.3290 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6890 - loss: 1.4014\n",
      "Epoch 3: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6860 - loss: 1.3903 - val_accuracy: 0.8000 - val_loss: 1.2990 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7113 - loss: 1.3646\n",
      "Epoch 4: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7074 - loss: 1.3610 - val_accuracy: 0.8000 - val_loss: 1.2717 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7107 - loss: 1.3426\n",
      "Epoch 5: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7147 - loss: 1.3262 - val_accuracy: 0.8000 - val_loss: 1.2425 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7247 - loss: 1.3125\n",
      "Epoch 6: val_accuracy improved from 0.80000 to 0.80417, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7346 - loss: 1.3097 - val_accuracy: 0.8042 - val_loss: 1.2115 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7513 - loss: 1.2608\n",
      "Epoch 7: val_accuracy improved from 0.80417 to 0.81250, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7610 - loss: 1.2636 - val_accuracy: 0.8125 - val_loss: 1.1803 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7692 - loss: 1.2382\n",
      "Epoch 8: val_accuracy improved from 0.81250 to 0.82083, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7662 - loss: 1.2417 - val_accuracy: 0.8208 - val_loss: 1.1501 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7656 - loss: 1.2226\n",
      "Epoch 9: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7699 - loss: 1.2218 - val_accuracy: 0.8208 - val_loss: 1.1233 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7699 - loss: 1.2069\n",
      "Epoch 10: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7684 - loss: 1.1893 - val_accuracy: 0.7958 - val_loss: 1.1055 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7387 - loss: 1.1831\n",
      "Epoch 11: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7551 - loss: 1.1675 - val_accuracy: 0.8167 - val_loss: 1.0755 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7571 - loss: 1.1330\n",
      "Epoch 12: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7574 - loss: 1.1473 - val_accuracy: 0.8042 - val_loss: 1.0581 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7839 - loss: 1.1182\n",
      "Epoch 13: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7853 - loss: 1.1151 - val_accuracy: 0.8167 - val_loss: 1.0317 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7897 - loss: 1.1129\n",
      "Epoch 14: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7956 - loss: 1.0904 - val_accuracy: 0.8083 - val_loss: 1.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7820 - loss: 1.0771\n",
      "Epoch 15: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7735 - loss: 1.0758 - val_accuracy: 0.8167 - val_loss: 0.9898 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7799 - loss: 1.0549\n",
      "Epoch 16: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7801 - loss: 1.0554 - val_accuracy: 0.8167 - val_loss: 0.9669 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7772 - loss: 1.0271\n",
      "Epoch 17: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7765 - loss: 1.0259 - val_accuracy: 0.8167 - val_loss: 0.9470 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7833 - loss: 1.0142\n",
      "Epoch 18: val_accuracy improved from 0.82083 to 0.82917, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7816 - loss: 1.0063 - val_accuracy: 0.8292 - val_loss: 0.9165 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7941 - loss: 0.9863\n",
      "Epoch 19: val_accuracy did not improve from 0.82917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7882 - loss: 0.9907 - val_accuracy: 0.8208 - val_loss: 0.9062 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7630 - loss: 0.9820\n",
      "Epoch 20: val_accuracy did not improve from 0.82917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7794 - loss: 0.9638 - val_accuracy: 0.8250 - val_loss: 0.8825 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8118 - loss: 0.9366\n",
      "Epoch 21: val_accuracy improved from 0.82917 to 0.83750, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7985 - loss: 0.9416 - val_accuracy: 0.8375 - val_loss: 0.8586 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7797 - loss: 0.9301\n",
      "Epoch 22: val_accuracy did not improve from 0.83750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7882 - loss: 0.9228 - val_accuracy: 0.8208 - val_loss: 0.8504 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8018 - loss: 0.9130\n",
      "Epoch 23: val_accuracy improved from 0.83750 to 0.84167, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8000 - loss: 0.8998 - val_accuracy: 0.8417 - val_loss: 0.8190 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8270 - loss: 0.8743\n",
      "Epoch 24: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8199 - loss: 0.8704 - val_accuracy: 0.8417 - val_loss: 0.7998 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8224 - loss: 0.8657\n",
      "Epoch 25: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8176 - loss: 0.8622 - val_accuracy: 0.8375 - val_loss: 0.7895 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7810 - loss: 0.8404\n",
      "Epoch 26: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7971 - loss: 0.8478 - val_accuracy: 0.8292 - val_loss: 0.7788 - learning_rate: 1.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8067 - loss: 0.8166\n",
      "Epoch 27: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8132 - loss: 0.8200 - val_accuracy: 0.8375 - val_loss: 0.7499 - learning_rate: 1.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7939 - loss: 0.8221\n",
      "Epoch 28: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8051 - loss: 0.8049 - val_accuracy: 0.8375 - val_loss: 0.7409 - learning_rate: 1.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8118 - loss: 0.7773\n",
      "Epoch 29: val_accuracy improved from 0.84167 to 0.86250, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8140 - loss: 0.7816 - val_accuracy: 0.8625 - val_loss: 0.7136 - learning_rate: 1.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8217 - loss: 0.7602\n",
      "Epoch 30: val_accuracy did not improve from 0.86250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8162 - loss: 0.7808 - val_accuracy: 0.8458 - val_loss: 0.7068 - learning_rate: 1.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7989 - loss: 0.7801\n",
      "Epoch 31: val_accuracy improved from 0.86250 to 0.86667, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8059 - loss: 0.7645 - val_accuracy: 0.8667 - val_loss: 0.6767 - learning_rate: 1.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8332 - loss: 0.7256\n",
      "Epoch 32: val_accuracy improved from 0.86667 to 0.87083, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8309 - loss: 0.7373 - val_accuracy: 0.8708 - val_loss: 0.6639 - learning_rate: 1.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8161 - loss: 0.7189\n",
      "Epoch 33: val_accuracy did not improve from 0.87083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8331 - loss: 0.7114 - val_accuracy: 0.8667 - val_loss: 0.6539 - learning_rate: 1.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8358 - loss: 0.7065\n",
      "Epoch 34: val_accuracy did not improve from 0.87083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8353 - loss: 0.7020 - val_accuracy: 0.8667 - val_loss: 0.6365 - learning_rate: 1.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8147 - loss: 0.7107\n",
      "Epoch 35: val_accuracy improved from 0.87083 to 0.87500, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8287 - loss: 0.6943 - val_accuracy: 0.8750 - val_loss: 0.6281 - learning_rate: 1.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8606 - loss: 0.6669\n",
      "Epoch 36: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8478 - loss: 0.6711 - val_accuracy: 0.8583 - val_loss: 0.6276 - learning_rate: 1.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8352 - loss: 0.6478\n",
      "Epoch 37: val_accuracy improved from 0.87500 to 0.87917, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8485 - loss: 0.6411 - val_accuracy: 0.8792 - val_loss: 0.6048 - learning_rate: 1.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8255 - loss: 0.6525\n",
      "Epoch 38: val_accuracy did not improve from 0.87917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8265 - loss: 0.6455 - val_accuracy: 0.8792 - val_loss: 0.5792 - learning_rate: 1.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8671 - loss: 0.6254\n",
      "Epoch 39: val_accuracy improved from 0.87917 to 0.89583, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8691 - loss: 0.6193 - val_accuracy: 0.8958 - val_loss: 0.5465 - learning_rate: 1.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8398 - loss: 0.6221\n",
      "Epoch 40: val_accuracy improved from 0.89583 to 0.90417, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8515 - loss: 0.6063 - val_accuracy: 0.9042 - val_loss: 0.5203 - learning_rate: 1.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8504 - loss: 0.5932\n",
      "Epoch 41: val_accuracy improved from 0.90417 to 0.92083, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8493 - loss: 0.5934 - val_accuracy: 0.9208 - val_loss: 0.5086 - learning_rate: 1.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8308 - loss: 0.6140\n",
      "Epoch 42: val_accuracy did not improve from 0.92083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8419 - loss: 0.5893 - val_accuracy: 0.9208 - val_loss: 0.4909 - learning_rate: 1.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8662 - loss: 0.5634\n",
      "Epoch 43: val_accuracy improved from 0.92083 to 0.92500, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8699 - loss: 0.5791 - val_accuracy: 0.9250 - val_loss: 0.4861 - learning_rate: 1.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8660 - loss: 0.5543\n",
      "Epoch 44: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8721 - loss: 0.5521 - val_accuracy: 0.9208 - val_loss: 0.4939 - learning_rate: 1.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8864 - loss: 0.5217\n",
      "Epoch 45: val_accuracy improved from 0.92500 to 0.93750, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8779 - loss: 0.5392 - val_accuracy: 0.9375 - val_loss: 0.4742 - learning_rate: 1.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8765 - loss: 0.5429\n",
      "Epoch 46: val_accuracy did not improve from 0.93750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8787 - loss: 0.5452 - val_accuracy: 0.9292 - val_loss: 0.4655 - learning_rate: 1.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8598 - loss: 0.5263\n",
      "Epoch 47: val_accuracy improved from 0.93750 to 0.95417, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8544 - loss: 0.5332 - val_accuracy: 0.9542 - val_loss: 0.4250 - learning_rate: 1.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8749 - loss: 0.5274\n",
      "Epoch 48: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8838 - loss: 0.5064 - val_accuracy: 0.9125 - val_loss: 0.4641 - learning_rate: 1.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8885 - loss: 0.4988\n",
      "Epoch 49: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8912 - loss: 0.4888 - val_accuracy: 0.9500 - val_loss: 0.4137 - learning_rate: 1.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9035 - loss: 0.5097\n",
      "Epoch 50: val_accuracy improved from 0.95417 to 0.96250, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8993 - loss: 0.5182 - val_accuracy: 0.9625 - val_loss: 0.4075 - learning_rate: 1.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8711 - loss: 0.4954\n",
      "Epoch 51: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8713 - loss: 0.4921 - val_accuracy: 0.9500 - val_loss: 0.4095 - learning_rate: 1.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9017 - loss: 0.4736\n",
      "Epoch 52: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9037 - loss: 0.4809 - val_accuracy: 0.9542 - val_loss: 0.3928 - learning_rate: 1.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8963 - loss: 0.4750\n",
      "Epoch 53: val_accuracy improved from 0.96250 to 0.96667, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8956 - loss: 0.4671 - val_accuracy: 0.9667 - val_loss: 0.3803 - learning_rate: 1.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9055 - loss: 0.4623\n",
      "Epoch 54: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9140 - loss: 0.4601 - val_accuracy: 0.9583 - val_loss: 0.3921 - learning_rate: 1.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9220 - loss: 0.4481\n",
      "Epoch 55: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9132 - loss: 0.4488 - val_accuracy: 0.9500 - val_loss: 0.3786 - learning_rate: 1.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9113 - loss: 0.4593\n",
      "Epoch 56: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9007 - loss: 0.4557 - val_accuracy: 0.9625 - val_loss: 0.3549 - learning_rate: 1.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9221 - loss: 0.4326\n",
      "Epoch 57: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9103 - loss: 0.4469 - val_accuracy: 0.9583 - val_loss: 0.3595 - learning_rate: 1.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9113 - loss: 0.4344\n",
      "Epoch 58: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9162 - loss: 0.4329 - val_accuracy: 0.9625 - val_loss: 0.3529 - learning_rate: 1.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9141 - loss: 0.4191\n",
      "Epoch 59: val_accuracy improved from 0.96667 to 0.97083, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9154 - loss: 0.4223 - val_accuracy: 0.9708 - val_loss: 0.3502 - learning_rate: 1.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9348 - loss: 0.4199\n",
      "Epoch 60: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9309 - loss: 0.4209 - val_accuracy: 0.9625 - val_loss: 0.3350 - learning_rate: 1.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9313 - loss: 0.3905\n",
      "Epoch 61: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9250 - loss: 0.4030 - val_accuracy: 0.9708 - val_loss: 0.3345 - learning_rate: 1.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9284 - loss: 0.4048\n",
      "Epoch 62: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9184 - loss: 0.4160 - val_accuracy: 0.9542 - val_loss: 0.3537 - learning_rate: 1.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9344 - loss: 0.3926\n",
      "Epoch 63: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9184 - loss: 0.4053 - val_accuracy: 0.9458 - val_loss: 0.3520 - learning_rate: 1.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9316 - loss: 0.4040\n",
      "Epoch 64: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9294 - loss: 0.3994 - val_accuracy: 0.9708 - val_loss: 0.3082 - learning_rate: 1.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9329 - loss: 0.3632\n",
      "Epoch 65: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9346 - loss: 0.3695 - val_accuracy: 0.9667 - val_loss: 0.3161 - learning_rate: 1.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9192 - loss: 0.3859\n",
      "Epoch 66: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9176 - loss: 0.3980 - val_accuracy: 0.9708 - val_loss: 0.3005 - learning_rate: 1.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9285 - loss: 0.3953\n",
      "Epoch 67: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9368 - loss: 0.3836 - val_accuracy: 0.9625 - val_loss: 0.3074 - learning_rate: 1.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9333 - loss: 0.3566\n",
      "Epoch 68: val_accuracy improved from 0.97083 to 0.98750, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9346 - loss: 0.3623 - val_accuracy: 0.9875 - val_loss: 0.2833 - learning_rate: 1.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9499 - loss: 0.3570\n",
      "Epoch 69: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9382 - loss: 0.3803 - val_accuracy: 0.9667 - val_loss: 0.3015 - learning_rate: 1.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9504 - loss: 0.3461\n",
      "Epoch 70: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9471 - loss: 0.3568 - val_accuracy: 0.9875 - val_loss: 0.2778 - learning_rate: 1.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9490 - loss: 0.3439\n",
      "Epoch 71: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9441 - loss: 0.3548 - val_accuracy: 0.9750 - val_loss: 0.2841 - learning_rate: 1.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9309 - loss: 0.3761\n",
      "Epoch 72: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9360 - loss: 0.3554 - val_accuracy: 0.9708 - val_loss: 0.2801 - learning_rate: 1.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9469 - loss: 0.3443\n",
      "Epoch 73: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9449 - loss: 0.3473 - val_accuracy: 0.9667 - val_loss: 0.2735 - learning_rate: 1.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9460 - loss: 0.3431\n",
      "Epoch 74: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9463 - loss: 0.3461 - val_accuracy: 0.9750 - val_loss: 0.2694 - learning_rate: 1.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9347 - loss: 0.3327\n",
      "Epoch 75: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9346 - loss: 0.3465 - val_accuracy: 0.9833 - val_loss: 0.2636 - learning_rate: 1.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9136 - loss: 0.3603\n",
      "Epoch 76: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9272 - loss: 0.3440 - val_accuracy: 0.9708 - val_loss: 0.2632 - learning_rate: 1.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9379 - loss: 0.3447\n",
      "Epoch 77: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9426 - loss: 0.3437 - val_accuracy: 0.9625 - val_loss: 0.2609 - learning_rate: 1.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9433 - loss: 0.3204\n",
      "Epoch 78: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9449 - loss: 0.3243 - val_accuracy: 0.9792 - val_loss: 0.2476 - learning_rate: 1.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9407 - loss: 0.3423\n",
      "Epoch 79: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9404 - loss: 0.3457 - val_accuracy: 0.9750 - val_loss: 0.2488 - learning_rate: 1.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9531 - loss: 0.3109\n",
      "Epoch 80: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9449 - loss: 0.3262 - val_accuracy: 0.9667 - val_loss: 0.2753 - learning_rate: 1.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9494 - loss: 0.3208\n",
      "Epoch 81: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9522 - loss: 0.3224 - val_accuracy: 0.9750 - val_loss: 0.2442 - learning_rate: 1.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9347 - loss: 0.3074\n",
      "Epoch 82: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9434 - loss: 0.3161 - val_accuracy: 0.9833 - val_loss: 0.2409 - learning_rate: 1.0000e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9409 - loss: 0.3301\n",
      "Epoch 83: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9500 - loss: 0.3019 - val_accuracy: 0.9708 - val_loss: 0.2446 - learning_rate: 1.0000e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9546 - loss: 0.2926\n",
      "Epoch 84: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9515 - loss: 0.3109 - val_accuracy: 0.9792 - val_loss: 0.2325 - learning_rate: 1.0000e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9602 - loss: 0.2921\n",
      "Epoch 85: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9566 - loss: 0.2898 - val_accuracy: 0.9708 - val_loss: 0.2296 - learning_rate: 1.0000e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9536 - loss: 0.3058\n",
      "Epoch 86: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9500 - loss: 0.3015 - val_accuracy: 0.9792 - val_loss: 0.2231 - learning_rate: 1.0000e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9441 - loss: 0.3131\n",
      "Epoch 87: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9529 - loss: 0.2970 - val_accuracy: 0.9667 - val_loss: 0.2495 - learning_rate: 1.0000e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9530 - loss: 0.2800\n",
      "Epoch 88: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9441 - loss: 0.3012 - val_accuracy: 0.9750 - val_loss: 0.2246 - learning_rate: 1.0000e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9513 - loss: 0.2967\n",
      "Epoch 89: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9515 - loss: 0.3025 - val_accuracy: 0.9833 - val_loss: 0.2192 - learning_rate: 1.0000e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9528 - loss: 0.2887\n",
      "Epoch 90: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9632 - loss: 0.2712 - val_accuracy: 0.9792 - val_loss: 0.2140 - learning_rate: 1.0000e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9710 - loss: 0.2538\n",
      "Epoch 91: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9632 - loss: 0.2653 - val_accuracy: 0.9667 - val_loss: 0.2129 - learning_rate: 1.0000e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9678 - loss: 0.2737\n",
      "Epoch 92: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9640 - loss: 0.2828 - val_accuracy: 0.9708 - val_loss: 0.2129 - learning_rate: 1.0000e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9616 - loss: 0.2643\n",
      "Epoch 93: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9691 - loss: 0.2694 - val_accuracy: 0.9750 - val_loss: 0.2131 - learning_rate: 1.0000e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9628 - loss: 0.2682\n",
      "Epoch 94: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9632 - loss: 0.2582 - val_accuracy: 0.9833 - val_loss: 0.2029 - learning_rate: 1.0000e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9664 - loss: 0.2492\n",
      "Epoch 95: val_accuracy improved from 0.98750 to 0.99167, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9610 - loss: 0.2646 - val_accuracy: 0.9917 - val_loss: 0.2002 - learning_rate: 1.0000e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9645 - loss: 0.2483\n",
      "Epoch 96: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9632 - loss: 0.2628 - val_accuracy: 0.9792 - val_loss: 0.2018 - learning_rate: 1.0000e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9734 - loss: 0.2350\n",
      "Epoch 97: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9603 - loss: 0.2635 - val_accuracy: 0.9583 - val_loss: 0.2518 - learning_rate: 1.0000e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9658 - loss: 0.2439\n",
      "Epoch 98: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9706 - loss: 0.2438 - val_accuracy: 0.9792 - val_loss: 0.1980 - learning_rate: 1.0000e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9548 - loss: 0.2601\n",
      "Epoch 99: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9537 - loss: 0.2670 - val_accuracy: 0.9792 - val_loss: 0.1967 - learning_rate: 1.0000e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9599 - loss: 0.2557\n",
      "Epoch 100: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9581 - loss: 0.2572 - val_accuracy: 0.9833 - val_loss: 0.1932 - learning_rate: 1.0000e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9551 - loss: 0.2555\n",
      "Epoch 101: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9537 - loss: 0.2627 - val_accuracy: 0.9750 - val_loss: 0.1960 - learning_rate: 1.0000e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9654 - loss: 0.2387\n",
      "Epoch 102: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9434 - loss: 0.2638 - val_accuracy: 0.9917 - val_loss: 0.1878 - learning_rate: 1.0000e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9572 - loss: 0.2555\n",
      "Epoch 103: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9544 - loss: 0.2520 - val_accuracy: 0.9833 - val_loss: 0.1865 - learning_rate: 1.0000e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9719 - loss: 0.2222\n",
      "Epoch 104: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9640 - loss: 0.2369 - val_accuracy: 0.9875 - val_loss: 0.1862 - learning_rate: 1.0000e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9683 - loss: 0.2446\n",
      "Epoch 105: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9721 - loss: 0.2391 - val_accuracy: 0.9875 - val_loss: 0.1828 - learning_rate: 1.0000e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9625 - loss: 0.2444\n",
      "Epoch 106: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9588 - loss: 0.2453 - val_accuracy: 0.9875 - val_loss: 0.1794 - learning_rate: 1.0000e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9746 - loss: 0.2316\n",
      "Epoch 107: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9743 - loss: 0.2376 - val_accuracy: 0.9792 - val_loss: 0.1832 - learning_rate: 1.0000e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9731 - loss: 0.2402\n",
      "Epoch 108: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9632 - loss: 0.2448 - val_accuracy: 0.9917 - val_loss: 0.1814 - learning_rate: 1.0000e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9593 - loss: 0.2442\n",
      "Epoch 109: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9662 - loss: 0.2313 - val_accuracy: 0.9792 - val_loss: 0.1813 - learning_rate: 1.0000e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9641 - loss: 0.2463\n",
      "Epoch 110: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9625 - loss: 0.2427 - val_accuracy: 0.9833 - val_loss: 0.1774 - learning_rate: 1.0000e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9648 - loss: 0.2383\n",
      "Epoch 111: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9669 - loss: 0.2303 - val_accuracy: 0.9917 - val_loss: 0.1717 - learning_rate: 1.0000e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9642 - loss: 0.2297\n",
      "Epoch 112: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9706 - loss: 0.2212 - val_accuracy: 0.9875 - val_loss: 0.1766 - learning_rate: 1.0000e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9546 - loss: 0.2452\n",
      "Epoch 113: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9625 - loss: 0.2288 - val_accuracy: 0.9833 - val_loss: 0.1686 - learning_rate: 1.0000e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9587 - loss: 0.2283\n",
      "Epoch 114: val_accuracy improved from 0.99167 to 0.99583, saving model to results\\model_fold4.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9625 - loss: 0.2287 - val_accuracy: 0.9958 - val_loss: 0.1664 - learning_rate: 1.0000e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9715 - loss: 0.2124\n",
      "Epoch 115: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9662 - loss: 0.2179 - val_accuracy: 0.9833 - val_loss: 0.1653 - learning_rate: 1.0000e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9729 - loss: 0.2106\n",
      "Epoch 116: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9728 - loss: 0.2125 - val_accuracy: 0.9833 - val_loss: 0.1711 - learning_rate: 1.0000e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9733 - loss: 0.2069\n",
      "Epoch 117: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9706 - loss: 0.2267 - val_accuracy: 0.9833 - val_loss: 0.1634 - learning_rate: 1.0000e-04\n",
      "Epoch 118/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9679 - loss: 0.2063\n",
      "Epoch 118: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9706 - loss: 0.2081 - val_accuracy: 0.9792 - val_loss: 0.1735 - learning_rate: 1.0000e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9748 - loss: 0.2176\n",
      "Epoch 119: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9765 - loss: 0.2132 - val_accuracy: 0.9875 - val_loss: 0.1618 - learning_rate: 1.0000e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9763 - loss: 0.1952\n",
      "Epoch 120: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9713 - loss: 0.2059 - val_accuracy: 0.9708 - val_loss: 0.1772 - learning_rate: 1.0000e-04\n",
      "Epoch 121/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9782 - loss: 0.2003\n",
      "Epoch 121: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9794 - loss: 0.1938 - val_accuracy: 0.9917 - val_loss: 0.1597 - learning_rate: 1.0000e-04\n",
      "Epoch 122/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9598 - loss: 0.2101\n",
      "Epoch 122: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9647 - loss: 0.2053 - val_accuracy: 0.9875 - val_loss: 0.1569 - learning_rate: 1.0000e-04\n",
      "Epoch 123/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9713 - loss: 0.1989\n",
      "Epoch 123: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9735 - loss: 0.1941 - val_accuracy: 0.9917 - val_loss: 0.1508 - learning_rate: 1.0000e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9698 - loss: 0.2194\n",
      "Epoch 124: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9699 - loss: 0.2220 - val_accuracy: 0.9917 - val_loss: 0.1534 - learning_rate: 1.0000e-04\n",
      "Epoch 125/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9801 - loss: 0.1896\n",
      "Epoch 125: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9757 - loss: 0.1931 - val_accuracy: 0.9875 - val_loss: 0.1535 - learning_rate: 1.0000e-04\n",
      "Epoch 126/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9790 - loss: 0.1864\n",
      "Epoch 126: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9750 - loss: 0.1848 - val_accuracy: 0.9958 - val_loss: 0.1469 - learning_rate: 1.0000e-04\n",
      "Epoch 127/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9696 - loss: 0.1976\n",
      "Epoch 127: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9669 - loss: 0.1987 - val_accuracy: 0.9792 - val_loss: 0.1558 - learning_rate: 1.0000e-04\n",
      "Epoch 128/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9758 - loss: 0.1920\n",
      "Epoch 128: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9713 - loss: 0.1950 - val_accuracy: 0.9875 - val_loss: 0.1528 - learning_rate: 1.0000e-04\n",
      "Epoch 129/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9728 - loss: 0.1925\n",
      "Epoch 129: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9765 - loss: 0.1856 - val_accuracy: 0.9833 - val_loss: 0.1521 - learning_rate: 1.0000e-04\n",
      "Epoch 130/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9665 - loss: 0.2020\n",
      "Epoch 130: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9669 - loss: 0.2001 - val_accuracy: 0.9833 - val_loss: 0.1509 - learning_rate: 1.0000e-04\n",
      "Epoch 131/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9770 - loss: 0.1800\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 131: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9676 - loss: 0.1856 - val_accuracy: 0.9958 - val_loss: 0.1502 - learning_rate: 1.0000e-04\n",
      "Epoch 132/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9615 - loss: 0.1889\n",
      "Epoch 132: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9721 - loss: 0.1835 - val_accuracy: 0.9958 - val_loss: 0.1434 - learning_rate: 5.0000e-05\n",
      "Epoch 133/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9847 - loss: 0.1715\n",
      "Epoch 133: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9824 - loss: 0.1732 - val_accuracy: 0.9958 - val_loss: 0.1412 - learning_rate: 5.0000e-05\n",
      "Epoch 134/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9839 - loss: 0.1830\n",
      "Epoch 134: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9809 - loss: 0.1856 - val_accuracy: 0.9875 - val_loss: 0.1424 - learning_rate: 5.0000e-05\n",
      "Epoch 135/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9748 - loss: 0.1825\n",
      "Epoch 135: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9750 - loss: 0.1880 - val_accuracy: 0.9958 - val_loss: 0.1404 - learning_rate: 5.0000e-05\n",
      "Epoch 136/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9752 - loss: 0.1845\n",
      "Epoch 136: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9809 - loss: 0.1778 - val_accuracy: 0.9875 - val_loss: 0.1400 - learning_rate: 5.0000e-05\n",
      "Epoch 137/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9878 - loss: 0.1678\n",
      "Epoch 137: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9831 - loss: 0.1734 - val_accuracy: 0.9917 - val_loss: 0.1439 - learning_rate: 5.0000e-05\n",
      "Epoch 138/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9770 - loss: 0.1916\n",
      "Epoch 138: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9794 - loss: 0.1835 - val_accuracy: 0.9833 - val_loss: 0.1445 - learning_rate: 5.0000e-05\n",
      "Epoch 139/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9794 - loss: 0.1749\n",
      "Epoch 139: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9757 - loss: 0.1874 - val_accuracy: 0.9917 - val_loss: 0.1407 - learning_rate: 5.0000e-05\n",
      "Epoch 140/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9534 - loss: 0.1967\n",
      "Epoch 140: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9647 - loss: 0.2011 - val_accuracy: 0.9917 - val_loss: 0.1413 - learning_rate: 5.0000e-05\n",
      "Epoch 141/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9716 - loss: 0.1804\n",
      "Epoch 141: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9765 - loss: 0.1847 - val_accuracy: 0.9917 - val_loss: 0.1398 - learning_rate: 5.0000e-05\n",
      "Epoch 142/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9815 - loss: 0.1726\n",
      "Epoch 142: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9743 - loss: 0.1785 - val_accuracy: 0.9917 - val_loss: 0.1385 - learning_rate: 5.0000e-05\n",
      "Epoch 143/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9862 - loss: 0.1625\n",
      "Epoch 143: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9816 - loss: 0.1678 - val_accuracy: 0.9875 - val_loss: 0.1378 - learning_rate: 5.0000e-05\n",
      "Epoch 144/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9858 - loss: 0.1644\n",
      "Epoch 144: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9831 - loss: 0.1635 - val_accuracy: 0.9875 - val_loss: 0.1449 - learning_rate: 5.0000e-05\n",
      "Epoch 145/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9750 - loss: 0.1823\n",
      "Epoch 145: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9647 - loss: 0.1899 - val_accuracy: 0.9958 - val_loss: 0.1418 - learning_rate: 5.0000e-05\n",
      "Epoch 146/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9821 - loss: 0.1688\n",
      "Epoch 146: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9831 - loss: 0.1624 - val_accuracy: 0.9875 - val_loss: 0.1418 - learning_rate: 5.0000e-05\n",
      "Epoch 147/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9855 - loss: 0.1622\n",
      "Epoch 147: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9846 - loss: 0.1738 - val_accuracy: 0.9958 - val_loss: 0.1352 - learning_rate: 5.0000e-05\n",
      "Epoch 148/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9760 - loss: 0.1685\n",
      "Epoch 148: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9757 - loss: 0.1779 - val_accuracy: 0.9958 - val_loss: 0.1351 - learning_rate: 5.0000e-05\n",
      "Epoch 149/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9788 - loss: 0.1643\n",
      "Epoch 149: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9809 - loss: 0.1617 - val_accuracy: 0.9875 - val_loss: 0.1397 - learning_rate: 5.0000e-05\n",
      "Epoch 150/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9847 - loss: 0.1878\n",
      "Epoch 150: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9824 - loss: 0.1873 - val_accuracy: 0.9958 - val_loss: 0.1349 - learning_rate: 5.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 150.\n",
      "\n",
      "âœ… Fold 4 Results:\n",
      "  Test Accuracy: 0.9900\n",
      "  Test AUC: 0.9996\n",
      "  Test Loss: 0.1674\n",
      "\n",
      "Fold 4 Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "ALL (NORMAL+INTERICTAL)     0.9938    0.9938    0.9938       320\n",
      "        ICTAL (SEIZURE)     0.9750    0.9750    0.9750        80\n",
      "\n",
      "               accuracy                         0.9900       400\n",
      "              macro avg     0.9844    0.9844    0.9844       400\n",
      "           weighted avg     0.9900    0.9900    0.9900       400\n",
      "\n",
      "\n",
      "============================================================\n",
      " FOLD 5\n",
      "============================================================\n",
      "\n",
      "Train: 1360, Val: 240, Test: 400\n",
      "Test set distribution: {np.int64(320): np.int64(0), np.int64(80): np.int64(1)}\n",
      "\n",
      "ğŸš€ Training Fold 5...\n",
      "ğŸ“Š Using data augmentation with real-time generator\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5643 - loss: 1.4682\n",
      "Epoch 1: val_accuracy improved from None to 0.80000, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5949 - loss: 1.4511 - val_accuracy: 0.8000 - val_loss: 1.3502 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6568 - loss: 1.4113\n",
      "Epoch 2: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6684 - loss: 1.4056 - val_accuracy: 0.8000 - val_loss: 1.3078 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7101 - loss: 1.3868\n",
      "Epoch 3: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7154 - loss: 1.3690 - val_accuracy: 0.8000 - val_loss: 1.2746 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7382 - loss: 1.3295\n",
      "Epoch 4: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.7221 - loss: 1.3287 - val_accuracy: 0.8000 - val_loss: 1.2459 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7575 - loss: 1.3061\n",
      "Epoch 5: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.7588 - loss: 1.3005 - val_accuracy: 0.8000 - val_loss: 1.2139 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7282 - loss: 1.2892\n",
      "Epoch 6: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7485 - loss: 1.2641 - val_accuracy: 0.8000 - val_loss: 1.1779 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7399 - loss: 1.2471\n",
      "Epoch 7: val_accuracy improved from 0.80000 to 0.80417, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.7478 - loss: 1.2433 - val_accuracy: 0.8042 - val_loss: 1.1441 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7437 - loss: 1.2288\n",
      "Epoch 8: val_accuracy improved from 0.80417 to 0.80833, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.7507 - loss: 1.2158 - val_accuracy: 0.8083 - val_loss: 1.1104 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7632 - loss: 1.1887\n",
      "Epoch 9: val_accuracy improved from 0.80833 to 0.82083, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.7566 - loss: 1.1818 - val_accuracy: 0.8208 - val_loss: 1.0816 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7580 - loss: 1.1608\n",
      "Epoch 10: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7640 - loss: 1.1560 - val_accuracy: 0.8208 - val_loss: 1.0568 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7617 - loss: 1.1046\n",
      "Epoch 11: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.7566 - loss: 1.1191 - val_accuracy: 0.8208 - val_loss: 1.0283 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7948 - loss: 1.0694\n",
      "Epoch 12: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7779 - loss: 1.0886 - val_accuracy: 0.8125 - val_loss: 1.0049 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7798 - loss: 1.0812\n",
      "Epoch 13: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7794 - loss: 1.0758 - val_accuracy: 0.8125 - val_loss: 0.9846 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7739 - loss: 1.0508\n",
      "Epoch 14: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7868 - loss: 1.0426 - val_accuracy: 0.8167 - val_loss: 0.9597 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7968 - loss: 1.0071\n",
      "Epoch 15: val_accuracy did not improve from 0.82083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7868 - loss: 1.0171 - val_accuracy: 0.8208 - val_loss: 0.9285 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7968 - loss: 0.9861\n",
      "Epoch 16: val_accuracy improved from 0.82083 to 0.85000, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.7941 - loss: 0.9899 - val_accuracy: 0.8500 - val_loss: 0.9042 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7519 - loss: 0.9935\n",
      "Epoch 17: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7721 - loss: 0.9695 - val_accuracy: 0.8208 - val_loss: 0.8949 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7871 - loss: 0.9503\n",
      "Epoch 18: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7897 - loss: 0.9504 - val_accuracy: 0.8417 - val_loss: 0.8661 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7904 - loss: 0.9351\n",
      "Epoch 19: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7875 - loss: 0.9289 - val_accuracy: 0.8250 - val_loss: 0.8548 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7907 - loss: 0.8964\n",
      "Epoch 20: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7882 - loss: 0.9049 - val_accuracy: 0.8208 - val_loss: 0.8335 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7856 - loss: 0.9083\n",
      "Epoch 21: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8059 - loss: 0.8838 - val_accuracy: 0.8250 - val_loss: 0.8137 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8203 - loss: 0.8556\n",
      "Epoch 22: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8140 - loss: 0.8563 - val_accuracy: 0.8417 - val_loss: 0.7939 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8033 - loss: 0.8523\n",
      "Epoch 23: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.8096 - loss: 0.8514 - val_accuracy: 0.8292 - val_loss: 0.7764 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7918 - loss: 0.8237\n",
      "Epoch 24: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7875 - loss: 0.8277 - val_accuracy: 0.8417 - val_loss: 0.7593 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8115 - loss: 0.8150\n",
      "Epoch 25: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8103 - loss: 0.8057 - val_accuracy: 0.8458 - val_loss: 0.7360 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8175 - loss: 0.7791\n",
      "Epoch 26: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8184 - loss: 0.7766 - val_accuracy: 0.8292 - val_loss: 0.7512 - learning_rate: 1.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7983 - loss: 0.7736\n",
      "Epoch 27: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7926 - loss: 0.7681 - val_accuracy: 0.8458 - val_loss: 0.7089 - learning_rate: 1.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8212 - loss: 0.7477\n",
      "Epoch 28: val_accuracy improved from 0.85000 to 0.85833, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.8169 - loss: 0.7483 - val_accuracy: 0.8583 - val_loss: 0.6887 - learning_rate: 1.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7949 - loss: 0.7432\n",
      "Epoch 29: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.8029 - loss: 0.7380 - val_accuracy: 0.8583 - val_loss: 0.6762 - learning_rate: 1.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8129 - loss: 0.7283\n",
      "Epoch 30: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8051 - loss: 0.7203 - val_accuracy: 0.8458 - val_loss: 0.6613 - learning_rate: 1.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7953 - loss: 0.7108\n",
      "Epoch 31: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8110 - loss: 0.7150 - val_accuracy: 0.8583 - val_loss: 0.6254 - learning_rate: 1.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8156 - loss: 0.6764\n",
      "Epoch 32: val_accuracy improved from 0.85833 to 0.87500, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.8206 - loss: 0.6980 - val_accuracy: 0.8750 - val_loss: 0.6102 - learning_rate: 1.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8239 - loss: 0.6731\n",
      "Epoch 33: val_accuracy improved from 0.87500 to 0.90000, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.8301 - loss: 0.6640 - val_accuracy: 0.9000 - val_loss: 0.5814 - learning_rate: 1.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8022 - loss: 0.7524\n",
      "Epoch 34: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.8199 - loss: 0.6754 - val_accuracy: 0.8792 - val_loss: 0.5843 - learning_rate: 1.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8217 - loss: 0.6712\n",
      "Epoch 35: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8397 - loss: 0.6392 - val_accuracy: 0.8625 - val_loss: 0.6047 - learning_rate: 1.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8702 - loss: 0.6242\n",
      "Epoch 36: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8603 - loss: 0.6258 - val_accuracy: 0.8875 - val_loss: 0.5487 - learning_rate: 1.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8534 - loss: 0.5973\n",
      "Epoch 37: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.8456 - loss: 0.6060 - val_accuracy: 0.8417 - val_loss: 0.6185 - learning_rate: 1.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8479 - loss: 0.5739\n",
      "Epoch 38: val_accuracy improved from 0.90000 to 0.95417, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.8412 - loss: 0.5854 - val_accuracy: 0.9542 - val_loss: 0.4938 - learning_rate: 1.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8448 - loss: 0.5745\n",
      "Epoch 39: val_accuracy improved from 0.95417 to 0.95833, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.8500 - loss: 0.5828 - val_accuracy: 0.9583 - val_loss: 0.5000 - learning_rate: 1.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8487 - loss: 0.5680\n",
      "Epoch 40: val_accuracy improved from 0.95833 to 0.96250, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.8478 - loss: 0.5811 - val_accuracy: 0.9625 - val_loss: 0.4902 - learning_rate: 1.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8741 - loss: 0.5654\n",
      "Epoch 41: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8684 - loss: 0.5675 - val_accuracy: 0.9625 - val_loss: 0.4736 - learning_rate: 1.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8701 - loss: 0.5594\n",
      "Epoch 42: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8625 - loss: 0.5538 - val_accuracy: 0.9625 - val_loss: 0.4682 - learning_rate: 1.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8885 - loss: 0.5318\n",
      "Epoch 43: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8993 - loss: 0.5305 - val_accuracy: 0.9500 - val_loss: 0.4719 - learning_rate: 1.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8794 - loss: 0.5307\n",
      "Epoch 44: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.8743 - loss: 0.5386 - val_accuracy: 0.9500 - val_loss: 0.4597 - learning_rate: 1.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9000 - loss: 0.5077\n",
      "Epoch 45: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8985 - loss: 0.5023 - val_accuracy: 0.9625 - val_loss: 0.4353 - learning_rate: 1.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8944 - loss: 0.5147\n",
      "Epoch 46: val_accuracy improved from 0.96250 to 0.97083, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.8993 - loss: 0.5155 - val_accuracy: 0.9708 - val_loss: 0.4340 - learning_rate: 1.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8744 - loss: 0.5069\n",
      "Epoch 47: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8654 - loss: 0.5207 - val_accuracy: 0.9708 - val_loss: 0.4234 - learning_rate: 1.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8767 - loss: 0.5076\n",
      "Epoch 48: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8779 - loss: 0.5101 - val_accuracy: 0.9417 - val_loss: 0.4370 - learning_rate: 1.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9061 - loss: 0.4738\n",
      "Epoch 49: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9132 - loss: 0.4643 - val_accuracy: 0.9542 - val_loss: 0.4219 - learning_rate: 1.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4789\n",
      "Epoch 50: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9037 - loss: 0.4836 - val_accuracy: 0.9625 - val_loss: 0.4111 - learning_rate: 1.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8968 - loss: 0.4766\n",
      "Epoch 51: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8985 - loss: 0.4742 - val_accuracy: 0.9708 - val_loss: 0.3983 - learning_rate: 1.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9110 - loss: 0.4471\n",
      "Epoch 52: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9029 - loss: 0.4571 - val_accuracy: 0.9667 - val_loss: 0.3793 - learning_rate: 1.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8971 - loss: 0.4532\n",
      "Epoch 53: val_accuracy improved from 0.97083 to 0.97917, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9000 - loss: 0.4497 - val_accuracy: 0.9792 - val_loss: 0.3628 - learning_rate: 1.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9243 - loss: 0.4592\n",
      "Epoch 54: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9051 - loss: 0.4654 - val_accuracy: 0.9708 - val_loss: 0.3666 - learning_rate: 1.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9258 - loss: 0.4237\n",
      "Epoch 55: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9176 - loss: 0.4338 - val_accuracy: 0.9583 - val_loss: 0.3697 - learning_rate: 1.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9016 - loss: 0.4459\n",
      "Epoch 56: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9081 - loss: 0.4309 - val_accuracy: 0.9583 - val_loss: 0.3880 - learning_rate: 1.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9268 - loss: 0.3906\n",
      "Epoch 57: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9287 - loss: 0.4012 - val_accuracy: 0.9750 - val_loss: 0.3516 - learning_rate: 1.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9156 - loss: 0.4043\n",
      "Epoch 58: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9162 - loss: 0.4078 - val_accuracy: 0.9750 - val_loss: 0.3565 - learning_rate: 1.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9045 - loss: 0.4208\n",
      "Epoch 59: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9066 - loss: 0.4141 - val_accuracy: 0.9708 - val_loss: 0.3583 - learning_rate: 1.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9492 - loss: 0.3809\n",
      "Epoch 60: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9375 - loss: 0.3937 - val_accuracy: 0.9792 - val_loss: 0.3372 - learning_rate: 1.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9068 - loss: 0.4175\n",
      "Epoch 61: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9213 - loss: 0.4072 - val_accuracy: 0.9625 - val_loss: 0.3585 - learning_rate: 1.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9352 - loss: 0.3928\n",
      "Epoch 62: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9338 - loss: 0.3851 - val_accuracy: 0.9750 - val_loss: 0.3366 - learning_rate: 1.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9316 - loss: 0.3935\n",
      "Epoch 63: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9279 - loss: 0.3793 - val_accuracy: 0.9667 - val_loss: 0.3166 - learning_rate: 1.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9320 - loss: 0.3651\n",
      "Epoch 64: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9368 - loss: 0.3660 - val_accuracy: 0.9750 - val_loss: 0.3106 - learning_rate: 1.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9497 - loss: 0.3629\n",
      "Epoch 65: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9390 - loss: 0.3701 - val_accuracy: 0.9750 - val_loss: 0.3147 - learning_rate: 1.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9469 - loss: 0.3439\n",
      "Epoch 66: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9404 - loss: 0.3578 - val_accuracy: 0.9667 - val_loss: 0.3003 - learning_rate: 1.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9270 - loss: 0.3711\n",
      "Epoch 67: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9316 - loss: 0.3733 - val_accuracy: 0.9750 - val_loss: 0.3209 - learning_rate: 1.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9365 - loss: 0.3779\n",
      "Epoch 68: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9368 - loss: 0.3732 - val_accuracy: 0.9667 - val_loss: 0.3073 - learning_rate: 1.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9487 - loss: 0.3391\n",
      "Epoch 69: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9529 - loss: 0.3286 - val_accuracy: 0.9708 - val_loss: 0.2919 - learning_rate: 1.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9408 - loss: 0.3603\n",
      "Epoch 70: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9346 - loss: 0.3662 - val_accuracy: 0.9750 - val_loss: 0.2883 - learning_rate: 1.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9319 - loss: 0.3956\n",
      "Epoch 71: val_accuracy improved from 0.97917 to 0.98333, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9279 - loss: 0.3755 - val_accuracy: 0.9833 - val_loss: 0.2769 - learning_rate: 1.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9336 - loss: 0.3452\n",
      "Epoch 72: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9279 - loss: 0.3449 - val_accuracy: 0.9792 - val_loss: 0.2963 - learning_rate: 1.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9337 - loss: 0.3727\n",
      "Epoch 73: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9471 - loss: 0.3401 - val_accuracy: 0.9792 - val_loss: 0.2681 - learning_rate: 1.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9530 - loss: 0.3184\n",
      "Epoch 74: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9551 - loss: 0.3143 - val_accuracy: 0.9708 - val_loss: 0.2883 - learning_rate: 1.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9549 - loss: 0.3201\n",
      "Epoch 75: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9485 - loss: 0.3329 - val_accuracy: 0.9792 - val_loss: 0.2794 - learning_rate: 1.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9331 - loss: 0.3196\n",
      "Epoch 76: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9449 - loss: 0.3149 - val_accuracy: 0.9750 - val_loss: 0.2658 - learning_rate: 1.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9513 - loss: 0.3161\n",
      "Epoch 77: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9507 - loss: 0.3151 - val_accuracy: 0.9625 - val_loss: 0.3119 - learning_rate: 1.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9602 - loss: 0.3060\n",
      "Epoch 78: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9529 - loss: 0.3098 - val_accuracy: 0.9750 - val_loss: 0.2710 - learning_rate: 1.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9246 - loss: 0.3201\n",
      "Epoch 79: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9471 - loss: 0.3183 - val_accuracy: 0.9750 - val_loss: 0.2530 - learning_rate: 1.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9471 - loss: 0.3138\n",
      "Epoch 80: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9500 - loss: 0.3148 - val_accuracy: 0.9750 - val_loss: 0.2418 - learning_rate: 1.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9626 - loss: 0.2993\n",
      "Epoch 81: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9581 - loss: 0.2941 - val_accuracy: 0.9750 - val_loss: 0.2397 - learning_rate: 1.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9553 - loss: 0.2920\n",
      "Epoch 82: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9574 - loss: 0.2970 - val_accuracy: 0.9708 - val_loss: 0.2401 - learning_rate: 1.0000e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9467 - loss: 0.2952\n",
      "Epoch 83: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9588 - loss: 0.2798 - val_accuracy: 0.9750 - val_loss: 0.2369 - learning_rate: 1.0000e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9502 - loss: 0.2999\n",
      "Epoch 84: val_accuracy improved from 0.98333 to 0.98750, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9419 - loss: 0.3213 - val_accuracy: 0.9875 - val_loss: 0.2358 - learning_rate: 1.0000e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9583 - loss: 0.3035\n",
      "Epoch 85: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9500 - loss: 0.3110 - val_accuracy: 0.9792 - val_loss: 0.2362 - learning_rate: 1.0000e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9611 - loss: 0.2935\n",
      "Epoch 86: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9596 - loss: 0.2864 - val_accuracy: 0.9750 - val_loss: 0.2345 - learning_rate: 1.0000e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9579 - loss: 0.2847\n",
      "Epoch 87: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9588 - loss: 0.2785 - val_accuracy: 0.9792 - val_loss: 0.2259 - learning_rate: 1.0000e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9670 - loss: 0.2675\n",
      "Epoch 88: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9588 - loss: 0.2676 - val_accuracy: 0.9833 - val_loss: 0.2124 - learning_rate: 1.0000e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9579 - loss: 0.3098\n",
      "Epoch 89: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9507 - loss: 0.2984 - val_accuracy: 0.9750 - val_loss: 0.2774 - learning_rate: 1.0000e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9514 - loss: 0.2718\n",
      "Epoch 90: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9515 - loss: 0.2784 - val_accuracy: 0.9875 - val_loss: 0.2147 - learning_rate: 1.0000e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9628 - loss: 0.2541\n",
      "Epoch 91: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9610 - loss: 0.2739 - val_accuracy: 0.9750 - val_loss: 0.2214 - learning_rate: 1.0000e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9498 - loss: 0.2917\n",
      "Epoch 92: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9529 - loss: 0.2864 - val_accuracy: 0.9750 - val_loss: 0.2254 - learning_rate: 1.0000e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9654 - loss: 0.2635\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 93: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9618 - loss: 0.2683 - val_accuracy: 0.9750 - val_loss: 0.2376 - learning_rate: 1.0000e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9559 - loss: 0.2686\n",
      "Epoch 94: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9574 - loss: 0.2671 - val_accuracy: 0.9750 - val_loss: 0.2309 - learning_rate: 5.0000e-05\n",
      "Epoch 95/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9725 - loss: 0.2486\n",
      "Epoch 95: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9654 - loss: 0.2594 - val_accuracy: 0.9750 - val_loss: 0.2288 - learning_rate: 5.0000e-05\n",
      "Epoch 96/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9594 - loss: 0.2589\n",
      "Epoch 96: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9581 - loss: 0.2676 - val_accuracy: 0.9750 - val_loss: 0.2167 - learning_rate: 5.0000e-05\n",
      "Epoch 97/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9615 - loss: 0.2453\n",
      "Epoch 97: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9691 - loss: 0.2426 - val_accuracy: 0.9750 - val_loss: 0.2212 - learning_rate: 5.0000e-05\n",
      "Epoch 98/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9620 - loss: 0.2704\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 98: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9632 - loss: 0.2651 - val_accuracy: 0.9750 - val_loss: 0.2162 - learning_rate: 5.0000e-05\n",
      "Epoch 99/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9752 - loss: 0.2491\n",
      "Epoch 99: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9706 - loss: 0.2531 - val_accuracy: 0.9750 - val_loss: 0.2193 - learning_rate: 2.5000e-05\n",
      "Epoch 100/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9697 - loss: 0.2343\n",
      "Epoch 100: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9662 - loss: 0.2437 - val_accuracy: 0.9750 - val_loss: 0.2120 - learning_rate: 2.5000e-05\n",
      "Epoch 101/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9610 - loss: 0.2887\n",
      "Epoch 101: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9603 - loss: 0.2775 - val_accuracy: 0.9750 - val_loss: 0.2093 - learning_rate: 2.5000e-05\n",
      "Epoch 102/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9632 - loss: 0.2454\n",
      "Epoch 102: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9699 - loss: 0.2463 - val_accuracy: 0.9750 - val_loss: 0.2106 - learning_rate: 2.5000e-05\n",
      "Epoch 103/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9760 - loss: 0.2467\n",
      "Epoch 103: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.9706 - loss: 0.2520 - val_accuracy: 0.9833 - val_loss: 0.2038 - learning_rate: 2.5000e-05\n",
      "Epoch 104/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9613 - loss: 0.2467\n",
      "Epoch 104: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9625 - loss: 0.2492 - val_accuracy: 0.9750 - val_loss: 0.2052 - learning_rate: 2.5000e-05\n",
      "Epoch 105/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9678 - loss: 0.2352\n",
      "Epoch 105: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9632 - loss: 0.2453 - val_accuracy: 0.9792 - val_loss: 0.2025 - learning_rate: 2.5000e-05\n",
      "Epoch 106/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9691 - loss: 0.2736\n",
      "Epoch 106: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9699 - loss: 0.2619 - val_accuracy: 0.9750 - val_loss: 0.2048 - learning_rate: 2.5000e-05\n",
      "Epoch 107/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9643 - loss: 0.2576\n",
      "Epoch 107: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9706 - loss: 0.2443 - val_accuracy: 0.9750 - val_loss: 0.2015 - learning_rate: 2.5000e-05\n",
      "Epoch 108/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9738 - loss: 0.2379\n",
      "Epoch 108: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9728 - loss: 0.2411 - val_accuracy: 0.9833 - val_loss: 0.1978 - learning_rate: 2.5000e-05\n",
      "Epoch 109/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9685 - loss: 0.2502\n",
      "Epoch 109: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9676 - loss: 0.2477 - val_accuracy: 0.9792 - val_loss: 0.1993 - learning_rate: 2.5000e-05\n",
      "Epoch 110/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9703 - loss: 0.2521\n",
      "Epoch 110: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9735 - loss: 0.2388 - val_accuracy: 0.9750 - val_loss: 0.2009 - learning_rate: 2.5000e-05\n",
      "Epoch 111/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9700 - loss: 0.2268\n",
      "Epoch 111: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9721 - loss: 0.2313 - val_accuracy: 0.9750 - val_loss: 0.2010 - learning_rate: 2.5000e-05\n",
      "Epoch 112/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9663 - loss: 0.2676\n",
      "Epoch 112: val_accuracy improved from 0.98750 to 0.99167, saving model to results\\model_fold5.weights.h5\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9669 - loss: 0.2525 - val_accuracy: 0.9917 - val_loss: 0.1918 - learning_rate: 2.5000e-05\n",
      "Epoch 113/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9666 - loss: 0.2357\n",
      "Epoch 113: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9684 - loss: 0.2349 - val_accuracy: 0.9833 - val_loss: 0.1953 - learning_rate: 2.5000e-05\n",
      "Epoch 114/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9718 - loss: 0.2281\n",
      "Epoch 114: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9750 - loss: 0.2431 - val_accuracy: 0.9917 - val_loss: 0.1903 - learning_rate: 2.5000e-05\n",
      "Epoch 115/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9682 - loss: 0.2436\n",
      "Epoch 115: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9699 - loss: 0.2425 - val_accuracy: 0.9917 - val_loss: 0.1917 - learning_rate: 2.5000e-05\n",
      "Epoch 116/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9734 - loss: 0.2301\n",
      "Epoch 116: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9676 - loss: 0.2370 - val_accuracy: 0.9917 - val_loss: 0.1903 - learning_rate: 2.5000e-05\n",
      "Epoch 117/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9707 - loss: 0.2353\n",
      "Epoch 117: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9676 - loss: 0.2446 - val_accuracy: 0.9917 - val_loss: 0.1915 - learning_rate: 2.5000e-05\n",
      "Epoch 118/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9803 - loss: 0.2173\n",
      "Epoch 118: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.9750 - loss: 0.2224 - val_accuracy: 0.9917 - val_loss: 0.1921 - learning_rate: 2.5000e-05\n",
      "Epoch 119/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9661 - loss: 0.2422\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 119: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9721 - loss: 0.2438 - val_accuracy: 0.9875 - val_loss: 0.1929 - learning_rate: 2.5000e-05\n",
      "Epoch 120/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9712 - loss: 0.2182\n",
      "Epoch 120: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9757 - loss: 0.2221 - val_accuracy: 0.9833 - val_loss: 0.1921 - learning_rate: 1.2500e-05\n",
      "Epoch 121/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9645 - loss: 0.2473\n",
      "Epoch 121: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9721 - loss: 0.2412 - val_accuracy: 0.9833 - val_loss: 0.1921 - learning_rate: 1.2500e-05\n",
      "Epoch 122/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9824 - loss: 0.2189\n",
      "Epoch 122: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9794 - loss: 0.2258 - val_accuracy: 0.9917 - val_loss: 0.1870 - learning_rate: 1.2500e-05\n",
      "Epoch 123/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9644 - loss: 0.2400\n",
      "Epoch 123: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9684 - loss: 0.2334 - val_accuracy: 0.9917 - val_loss: 0.1879 - learning_rate: 1.2500e-05\n",
      "Epoch 124/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9786 - loss: 0.2160\n",
      "Epoch 124: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9779 - loss: 0.2194 - val_accuracy: 0.9917 - val_loss: 0.1883 - learning_rate: 1.2500e-05\n",
      "Epoch 125/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9638 - loss: 0.2455\n",
      "Epoch 125: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9647 - loss: 0.2424 - val_accuracy: 0.9917 - val_loss: 0.1873 - learning_rate: 1.2500e-05\n",
      "Epoch 126/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9711 - loss: 0.2413\n",
      "Epoch 126: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9706 - loss: 0.2285 - val_accuracy: 0.9917 - val_loss: 0.1891 - learning_rate: 1.2500e-05\n",
      "Epoch 127/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9792 - loss: 0.2212\n",
      "Epoch 127: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 127: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9684 - loss: 0.2388 - val_accuracy: 0.9917 - val_loss: 0.1883 - learning_rate: 1.2500e-05\n",
      "Epoch 128/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9767 - loss: 0.2309\n",
      "Epoch 128: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9728 - loss: 0.2430 - val_accuracy: 0.9917 - val_loss: 0.1889 - learning_rate: 6.2500e-06\n",
      "Epoch 129/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9822 - loss: 0.2216\n",
      "Epoch 129: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9728 - loss: 0.2319 - val_accuracy: 0.9917 - val_loss: 0.1895 - learning_rate: 6.2500e-06\n",
      "Epoch 130/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9753 - loss: 0.2141\n",
      "Epoch 130: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9735 - loss: 0.2166 - val_accuracy: 0.9917 - val_loss: 0.1892 - learning_rate: 6.2500e-06\n",
      "Epoch 131/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9772 - loss: 0.2328\n",
      "Epoch 131: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9765 - loss: 0.2344 - val_accuracy: 0.9917 - val_loss: 0.1888 - learning_rate: 6.2500e-06\n",
      "Epoch 132/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9838 - loss: 0.2118\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 132: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9809 - loss: 0.2130 - val_accuracy: 0.9917 - val_loss: 0.1884 - learning_rate: 6.2500e-06\n",
      "Epoch 133/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9789 - loss: 0.2274\n",
      "Epoch 133: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9787 - loss: 0.2300 - val_accuracy: 0.9917 - val_loss: 0.1881 - learning_rate: 3.1250e-06\n",
      "Epoch 134/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9765 - loss: 0.2350\n",
      "Epoch 134: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9728 - loss: 0.2292 - val_accuracy: 0.9917 - val_loss: 0.1890 - learning_rate: 3.1250e-06\n",
      "Epoch 135/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9691 - loss: 0.2326\n",
      "Epoch 135: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9676 - loss: 0.2420 - val_accuracy: 0.9917 - val_loss: 0.1878 - learning_rate: 3.1250e-06\n",
      "Epoch 136/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9697 - loss: 0.2264\n",
      "Epoch 136: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9743 - loss: 0.2236 - val_accuracy: 0.9917 - val_loss: 0.1879 - learning_rate: 3.1250e-06\n",
      "Epoch 137/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9770 - loss: 0.2355\n",
      "Epoch 137: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 137: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9779 - loss: 0.2309 - val_accuracy: 0.9917 - val_loss: 0.1875 - learning_rate: 3.1250e-06\n",
      "Epoch 138/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9706 - loss: 0.2293\n",
      "Epoch 138: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9699 - loss: 0.2466 - val_accuracy: 0.9917 - val_loss: 0.1884 - learning_rate: 1.5625e-06\n",
      "Epoch 139/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9818 - loss: 0.2195\n",
      "Epoch 139: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9794 - loss: 0.2224 - val_accuracy: 0.9917 - val_loss: 0.1874 - learning_rate: 1.5625e-06\n",
      "Epoch 140/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9716 - loss: 0.2297\n",
      "Epoch 140: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9735 - loss: 0.2303 - val_accuracy: 0.9917 - val_loss: 0.1873 - learning_rate: 1.5625e-06\n",
      "Epoch 141/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9657 - loss: 0.2212\n",
      "Epoch 141: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9750 - loss: 0.2224 - val_accuracy: 0.9917 - val_loss: 0.1874 - learning_rate: 1.5625e-06\n",
      "Epoch 142/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9779 - loss: 0.2136\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 142: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9750 - loss: 0.2250 - val_accuracy: 0.9917 - val_loss: 0.1876 - learning_rate: 1.5625e-06\n",
      "Epoch 143/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9642 - loss: 0.2356\n",
      "Epoch 143: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9669 - loss: 0.2328 - val_accuracy: 0.9917 - val_loss: 0.1875 - learning_rate: 7.8125e-07\n",
      "Epoch 144/150\n",
      "\u001b[1m113/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9753 - loss: 0.2402\n",
      "Epoch 144: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9794 - loss: 0.2285 - val_accuracy: 0.9917 - val_loss: 0.1873 - learning_rate: 7.8125e-07\n",
      "Epoch 145/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9781 - loss: 0.2249\n",
      "Epoch 145: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9787 - loss: 0.2236 - val_accuracy: 0.9917 - val_loss: 0.1871 - learning_rate: 7.8125e-07\n",
      "Epoch 146/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9735 - loss: 0.2317\n",
      "Epoch 146: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9765 - loss: 0.2238 - val_accuracy: 0.9917 - val_loss: 0.1879 - learning_rate: 7.8125e-07\n",
      "Epoch 147/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9716 - loss: 0.2286\n",
      "Epoch 147: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 147: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9728 - loss: 0.2298 - val_accuracy: 0.9917 - val_loss: 0.1875 - learning_rate: 7.8125e-07\n",
      "Epoch 147: early stopping\n",
      "Restoring model weights from the end of the best epoch: 122.\n",
      "\n",
      "âœ… Fold 5 Results:\n",
      "  Test Accuracy: 0.9750\n",
      "  Test AUC: 0.9895\n",
      "  Test Loss: 0.2185\n",
      "\n",
      "Fold 5 Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "ALL (NORMAL+INTERICTAL)     0.9814    0.9875    0.9844       320\n",
      "        ICTAL (SEIZURE)     0.9487    0.9250    0.9367        80\n",
      "\n",
      "               accuracy                         0.9750       400\n",
      "              macro avg     0.9650    0.9563    0.9606       400\n",
      "           weighted avg     0.9748    0.9750    0.9749       400\n",
      "\n",
      "\n",
      "============================================================\n",
      " CROSS-VALIDATION SUMMARY\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Mean Test Accuracy across folds: 0.9825 (Â±0.0074)\n",
      "ğŸ“Š Mean Test AUC across folds: 0.9945 (Â±0.0063)\n",
      "\n",
      "ğŸ“‹ Fold-wise Metrics Summary:\n",
      "\n",
      "ğŸ”¸ Fold 1 Metrics:\n",
      "  Train Accuracy : 0.9765\n",
      "  Val Accuracy   : 0.9917\n",
      "  Test Accuracy  : 0.9850\n",
      "  Test Loss      : 0.1802\n",
      "  Precision      : 0.9853\n",
      "  Recall         : 0.9850\n",
      "  F1 Score       : 0.9848\n",
      "  Test AUC       : 0.9991\n",
      "\n",
      "ğŸ”¸ Fold 2 Metrics:\n",
      "  Train Accuracy : 0.9728\n",
      "  Val Accuracy   : 0.9833\n",
      "  Test Accuracy  : 0.9725\n",
      "  Test Loss      : 0.3679\n",
      "  Precision      : 0.9729\n",
      "  Recall         : 0.9725\n",
      "  F1 Score       : 0.9719\n",
      "  Test AUC       : 0.9845\n",
      "\n",
      "ğŸ”¸ Fold 3 Metrics:\n",
      "  Train Accuracy : 0.9824\n",
      "  Val Accuracy   : 1.0000\n",
      "  Test Accuracy  : 0.9900\n",
      "  Test Loss      : 0.1866\n",
      "  Precision      : 0.9901\n",
      "  Recall         : 0.9900\n",
      "  F1 Score       : 0.9899\n",
      "  Test AUC       : 0.9996\n",
      "\n",
      "ğŸ”¸ Fold 4 Metrics:\n",
      "  Train Accuracy : 0.9846\n",
      "  Val Accuracy   : 0.9958\n",
      "  Test Accuracy  : 0.9900\n",
      "  Test Loss      : 0.1674\n",
      "  Precision      : 0.9900\n",
      "  Recall         : 0.9900\n",
      "  F1 Score       : 0.9900\n",
      "  Test AUC       : 0.9996\n",
      "\n",
      "ğŸ”¸ Fold 5 Metrics:\n",
      "  Train Accuracy : 0.9809\n",
      "  Val Accuracy   : 0.9917\n",
      "  Test Accuracy  : 0.9750\n",
      "  Test Loss      : 0.2185\n",
      "  Precision      : 0.9748\n",
      "  Recall         : 0.9750\n",
      "  F1 Score       : 0.9749\n",
      "  Test AUC       : 0.9895\n",
      "\n",
      "ğŸ’¾ Best model (Fold 3) saved as 'results/best_model.keras'\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D, MaxPooling1D, Dense, Dropout, BatchNormalization, \n",
    "    GlobalAveragePooling1D, Input, Activation, SpatialDropout1D, \n",
    "    LSTM, Bidirectional, Multiply, Reshape, LeakyReLU\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# ===================== DATA AUGMENTATION =====================\n",
    "def augment_signal(segment, augmentation_prob=0.5):\n",
    "    \"\"\"\n",
    "    Apply random augmentation to EEG segment\n",
    "    \n",
    "    Args:\n",
    "        segment: Input EEG segment (1D array)\n",
    "        augmentation_prob: Probability of applying augmentation\n",
    "    \n",
    "    Returns:\n",
    "        Augmented segment\n",
    "    \"\"\"\n",
    "    if np.random.random() > augmentation_prob:\n",
    "        return segment  # No augmentation\n",
    "    \n",
    "    # Choose augmentation type\n",
    "    aug_type = np.random.choice(['noise', 'scale', 'shift', 'time_shift'], p=[0.3, 0.3, 0.2, 0.2])\n",
    "    \n",
    "    if aug_type == 'noise':\n",
    "        # Add Gaussian noise\n",
    "        noise_level = np.random.uniform(0.01, 0.05)\n",
    "        noise = np.random.normal(0, noise_level, segment.shape)\n",
    "        return segment + noise\n",
    "    \n",
    "    elif aug_type == 'scale':\n",
    "        # Random amplitude scaling\n",
    "        scale = np.random.uniform(0.9, 1.1)\n",
    "        return segment * scale\n",
    "    \n",
    "    elif aug_type == 'shift':\n",
    "        # Random DC shift\n",
    "        shift = np.random.uniform(-0.1, 0.1)\n",
    "        return segment + shift\n",
    "    \n",
    "    elif aug_type == 'time_shift':\n",
    "        # Random time shift (circular shift)\n",
    "        shift_amount = np.random.randint(-20, 20)\n",
    "        return np.roll(segment, shift_amount)\n",
    "    \n",
    "    return segment\n",
    "\n",
    "\n",
    "def augment_batch(X_batch, y_batch, augmentation_prob=0.5):\n",
    "    \"\"\"\n",
    "    Apply augmentation to a batch of data\n",
    "    \n",
    "    Args:\n",
    "        X_batch: Batch of EEG segments (batch_size, time_steps, channels)\n",
    "        y_batch: Batch of labels (1 = ICTAL, 0 = ALL)\n",
    "        augmentation_prob: Probability of applying augmentation\n",
    "    \n",
    "    Returns:\n",
    "        Augmented batch\n",
    "    \"\"\"\n",
    "    X_augmented = np.zeros_like(X_batch)\n",
    "    \n",
    "    for i in range(len(X_batch)):\n",
    "        # Augment ICTAL class (minority) more aggressively\n",
    "        if y_batch[i] == 1:  # ICTAL (seizure)\n",
    "            prob = augmentation_prob * 1.5  # Higher probability for minority class\n",
    "        else:  # ALL (NORMAL + INTERICTAL)\n",
    "            prob = augmentation_prob\n",
    "        \n",
    "        X_augmented[i, :, 0] = augment_signal(X_batch[i, :, 0], prob)\n",
    "    \n",
    "    return X_augmented\n",
    "\n",
    "\n",
    "# ===================== CUSTOM DATA GENERATOR =====================\n",
    "class AugmentedDataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Custom data generator with real-time augmentation\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size=32, augmentation_prob=0.5, shuffle=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.augmentation_prob = augmentation_prob\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        start_idx = index * self.batch_size\n",
    "        end_idx = min((index + 1) * self.batch_size, len(self.X))\n",
    "        batch_indices = self.indices[start_idx:end_idx]\n",
    "        \n",
    "        # Get batch data\n",
    "        X_batch = self.X[batch_indices].copy()\n",
    "        y_batch = self.y[batch_indices]\n",
    "        \n",
    "        # Apply augmentation\n",
    "        X_batch = augment_batch(X_batch, y_batch, self.augmentation_prob)\n",
    "        \n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "\n",
    "# ===================== SE BLOCK IMPLEMENTATION =====================\n",
    "class SEBlock(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation Block for channel attention\n",
    "    Paper: \"Interpretable classification of epileptic EEG signals...\"\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction=8, **kwargs):\n",
    "        super(SEBlock, self).__init__(**kwargs)\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        channels = input_shape[-1]\n",
    "        self.squeeze = GlobalAveragePooling1D()\n",
    "        \n",
    "        # Excitation network\n",
    "        self.fc1 = Dense(\n",
    "            channels // self.reduction, \n",
    "            activation='relu', \n",
    "            kernel_initializer='he_normal'\n",
    "        )\n",
    "        self.fc2 = Dense(\n",
    "            channels, \n",
    "            activation='sigmoid', \n",
    "            kernel_initializer='he_normal'\n",
    "        )\n",
    "        \n",
    "        super(SEBlock, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Squeeze: Global average pooling\n",
    "        squeeze = self.squeeze(inputs)\n",
    "        \n",
    "        # Excitation: Learn channel importance\n",
    "        excitation = self.fc1(squeeze)\n",
    "        excitation = self.fc2(excitation)\n",
    "        \n",
    "        # Reshape for broadcasting\n",
    "        excitation = tf.reshape(excitation, [-1, 1, tf.shape(inputs)[-1]])\n",
    "        \n",
    "        # Scale: Multiply input with learned weights\n",
    "        return Multiply()([inputs, excitation])\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(SEBlock, self).get_config()\n",
    "        config.update({\"reduction\": self.reduction})\n",
    "        return config\n",
    "\n",
    "\n",
    "# ===================== LOAD DATA =====================\n",
    "data_dir = os.path.join(\"preprocessed\")\n",
    "X = np.load(os.path.join(data_dir, \"ALL_X.npy\"))\n",
    "y = np.load(os.path.join(data_dir, \"ALL_y.npy\"))\n",
    "\n",
    "# Convert to Binary Classification: ICTAL (1) vs ALL (0)\n",
    "# ICTAL = seizure (minority class)\n",
    "# ALL = NORMAL + INTERICTAL (majority class)\n",
    "y_encoded = np.where(y == 'ICTAL', 1, 0)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BINARY CLASSIFICATION SETUP\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original classes: {np.unique(y)}\")\n",
    "print(f\"Binary encoding: 1 (ICTAL) vs 0 (ALL: NORMAL+INTERICTAL)\")\n",
    "print(f\"Binary labels distribution: {dict(zip(*np.unique(y_encoded, return_counts=True)[::-1]))}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare Data\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "\n",
    "# Compute Class Weights with stronger emphasis on minority class\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_encoded), y=y_encoded)\n",
    "# Boost minority class (ICTAL) weight even more\n",
    "class_weights[1] = class_weights[1] * 1.5  # 50% increase for ICTAL\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "print(f\"Class weights (adjusted): {class_weight_dict}\")\n",
    "\n",
    "# ===================== PREPARE CROSS VALIDATION =====================\n",
    "random_state = np.random.randint(0, 10000)\n",
    "print(f\"ğŸ² Random state used for this run: {random_state}\")\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "fold_indices = [(train_val_idx, test_idx) for train_val_idx, test_idx in kfold.split(X, y_encoded)]\n",
    "\n",
    "# Save indices for reproducibility\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "np.save(os.path.join(\"results\", \"fold_indices.npy\"), np.array(fold_indices, dtype=object), allow_pickle=True)\n",
    "\n",
    "\n",
    "# ===================== LOSS FUNCTIONS =====================\n",
    "def focal_loss(alpha=0.75, gamma=2.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        cross_entropy = -y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred)\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        focal_term = K.pow(1 - p_t, gamma)\n",
    "        alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        \n",
    "        return K.mean(alpha_t * focal_term * cross_entropy)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def hybrid_focal_loss(alpha=0.75, gamma=1.7, focal_weight=0.55):\n",
    "    \"\"\"Hybrid: Focal + BCE\"\"\"\n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        bce = -y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred)\n",
    "        \n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        focal_term = K.pow(1 - p_t, gamma)\n",
    "        alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        focal = alpha_t * focal_term * bce\n",
    "        \n",
    "        combined = focal_weight * focal + (1 - focal_weight) * bce\n",
    "        return K.mean(combined)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "# ===================== MODEL BUILDING =====================\n",
    "def build_model(input_shape):\n",
    "    \"\"\"\n",
    "    MODIFIED MODEL:\n",
    "    - Added 4th CNN block\n",
    "    - Changed Bidirectional LSTM to regular LSTM\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # ========== Block 1: Local patterns ==========\n",
    "    x = Conv1D(48, kernel_size=7, padding='same', kernel_regularizer=l2(0.002))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = SEBlock(reduction=8)(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = SpatialDropout1D(0.28)(x)\n",
    "    \n",
    "    # ========== Block 2: Mid-level features ==========\n",
    "    x = Conv1D(96, kernel_size=5, padding='same', kernel_regularizer=l2(0.002))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = SEBlock(reduction=8)(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = SpatialDropout1D(0.32)(x)\n",
    "    \n",
    "    # ========== Block 3: High-level features ==========\n",
    "    x = Conv1D(128, kernel_size=3, padding='same', kernel_regularizer=l2(0.002))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = SEBlock(reduction=8)(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = SpatialDropout1D(0.38)(x)\n",
    "    \n",
    "    # ========== Block 4: Deep features (NEW LAYER) ==========\n",
    "    x = Conv1D(160, kernel_size=3, padding='same', kernel_regularizer=l2(0.002))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = SEBlock(reduction=8)(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = SpatialDropout1D(0.38)(x)\n",
    "    \n",
    "    # ========== LSTM Temporal Modeling (Changed from Bidirectional to regular LSTM) ==========\n",
    "    x = LSTM(64, return_sequences=False, kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    # ========== Dense Classification ==========\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.003))(x)\n",
    "    x = Dropout(0.48)(x)\n",
    "    \n",
    "    x = Dense(32, activation='relu', kernel_regularizer=l2(0.003))(x)\n",
    "    x = Dropout(0.48)(x)\n",
    "    \n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ===================== TRAINING =====================\n",
    "USE_DATA_AUGMENTATION = True  \n",
    "\n",
    "acc_per_fold = []\n",
    "auc_per_fold = []\n",
    "conf_matrices = []\n",
    "class_names = ['ALL (NORMAL+INTERICTAL)', 'ICTAL (SEIZURE)']\n",
    "\n",
    "# Track metrics for best model selection\n",
    "fold_metrics = {\n",
    "    'fold_no': [],\n",
    "    'test_acc': [],\n",
    "    'test_loss': [],\n",
    "    'test_auc': [],\n",
    "    'val_acc': [],\n",
    "    'train_acc': [],\n",
    "    'f1_score': [],\n",
    "    'precision': [],\n",
    "    'recall': []\n",
    "}\n",
    "best_model = None\n",
    "best_fold = None\n",
    "best_acc = 0\n",
    "\n",
    "\n",
    "for fold_no, (train_val_idx, test_idx) in enumerate(fold_indices, start=1):\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\" FOLD {fold_no}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Split into train/val/test\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y_encoded[train_val_idx], y_encoded[test_idx]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.15, stratify=y_train_val, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "    print(f\"Test set distribution: {dict(zip(*np.unique(y_test, return_counts=True)[::-1]))}\")\n",
    "\n",
    "    # Build model\n",
    "    model = build_model(input_shape=(X.shape[1], 1))\n",
    "    \n",
    "    # Print model summary only for first fold\n",
    "    if fold_no == 1:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"MODEL ARCHITECTURE\")\n",
    "        print(\"=\"*60)\n",
    "        model.summary()\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Compile with adjusted hyperparameters\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-4),  # Increased learning rate\n",
    "        loss=hybrid_focal_loss(alpha=0.80, gamma=2.0, focal_weight=0.7),  # More aggressive focal loss\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Callbacks \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=25, \n",
    "        restore_best_weights=True, \n",
    "        verbose=1, \n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,  # More aggressive reduction\n",
    "        patience=5,  # Reduce faster\n",
    "        min_lr=1e-7,\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        os.path.join(\"results\", f\"model_fold{fold_no}.weights.h5\"),\n",
    "        monitor='val_accuracy', \n",
    "        save_best_only=True, \n",
    "        save_weights_only=True,\n",
    "        verbose=1,  # Changed to 1 for better monitoring\n",
    "        mode='max'\n",
    "    )\n",
    "    \n",
    "    callbacks = [early_stop, reduce_lr, checkpoint]\n",
    "    \n",
    "    # Train Model\n",
    "    print(f\"\\nğŸš€ Training Fold {fold_no}...\")\n",
    "    \n",
    "    if USE_DATA_AUGMENTATION:\n",
    "        print(\"ğŸ“Š Using data augmentation with real-time generator\")\n",
    "        \n",
    "        # Create data generators\n",
    "        train_generator = AugmentedDataGenerator(\n",
    "            X_train, y_train, \n",
    "            batch_size=12, \n",
    "            augmentation_prob=0.55,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        # Note: Validation data is NOT augmented\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=150,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=callbacks,\n",
    "            class_weight=class_weight_dict,\n",
    "            verbose=1\n",
    "        )\n",
    "    else:\n",
    "        print(\"ğŸ“Š Training without data augmentation\")\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=150,\n",
    "            batch_size=32,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=callbacks,\n",
    "            class_weight=class_weight_dict,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    # Load best weights\n",
    "    model.load_weights(os.path.join(\"results\", f\"model_fold{fold_no}.weights.h5\"))\n",
    "\n",
    "    # Evaluate\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    acc_per_fold.append(test_acc)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_prob = model.predict(X_test, verbose=0)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # AUC Score\n",
    "    test_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    auc_per_fold.append(test_auc)\n",
    "    \n",
    "    print(f\"\\nâœ… Fold {fold_no} Results:\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  Test AUC: {test_auc:.4f}\")\n",
    "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrices.append(cm)\n",
    "    \n",
    "    # Classification Metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Store metrics\n",
    "    fold_metrics['fold_no'].append(fold_no)\n",
    "    fold_metrics['test_acc'].append(test_acc)\n",
    "    fold_metrics['test_loss'].append(test_loss)\n",
    "    fold_metrics['test_auc'].append(test_auc)\n",
    "    fold_metrics['val_acc'].append(max(history.history['val_accuracy']))\n",
    "    fold_metrics['train_acc'].append(max(history.history['accuracy']))\n",
    "    fold_metrics['f1_score'].append(f1)\n",
    "    fold_metrics['precision'].append(precision)\n",
    "    fold_metrics['recall'].append(recall)\n",
    "    \n",
    "    # Check if this is the best model\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        best_fold = fold_no\n",
    "        best_model = model\n",
    "        best_cm = cm\n",
    "        best_y_test = y_test\n",
    "        best_y_pred = y_pred\n",
    "        best_y_pred_prob = y_pred_prob\n",
    "        print(f\"ğŸŒŸ New best model! Fold {fold_no} with accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    print(f\"\\nFold {fold_no} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                annot_kws={'size': 14})\n",
    "    plt.title(f\"Fold {fold_no} Confusion Matrix\\nAcc: {test_acc:.4f} | AUC: {test_auc:.4f}\", \n",
    "              fontsize=14)\n",
    "    plt.xlabel(\"Predicted\", fontsize=12)\n",
    "    plt.ylabel(\"True\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(\"results\", f\"confusion_fold{fold_no}.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Training History \n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "    plt.axhline(y=test_acc, color='r', linestyle='--', label=f'Test Acc: {test_acc:.4f}')\n",
    "    plt.title(f'Fold {fold_no} - Model Accuracy', fontsize=13)\n",
    "    plt.xlabel('Epoch', fontsize=11)\n",
    "    plt.ylabel('Accuracy', fontsize=11)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    plt.title(f'Fold {fold_no} - Model Loss', fontsize=13)\n",
    "    plt.xlabel('Epoch', fontsize=11)\n",
    "    plt.ylabel('Loss', fontsize=11)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(\"results\", f\"training_history_fold{fold_no}.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ===================== SUMMARY =====================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" CROSS-VALIDATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nğŸ“Š Mean Test Accuracy across folds: {np.mean(acc_per_fold):.4f} (Â±{np.std(acc_per_fold):.4f})\")\n",
    "print(f\"ğŸ“Š Mean Test AUC across folds: {np.mean(auc_per_fold):.4f} (Â±{np.std(auc_per_fold):.4f})\")\n",
    "\n",
    "# Combine confusion matrices\n",
    "total_cm = np.sum(conf_matrices, axis=0)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(total_cm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            annot_kws={'size': 14})\n",
    "plt.title(\"Overall Confusion Matrix (All Folds)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(\"results\", \"confusion_overall.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Print Fold Metrics\n",
    "print(\"\\nğŸ“‹ Fold-wise Metrics Summary:\")\n",
    "for i in range(len(fold_metrics['fold_no'])):\n",
    "    print(f\"\\nğŸ”¸ Fold {fold_metrics['fold_no'][i]} Metrics:\")\n",
    "    print(f\"  Train Accuracy : {fold_metrics['train_acc'][i]:.4f}\")\n",
    "    print(f\"  Val Accuracy   : {fold_metrics['val_acc'][i]:.4f}\")\n",
    "    print(f\"  Test Accuracy  : {fold_metrics['test_acc'][i]:.4f}\")\n",
    "    print(f\"  Test Loss      : {fold_metrics['test_loss'][i]:.4f}\")\n",
    "    print(f\"  Precision      : {fold_metrics['precision'][i]:.4f}\")\n",
    "    print(f\"  Recall         : {fold_metrics['recall'][i]:.4f}\")\n",
    "    print(f\"  F1 Score       : {fold_metrics['f1_score'][i]:.4f}\")\n",
    "    print(f\"  Test AUC       : {fold_metrics['test_auc'][i]:.4f}\")\n",
    "\n",
    "# Save best model\n",
    "best_model.save(os.path.join(\"results\", \"best_model.keras\"))\n",
    "print(f\"\\nğŸ’¾ Best model (Fold {best_fold}) saved as 'results/best_model.keras'\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
