{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49321111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original classes: ['ICTAL' 'INTERICTAL' 'NORMAL']\n",
      "Binary classes: 0 (NORMAL) vs 1 (INTERICTAL + ICTAL)\n",
      "Binary labels distribution: (array([0, 1]), array([ 800, 1200], dtype=int64))\n",
      "Dataset shape: (2000, 868, 1)\n",
      "Class weights: {0: 1.25, 1: 0.8333333333333334}\n",
      "ğŸ² Random state used for this run: 2160\n",
      "\n",
      "============================================================\n",
      " FOLD 1\n",
      "============================================================\n",
      "\n",
      "Train: 1360, Val: 240, Test: 400\n",
      "Test set distribution: (array([0, 1]), array([160, 240], dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Fold 1...\n",
      "ğŸ“Š Using data augmentation with real-time generator\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - accuracy: 0.5456 - loss: 1.5634 - val_accuracy: 0.6000 - val_loss: 1.5451 - learning_rate: 5.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.5610 - loss: 1.5425 - val_accuracy: 0.6000 - val_loss: 1.5262 - learning_rate: 5.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.5647 - loss: 1.5293 - val_accuracy: 0.6000 - val_loss: 1.5077 - learning_rate: 5.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.5669 - loss: 1.5160 - val_accuracy: 0.6000 - val_loss: 1.4912 - learning_rate: 5.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.5853 - loss: 1.4983 - val_accuracy: 0.6000 - val_loss: 1.4763 - learning_rate: 5.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.5735 - loss: 1.4823 - val_accuracy: 0.6000 - val_loss: 1.4620 - learning_rate: 5.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.5926 - loss: 1.4642 - val_accuracy: 0.6000 - val_loss: 1.4459 - learning_rate: 5.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.6169 - loss: 1.4459 - val_accuracy: 0.6000 - val_loss: 1.4275 - learning_rate: 5.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.6103 - loss: 1.4295 - val_accuracy: 0.6000 - val_loss: 1.4078 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.5890 - loss: 1.4219 - val_accuracy: 0.6125 - val_loss: 1.3889 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.6066 - loss: 1.3942 - val_accuracy: 0.6125 - val_loss: 1.3717 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.6213 - loss: 1.3797 - val_accuracy: 0.6125 - val_loss: 1.3533 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6463 - loss: 1.3578 - val_accuracy: 0.6333 - val_loss: 1.3419 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6397 - loss: 1.3266 - val_accuracy: 0.6542 - val_loss: 1.3240 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 74ms/step - accuracy: 0.6669 - loss: 1.3138 - val_accuracy: 0.6708 - val_loss: 1.3093 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.6662 - loss: 1.2941 - val_accuracy: 0.6750 - val_loss: 1.3085 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6919 - loss: 1.2730 - val_accuracy: 0.6875 - val_loss: 1.2887 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.7022 - loss: 1.2551 - val_accuracy: 0.7250 - val_loss: 1.2630 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.7243 - loss: 1.2398 - val_accuracy: 0.7458 - val_loss: 1.2244 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.7375 - loss: 1.2176 - val_accuracy: 0.7583 - val_loss: 1.2176 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.7625 - loss: 1.2030 - val_accuracy: 0.7375 - val_loss: 1.2326 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.7706 - loss: 1.1819 - val_accuracy: 0.7708 - val_loss: 1.1920 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.7853 - loss: 1.1579 - val_accuracy: 0.7708 - val_loss: 1.1855 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.7838 - loss: 1.1522 - val_accuracy: 0.7958 - val_loss: 1.1556 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.7816 - loss: 1.1355 - val_accuracy: 0.7500 - val_loss: 1.2201 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.7831 - loss: 1.1319 - val_accuracy: 0.8083 - val_loss: 1.1231 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.7971 - loss: 1.1118 - val_accuracy: 0.8000 - val_loss: 1.1372 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8051 - loss: 1.0951 - val_accuracy: 0.8042 - val_loss: 1.1251 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8154 - loss: 1.0774 - val_accuracy: 0.8042 - val_loss: 1.1199 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8081 - loss: 1.0741 - val_accuracy: 0.8333 - val_loss: 1.0601 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8088 - loss: 1.0735 - val_accuracy: 0.8083 - val_loss: 1.0765 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.8066 - loss: 1.0584 - val_accuracy: 0.8500 - val_loss: 1.0294 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.8066 - loss: 1.0544 - val_accuracy: 0.8417 - val_loss: 1.0251 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.8257 - loss: 1.0355 - val_accuracy: 0.8375 - val_loss: 1.0198 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8279 - loss: 1.0261 - val_accuracy: 0.8417 - val_loss: 1.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8243 - loss: 1.0148 - val_accuracy: 0.8375 - val_loss: 0.9951 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.8294 - loss: 0.9999 - val_accuracy: 0.8500 - val_loss: 0.9676 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8294 - loss: 0.9876 - val_accuracy: 0.8125 - val_loss: 1.0174 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.8176 - loss: 0.9926 - val_accuracy: 0.8583 - val_loss: 0.9487 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8184 - loss: 0.9812 - val_accuracy: 0.8542 - val_loss: 0.9371 - learning_rate: 5.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8228 - loss: 0.9797 - val_accuracy: 0.8542 - val_loss: 0.9314 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8456 - loss: 0.9531 - val_accuracy: 0.8625 - val_loss: 0.9013 - learning_rate: 5.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.8360 - loss: 0.9539 - val_accuracy: 0.8625 - val_loss: 0.9090 - learning_rate: 5.0000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.8471 - loss: 0.9224 - val_accuracy: 0.8667 - val_loss: 0.8797 - learning_rate: 5.0000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.8375 - loss: 0.9380 - val_accuracy: 0.8500 - val_loss: 0.9174 - learning_rate: 5.0000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.8507 - loss: 0.9013 - val_accuracy: 0.8583 - val_loss: 0.8985 - learning_rate: 5.0000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.8478 - loss: 0.8944 - val_accuracy: 0.8625 - val_loss: 0.8631 - learning_rate: 5.0000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8632 - loss: 0.8937 - val_accuracy: 0.8417 - val_loss: 0.8937 - learning_rate: 5.0000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8625 - loss: 0.8806 - val_accuracy: 0.8667 - val_loss: 0.8530 - learning_rate: 5.0000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8559 - loss: 0.8585 - val_accuracy: 0.8792 - val_loss: 0.8172 - learning_rate: 5.0000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8765 - loss: 0.8666 - val_accuracy: 0.8458 - val_loss: 0.8671 - learning_rate: 5.0000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8559 - loss: 0.8566 - val_accuracy: 0.8792 - val_loss: 0.8025 - learning_rate: 5.0000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8456 - loss: 0.8513 - val_accuracy: 0.8833 - val_loss: 0.7911 - learning_rate: 5.0000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8544 - loss: 0.8349 - val_accuracy: 0.8708 - val_loss: 0.8111 - learning_rate: 5.0000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8625 - loss: 0.8222 - val_accuracy: 0.8667 - val_loss: 0.7914 - learning_rate: 5.0000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8581 - loss: 0.8235 - val_accuracy: 0.8875 - val_loss: 0.7682 - learning_rate: 5.0000e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8669 - loss: 0.8099 - val_accuracy: 0.8708 - val_loss: 0.7943 - learning_rate: 5.0000e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8757 - loss: 0.8052 - val_accuracy: 0.8750 - val_loss: 0.7618 - learning_rate: 5.0000e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8625 - loss: 0.7898 - val_accuracy: 0.8833 - val_loss: 0.7480 - learning_rate: 5.0000e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8684 - loss: 0.7946 - val_accuracy: 0.8792 - val_loss: 0.7434 - learning_rate: 5.0000e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8522 - loss: 0.7816 - val_accuracy: 0.8833 - val_loss: 0.7344 - learning_rate: 5.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8625 - loss: 0.7846 - val_accuracy: 0.8875 - val_loss: 0.7185 - learning_rate: 5.0000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8728 - loss: 0.7664 - val_accuracy: 0.8917 - val_loss: 0.7070 - learning_rate: 5.0000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8721 - loss: 0.7778 - val_accuracy: 0.8958 - val_loss: 0.7027 - learning_rate: 5.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8654 - loss: 0.7615 - val_accuracy: 0.8792 - val_loss: 0.7009 - learning_rate: 5.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8794 - loss: 0.7451 - val_accuracy: 0.8875 - val_loss: 0.6956 - learning_rate: 5.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8779 - loss: 0.7380 - val_accuracy: 0.8833 - val_loss: 0.6909 - learning_rate: 5.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8706 - loss: 0.7332 - val_accuracy: 0.8792 - val_loss: 0.6912 - learning_rate: 5.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8816 - loss: 0.7160 - val_accuracy: 0.8875 - val_loss: 0.6807 - learning_rate: 5.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8890 - loss: 0.7092 - val_accuracy: 0.8958 - val_loss: 0.6687 - learning_rate: 5.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8956 - loss: 0.6989 - val_accuracy: 0.9083 - val_loss: 0.6568 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8985 - loss: 0.6871 - val_accuracy: 0.9042 - val_loss: 0.6562 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8838 - loss: 0.6835 - val_accuracy: 0.9042 - val_loss: 0.6508 - learning_rate: 5.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8728 - loss: 0.6906 - val_accuracy: 0.9125 - val_loss: 0.6298 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8882 - loss: 0.6733 - val_accuracy: 0.9083 - val_loss: 0.6272 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8941 - loss: 0.6753 - val_accuracy: 0.9083 - val_loss: 0.6266 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8875 - loss: 0.6705 - val_accuracy: 0.9125 - val_loss: 0.6159 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8985 - loss: 0.6461 - val_accuracy: 0.9167 - val_loss: 0.6123 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8897 - loss: 0.6593 - val_accuracy: 0.9208 - val_loss: 0.5915 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8831 - loss: 0.6488 - val_accuracy: 0.9125 - val_loss: 0.6075 - learning_rate: 5.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8890 - loss: 0.6417 - val_accuracy: 0.9083 - val_loss: 0.5890 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8779 - loss: 0.6452 - val_accuracy: 0.9167 - val_loss: 0.5864 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8956 - loss: 0.6267 - val_accuracy: 0.9333 - val_loss: 0.5869 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8963 - loss: 0.6153 - val_accuracy: 0.9333 - val_loss: 0.5804 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9169 - loss: 0.6062 - val_accuracy: 0.9250 - val_loss: 0.5578 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9037 - loss: 0.6099 - val_accuracy: 0.9250 - val_loss: 0.5588 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8926 - loss: 0.6151 - val_accuracy: 0.9458 - val_loss: 0.5497 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.9029 - loss: 0.5959 - val_accuracy: 0.9458 - val_loss: 0.5457 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9118 - loss: 0.5788 - val_accuracy: 0.9375 - val_loss: 0.5380 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8941 - loss: 0.5877 - val_accuracy: 0.9417 - val_loss: 0.5437 - learning_rate: 5.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8978 - loss: 0.5861 - val_accuracy: 0.9375 - val_loss: 0.5239 - learning_rate: 5.0000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9022 - loss: 0.5803 - val_accuracy: 0.9375 - val_loss: 0.5136 - learning_rate: 5.0000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9147 - loss: 0.5640 - val_accuracy: 0.9333 - val_loss: 0.5099 - learning_rate: 5.0000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9132 - loss: 0.5589 - val_accuracy: 0.9417 - val_loss: 0.5394 - learning_rate: 5.0000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8985 - loss: 0.5699 - val_accuracy: 0.9417 - val_loss: 0.5018 - learning_rate: 5.0000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9132 - loss: 0.5581 - val_accuracy: 0.9333 - val_loss: 0.5001 - learning_rate: 5.0000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9081 - loss: 0.5524 - val_accuracy: 0.9458 - val_loss: 0.4904 - learning_rate: 5.0000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9103 - loss: 0.5562 - val_accuracy: 0.9417 - val_loss: 0.4813 - learning_rate: 5.0000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9037 - loss: 0.5476 - val_accuracy: 0.9458 - val_loss: 0.5017 - learning_rate: 5.0000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9103 - loss: 0.5554 - val_accuracy: 0.9333 - val_loss: 0.4830 - learning_rate: 5.0000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9081 - loss: 0.5463 - val_accuracy: 0.9292 - val_loss: 0.4819 - learning_rate: 5.0000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9257 - loss: 0.5116 - val_accuracy: 0.9333 - val_loss: 0.4807 - learning_rate: 5.0000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9199 - loss: 0.5333 - val_accuracy: 0.9458 - val_loss: 0.4706 - learning_rate: 5.0000e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9184 - loss: 0.5223 - val_accuracy: 0.9500 - val_loss: 0.4646 - learning_rate: 5.0000e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9199 - loss: 0.5146 - val_accuracy: 0.9458 - val_loss: 0.4610 - learning_rate: 5.0000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9176 - loss: 0.5031 - val_accuracy: 0.9458 - val_loss: 0.4796 - learning_rate: 5.0000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.9125 - loss: 0.5091 - val_accuracy: 0.9333 - val_loss: 0.4573 - learning_rate: 5.0000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 135ms/step - accuracy: 0.8985 - loss: 0.5280 - val_accuracy: 0.9625 - val_loss: 0.4604 - learning_rate: 5.0000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.9140 - loss: 0.5092 - val_accuracy: 0.9458 - val_loss: 0.4613 - learning_rate: 5.0000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9162 - loss: 0.4997 - val_accuracy: 0.9417 - val_loss: 0.4508 - learning_rate: 5.0000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9191 - loss: 0.4899 - val_accuracy: 0.9458 - val_loss: 0.4426 - learning_rate: 5.0000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9250 - loss: 0.4924 - val_accuracy: 0.9458 - val_loss: 0.4425 - learning_rate: 5.0000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.9243 - loss: 0.4760 - val_accuracy: 0.9417 - val_loss: 0.4451 - learning_rate: 5.0000e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.9074 - loss: 0.5036 - val_accuracy: 0.9417 - val_loss: 0.4380 - learning_rate: 5.0000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9125 - loss: 0.4949 - val_accuracy: 0.9417 - val_loss: 0.4401 - learning_rate: 5.0000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9096 - loss: 0.4787 - val_accuracy: 0.9417 - val_loss: 0.4356 - learning_rate: 5.0000e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9250 - loss: 0.4693 - val_accuracy: 0.9583 - val_loss: 0.4379 - learning_rate: 5.0000e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9191 - loss: 0.4930 - val_accuracy: 0.9583 - val_loss: 0.4253 - learning_rate: 5.0000e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9176 - loss: 0.4727 - val_accuracy: 0.9458 - val_loss: 0.4235 - learning_rate: 5.0000e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.9191 - loss: 0.4556 - val_accuracy: 0.9458 - val_loss: 0.4180 - learning_rate: 5.0000e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9221 - loss: 0.4522 - val_accuracy: 0.9417 - val_loss: 0.4206 - learning_rate: 5.0000e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9147 - loss: 0.4670 - val_accuracy: 0.9458 - val_loss: 0.4224 - learning_rate: 5.0000e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.9213 - loss: 0.4601 - val_accuracy: 0.9458 - val_loss: 0.4066 - learning_rate: 5.0000e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9169 - loss: 0.4641 - val_accuracy: 0.9458 - val_loss: 0.4059 - learning_rate: 5.0000e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9213 - loss: 0.4535 - val_accuracy: 0.9542 - val_loss: 0.3961 - learning_rate: 5.0000e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9272 - loss: 0.4327 - val_accuracy: 0.9542 - val_loss: 0.3930 - learning_rate: 5.0000e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9360 - loss: 0.4242 - val_accuracy: 0.9542 - val_loss: 0.3996 - learning_rate: 5.0000e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.9125 - loss: 0.4745 - val_accuracy: 0.9583 - val_loss: 0.4198 - learning_rate: 5.0000e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9287 - loss: 0.4385 - val_accuracy: 0.9500 - val_loss: 0.3909 - learning_rate: 5.0000e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.9368 - loss: 0.4207 - val_accuracy: 0.9458 - val_loss: 0.3851 - learning_rate: 5.0000e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9184 - loss: 0.4504 - val_accuracy: 0.9458 - val_loss: 0.3799 - learning_rate: 5.0000e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.9213 - loss: 0.4325 - val_accuracy: 0.9500 - val_loss: 0.3836 - learning_rate: 5.0000e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.9316 - loss: 0.4283 - val_accuracy: 0.9583 - val_loss: 0.3830 - learning_rate: 5.0000e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9368 - loss: 0.4123 - val_accuracy: 0.9500 - val_loss: 0.3811 - learning_rate: 5.0000e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.9346 - loss: 0.4298 - val_accuracy: 0.9458 - val_loss: 0.3806 - learning_rate: 5.0000e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.9272 - loss: 0.4272 - val_accuracy: 0.9250 - val_loss: 0.3982 - learning_rate: 5.0000e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.9324 - loss: 0.4091 - val_accuracy: 0.9500 - val_loss: 0.3769 - learning_rate: 5.0000e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.9375 - loss: 0.4075 - val_accuracy: 0.9500 - val_loss: 0.3780 - learning_rate: 5.0000e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.9360 - loss: 0.4137 - val_accuracy: 0.9542 - val_loss: 0.3805 - learning_rate: 5.0000e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9316 - loss: 0.4113 - val_accuracy: 0.9542 - val_loss: 0.3736 - learning_rate: 5.0000e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.9338 - loss: 0.4068 - val_accuracy: 0.9542 - val_loss: 0.3693 - learning_rate: 5.0000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9316 - loss: 0.4035 - val_accuracy: 0.9542 - val_loss: 0.3596 - learning_rate: 5.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.9316 - loss: 0.3932 - val_accuracy: 0.9583 - val_loss: 0.3537 - learning_rate: 5.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.9338 - loss: 0.3912 - val_accuracy: 0.9500 - val_loss: 0.3524 - learning_rate: 5.0000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.9287 - loss: 0.4114 - val_accuracy: 0.9542 - val_loss: 0.3628 - learning_rate: 5.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.9390 - loss: 0.3869 - val_accuracy: 0.9625 - val_loss: 0.3462 - learning_rate: 5.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.9250 - loss: 0.3899 - val_accuracy: 0.9583 - val_loss: 0.3658 - learning_rate: 5.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.9353 - loss: 0.3816 - val_accuracy: 0.9500 - val_loss: 0.3577 - learning_rate: 5.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.9199 - loss: 0.3959 - val_accuracy: 0.9542 - val_loss: 0.3551 - learning_rate: 5.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.9235 - loss: 0.3860 - val_accuracy: 0.9500 - val_loss: 0.3430 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.9338 - loss: 0.3849 - val_accuracy: 0.9583 - val_loss: 0.3443 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.9331 - loss: 0.3801 - val_accuracy: 0.9500 - val_loss: 0.3439 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.9404 - loss: 0.3862 - val_accuracy: 0.9583 - val_loss: 0.3306 - learning_rate: 5.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.9449 - loss: 0.3686 - val_accuracy: 0.9583 - val_loss: 0.3396 - learning_rate: 5.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.9493 - loss: 0.3582 - val_accuracy: 0.9542 - val_loss: 0.3366 - learning_rate: 5.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.9346 - loss: 0.3753 - val_accuracy: 0.9542 - val_loss: 0.3495 - learning_rate: 5.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.9500 - loss: 0.3534 - val_accuracy: 0.9500 - val_loss: 0.3234 - learning_rate: 5.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.9368 - loss: 0.3606 - val_accuracy: 0.9583 - val_loss: 0.3343 - learning_rate: 5.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.9287 - loss: 0.3675 - val_accuracy: 0.9583 - val_loss: 0.3300 - learning_rate: 5.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.9449 - loss: 0.3583 - val_accuracy: 0.9583 - val_loss: 0.3339 - learning_rate: 5.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.9397 - loss: 0.3657 - val_accuracy: 0.9500 - val_loss: 0.3258 - learning_rate: 5.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.9294 - loss: 0.3601 - val_accuracy: 0.9542 - val_loss: 0.3223 - learning_rate: 5.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.9441 - loss: 0.3509 - val_accuracy: 0.9583 - val_loss: 0.3392 - learning_rate: 5.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.9346 - loss: 0.3651 - val_accuracy: 0.9583 - val_loss: 0.3145 - learning_rate: 5.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.9449 - loss: 0.3412 - val_accuracy: 0.9583 - val_loss: 0.3319 - learning_rate: 5.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.9338 - loss: 0.3553 - val_accuracy: 0.9542 - val_loss: 0.3163 - learning_rate: 5.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.9272 - loss: 0.3536 - val_accuracy: 0.9500 - val_loss: 0.3258 - learning_rate: 5.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.9419 - loss: 0.3544 - val_accuracy: 0.9417 - val_loss: 0.3164 - learning_rate: 5.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.9309 - loss: 0.3472 - val_accuracy: 0.9542 - val_loss: 0.3128 - learning_rate: 5.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.9404 - loss: 0.3480 - val_accuracy: 0.9583 - val_loss: 0.3174 - learning_rate: 5.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.9316 - loss: 0.3563 - val_accuracy: 0.9542 - val_loss: 0.3083 - learning_rate: 5.0000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.9353 - loss: 0.3466 - val_accuracy: 0.9583 - val_loss: 0.3019 - learning_rate: 5.0000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.9301 - loss: 0.3495 - val_accuracy: 0.9542 - val_loss: 0.3070 - learning_rate: 5.0000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9390 - loss: 0.3354 - val_accuracy: 0.9583 - val_loss: 0.3058 - learning_rate: 5.0000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9390 - loss: 0.3481 - val_accuracy: 0.9500 - val_loss: 0.3070 - learning_rate: 5.0000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9485 - loss: 0.3226 - val_accuracy: 0.9625 - val_loss: 0.3179 - learning_rate: 5.0000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9404 - loss: 0.3320 - val_accuracy: 0.9625 - val_loss: 0.2958 - learning_rate: 5.0000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9324 - loss: 0.3341 - val_accuracy: 0.9583 - val_loss: 0.2928 - learning_rate: 5.0000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9478 - loss: 0.3193 - val_accuracy: 0.9583 - val_loss: 0.2916 - learning_rate: 5.0000e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9412 - loss: 0.3244 - val_accuracy: 0.9542 - val_loss: 0.2994 - learning_rate: 5.0000e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.9515 - loss: 0.3185 - val_accuracy: 0.9500 - val_loss: 0.2947 - learning_rate: 5.0000e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.9522 - loss: 0.3124 - val_accuracy: 0.9500 - val_loss: 0.2975 - learning_rate: 5.0000e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.9397 - loss: 0.3310 - val_accuracy: 0.9542 - val_loss: 0.3002 - learning_rate: 5.0000e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.9382 - loss: 0.3273 - val_accuracy: 0.9542 - val_loss: 0.2911 - learning_rate: 5.0000e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9419 - loss: 0.3175 - val_accuracy: 0.9583 - val_loss: 0.2906 - learning_rate: 5.0000e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9434 - loss: 0.3105 - val_accuracy: 0.9625 - val_loss: 0.2841 - learning_rate: 5.0000e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9507 - loss: 0.3077 - val_accuracy: 0.9542 - val_loss: 0.2902 - learning_rate: 5.0000e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.9441 - loss: 0.3156 - val_accuracy: 0.9625 - val_loss: 0.2807 - learning_rate: 5.0000e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9485 - loss: 0.3030 - val_accuracy: 0.9542 - val_loss: 0.2822 - learning_rate: 5.0000e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.9456 - loss: 0.3143 - val_accuracy: 0.9583 - val_loss: 0.2807 - learning_rate: 5.0000e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.9375 - loss: 0.3209 - val_accuracy: 0.9542 - val_loss: 0.2881 - learning_rate: 5.0000e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.9404 - loss: 0.3145 - val_accuracy: 0.9542 - val_loss: 0.2797 - learning_rate: 5.0000e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9493 - loss: 0.3031 - val_accuracy: 0.9542 - val_loss: 0.2820 - learning_rate: 5.0000e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9478 - loss: 0.3126 - val_accuracy: 0.9542 - val_loss: 0.2868 - learning_rate: 5.0000e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9537 - loss: 0.2934 - val_accuracy: 0.9625 - val_loss: 0.2736 - learning_rate: 5.0000e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.9471 - loss: 0.2913 - val_accuracy: 0.9583 - val_loss: 0.2823 - learning_rate: 5.0000e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.9493 - loss: 0.2877 - val_accuracy: 0.9583 - val_loss: 0.2709 - learning_rate: 5.0000e-05\n",
      "Epoch 198/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.9456 - loss: 0.3020 - val_accuracy: 0.9625 - val_loss: 0.2704 - learning_rate: 5.0000e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.9419 - loss: 0.2998 - val_accuracy: 0.9583 - val_loss: 0.2709 - learning_rate: 5.0000e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.9368 - loss: 0.3058 - val_accuracy: 0.9583 - val_loss: 0.2810 - learning_rate: 5.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 198.\n",
      "\n",
      "âœ… Fold 1 Results:\n",
      "  Test Accuracy: 0.9500\n",
      "  Test AUC: 0.9834\n",
      "  Test Loss: 0.4609\n",
      "ğŸŒŸ New best model! Fold 1 with accuracy: 0.9500\n",
      "\n",
      "Fold 1 Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                NORMAL     0.9217    0.9563    0.9387       160\n",
      "ALL (INTERICTAL+ICTAL)     0.9701    0.9458    0.9578       240\n",
      "\n",
      "              accuracy                         0.9500       400\n",
      "             macro avg     0.9459    0.9510    0.9482       400\n",
      "          weighted avg     0.9507    0.9500    0.9501       400\n",
      "\n",
      "\n",
      "============================================================\n",
      " FOLD 2\n",
      "============================================================\n",
      "\n",
      "Train: 1360, Val: 240, Test: 400\n",
      "Test set distribution: (array([0, 1]), array([160, 240], dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Fold 2...\n",
      "ğŸ“Š Using data augmentation with real-time generator\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.5426 - loss: 1.5754 - val_accuracy: 0.6000 - val_loss: 1.5416 - learning_rate: 5.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.5757 - loss: 1.5497 - val_accuracy: 0.6000 - val_loss: 1.5243 - learning_rate: 5.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.5419 - loss: 1.5436 - val_accuracy: 0.6000 - val_loss: 1.5093 - learning_rate: 5.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.5522 - loss: 1.5249 - val_accuracy: 0.6000 - val_loss: 1.4960 - learning_rate: 5.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.5618 - loss: 1.5136 - val_accuracy: 0.6000 - val_loss: 1.4822 - learning_rate: 5.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.5603 - loss: 1.5032 - val_accuracy: 0.6000 - val_loss: 1.4677 - learning_rate: 5.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.5706 - loss: 1.4837 - val_accuracy: 0.6000 - val_loss: 1.4514 - learning_rate: 5.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.5640 - loss: 1.4740 - val_accuracy: 0.6000 - val_loss: 1.4343 - learning_rate: 5.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.5772 - loss: 1.4530 - val_accuracy: 0.6000 - val_loss: 1.4157 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.6184 - loss: 1.4302 - val_accuracy: 0.6000 - val_loss: 1.3982 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.5971 - loss: 1.4230 - val_accuracy: 0.6000 - val_loss: 1.3806 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.5993 - loss: 1.4069 - val_accuracy: 0.6042 - val_loss: 1.3612 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6154 - loss: 1.3978 - val_accuracy: 0.6083 - val_loss: 1.3427 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6147 - loss: 1.3856 - val_accuracy: 0.6083 - val_loss: 1.3261 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6213 - loss: 1.3673 - val_accuracy: 0.6542 - val_loss: 1.3046 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6250 - loss: 1.3443 - val_accuracy: 0.6875 - val_loss: 1.2849 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6331 - loss: 1.3355 - val_accuracy: 0.7292 - val_loss: 1.2633 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.6765 - loss: 1.3013 - val_accuracy: 0.7542 - val_loss: 1.2441 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6772 - loss: 1.2889 - val_accuracy: 0.7625 - val_loss: 1.2289 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.6934 - loss: 1.2666 - val_accuracy: 0.7833 - val_loss: 1.2047 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.7184 - loss: 1.2538 - val_accuracy: 0.8083 - val_loss: 1.1811 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.7235 - loss: 1.2410 - val_accuracy: 0.8125 - val_loss: 1.1692 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.7471 - loss: 1.2100 - val_accuracy: 0.8417 - val_loss: 1.1471 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.7412 - loss: 1.1988 - val_accuracy: 0.8458 - val_loss: 1.1344 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.7706 - loss: 1.1790 - val_accuracy: 0.8167 - val_loss: 1.1426 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.7699 - loss: 1.1637 - val_accuracy: 0.8333 - val_loss: 1.1225 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.7765 - loss: 1.1406 - val_accuracy: 0.8708 - val_loss: 1.0783 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8074 - loss: 1.1341 - val_accuracy: 0.8417 - val_loss: 1.1033 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.7890 - loss: 1.1232 - val_accuracy: 0.8750 - val_loss: 1.0532 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8059 - loss: 1.1084 - val_accuracy: 0.8708 - val_loss: 1.0464 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.7993 - loss: 1.1105 - val_accuracy: 0.8625 - val_loss: 1.0428 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.8051 - loss: 1.0863 - val_accuracy: 0.8333 - val_loss: 1.0846 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8184 - loss: 1.0752 - val_accuracy: 0.8750 - val_loss: 1.0144 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8235 - loss: 1.0606 - val_accuracy: 0.8708 - val_loss: 1.0123 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.8243 - loss: 1.0587 - val_accuracy: 0.8750 - val_loss: 0.9898 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8316 - loss: 1.0315 - val_accuracy: 0.8875 - val_loss: 0.9746 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8221 - loss: 1.0347 - val_accuracy: 0.8792 - val_loss: 0.9797 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8118 - loss: 1.0220 - val_accuracy: 0.8917 - val_loss: 0.9547 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8301 - loss: 1.0048 - val_accuracy: 0.8833 - val_loss: 0.9616 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8191 - loss: 1.0008 - val_accuracy: 0.8917 - val_loss: 0.9320 - learning_rate: 5.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8228 - loss: 0.9848 - val_accuracy: 0.8958 - val_loss: 0.9184 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8279 - loss: 0.9766 - val_accuracy: 0.8875 - val_loss: 0.9271 - learning_rate: 5.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8390 - loss: 0.9735 - val_accuracy: 0.8833 - val_loss: 0.9274 - learning_rate: 5.0000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8390 - loss: 0.9566 - val_accuracy: 0.8917 - val_loss: 0.8893 - learning_rate: 5.0000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8382 - loss: 0.9520 - val_accuracy: 0.9000 - val_loss: 0.8897 - learning_rate: 5.0000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8368 - loss: 0.9428 - val_accuracy: 0.8958 - val_loss: 0.8779 - learning_rate: 5.0000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8478 - loss: 0.9195 - val_accuracy: 0.8958 - val_loss: 0.8656 - learning_rate: 5.0000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8382 - loss: 0.9185 - val_accuracy: 0.9000 - val_loss: 0.8614 - learning_rate: 5.0000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8515 - loss: 0.9013 - val_accuracy: 0.9000 - val_loss: 0.8447 - learning_rate: 5.0000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8279 - loss: 0.9080 - val_accuracy: 0.9000 - val_loss: 0.8463 - learning_rate: 5.0000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8390 - loss: 0.8940 - val_accuracy: 0.9042 - val_loss: 0.8517 - learning_rate: 5.0000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8566 - loss: 0.8661 - val_accuracy: 0.9042 - val_loss: 0.8368 - learning_rate: 5.0000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8618 - loss: 0.8710 - val_accuracy: 0.9083 - val_loss: 0.8272 - learning_rate: 5.0000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8544 - loss: 0.8611 - val_accuracy: 0.9042 - val_loss: 0.8237 - learning_rate: 5.0000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8478 - loss: 0.8532 - val_accuracy: 0.8875 - val_loss: 0.7979 - learning_rate: 5.0000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8596 - loss: 0.8353 - val_accuracy: 0.8917 - val_loss: 0.7965 - learning_rate: 5.0000e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8669 - loss: 0.8350 - val_accuracy: 0.9125 - val_loss: 0.7775 - learning_rate: 5.0000e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8566 - loss: 0.8340 - val_accuracy: 0.9125 - val_loss: 0.7686 - learning_rate: 5.0000e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8618 - loss: 0.8194 - val_accuracy: 0.9125 - val_loss: 0.7607 - learning_rate: 5.0000e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8581 - loss: 0.8117 - val_accuracy: 0.9042 - val_loss: 0.7560 - learning_rate: 5.0000e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8662 - loss: 0.8081 - val_accuracy: 0.9083 - val_loss: 0.7538 - learning_rate: 5.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8566 - loss: 0.8061 - val_accuracy: 0.9083 - val_loss: 0.7354 - learning_rate: 5.0000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8721 - loss: 0.7815 - val_accuracy: 0.9125 - val_loss: 0.7294 - learning_rate: 5.0000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8669 - loss: 0.7862 - val_accuracy: 0.9083 - val_loss: 0.7187 - learning_rate: 5.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8713 - loss: 0.7653 - val_accuracy: 0.9083 - val_loss: 0.7153 - learning_rate: 5.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8787 - loss: 0.7596 - val_accuracy: 0.9083 - val_loss: 0.7086 - learning_rate: 5.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8779 - loss: 0.7566 - val_accuracy: 0.9167 - val_loss: 0.6943 - learning_rate: 5.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8669 - loss: 0.7524 - val_accuracy: 0.9250 - val_loss: 0.6848 - learning_rate: 5.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8691 - loss: 0.7394 - val_accuracy: 0.9167 - val_loss: 0.6797 - learning_rate: 5.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8794 - loss: 0.7323 - val_accuracy: 0.9167 - val_loss: 0.6737 - learning_rate: 5.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8676 - loss: 0.7401 - val_accuracy: 0.9208 - val_loss: 0.6678 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8699 - loss: 0.7364 - val_accuracy: 0.9208 - val_loss: 0.6592 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8824 - loss: 0.7135 - val_accuracy: 0.9125 - val_loss: 0.6518 - learning_rate: 5.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8750 - loss: 0.7092 - val_accuracy: 0.9250 - val_loss: 0.6426 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8846 - loss: 0.6963 - val_accuracy: 0.9167 - val_loss: 0.6418 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8735 - loss: 0.7024 - val_accuracy: 0.9167 - val_loss: 0.6380 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8978 - loss: 0.6802 - val_accuracy: 0.9250 - val_loss: 0.6236 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8919 - loss: 0.6698 - val_accuracy: 0.9333 - val_loss: 0.6148 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8824 - loss: 0.6813 - val_accuracy: 0.9250 - val_loss: 0.6117 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8897 - loss: 0.6659 - val_accuracy: 0.9292 - val_loss: 0.6025 - learning_rate: 5.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8757 - loss: 0.6732 - val_accuracy: 0.9250 - val_loss: 0.5955 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8926 - loss: 0.6506 - val_accuracy: 0.9250 - val_loss: 0.5915 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8904 - loss: 0.6460 - val_accuracy: 0.9208 - val_loss: 0.5943 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8757 - loss: 0.6550 - val_accuracy: 0.9208 - val_loss: 0.5921 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8926 - loss: 0.6272 - val_accuracy: 0.9333 - val_loss: 0.5696 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8890 - loss: 0.6429 - val_accuracy: 0.9417 - val_loss: 0.5583 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8941 - loss: 0.6191 - val_accuracy: 0.9292 - val_loss: 0.5626 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8897 - loss: 0.6213 - val_accuracy: 0.9167 - val_loss: 0.5630 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8985 - loss: 0.6036 - val_accuracy: 0.9375 - val_loss: 0.5497 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9022 - loss: 0.6070 - val_accuracy: 0.9417 - val_loss: 0.5443 - learning_rate: 5.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8904 - loss: 0.5981 - val_accuracy: 0.9458 - val_loss: 0.5370 - learning_rate: 5.0000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8868 - loss: 0.6000 - val_accuracy: 0.9250 - val_loss: 0.5383 - learning_rate: 5.0000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8963 - loss: 0.5843 - val_accuracy: 0.9417 - val_loss: 0.5213 - learning_rate: 5.0000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9103 - loss: 0.5710 - val_accuracy: 0.9375 - val_loss: 0.5216 - learning_rate: 5.0000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9162 - loss: 0.5656 - val_accuracy: 0.9458 - val_loss: 0.5241 - learning_rate: 5.0000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9029 - loss: 0.5713 - val_accuracy: 0.9542 - val_loss: 0.5026 - learning_rate: 5.0000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.8934 - loss: 0.5784 - val_accuracy: 0.9333 - val_loss: 0.5182 - learning_rate: 5.0000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9051 - loss: 0.5605 - val_accuracy: 0.9458 - val_loss: 0.4981 - learning_rate: 5.0000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8985 - loss: 0.5716 - val_accuracy: 0.9458 - val_loss: 0.4947 - learning_rate: 5.0000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9022 - loss: 0.5634 - val_accuracy: 0.9542 - val_loss: 0.4835 - learning_rate: 5.0000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9000 - loss: 0.5513 - val_accuracy: 0.9542 - val_loss: 0.4802 - learning_rate: 5.0000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9147 - loss: 0.5341 - val_accuracy: 0.9542 - val_loss: 0.4789 - learning_rate: 5.0000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.9162 - loss: 0.5305 - val_accuracy: 0.9500 - val_loss: 0.4691 - learning_rate: 5.0000e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8978 - loss: 0.5354 - val_accuracy: 0.9583 - val_loss: 0.4643 - learning_rate: 5.0000e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9007 - loss: 0.5382 - val_accuracy: 0.9583 - val_loss: 0.4695 - learning_rate: 5.0000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.9088 - loss: 0.5271 - val_accuracy: 0.9583 - val_loss: 0.4551 - learning_rate: 5.0000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9088 - loss: 0.5201 - val_accuracy: 0.9542 - val_loss: 0.4573 - learning_rate: 5.0000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.9103 - loss: 0.5247 - val_accuracy: 0.9500 - val_loss: 0.4567 - learning_rate: 5.0000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9044 - loss: 0.5228 - val_accuracy: 0.9542 - val_loss: 0.4490 - learning_rate: 5.0000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9199 - loss: 0.5172 - val_accuracy: 0.9375 - val_loss: 0.4633 - learning_rate: 5.0000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.9051 - loss: 0.5158 - val_accuracy: 0.9417 - val_loss: 0.4529 - learning_rate: 5.0000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9059 - loss: 0.5114 - val_accuracy: 0.9458 - val_loss: 0.4574 - learning_rate: 5.0000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8956 - loss: 0.5108 - val_accuracy: 0.9583 - val_loss: 0.4497 - learning_rate: 5.0000e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9206 - loss: 0.4847 - val_accuracy: 0.9583 - val_loss: 0.4411 - learning_rate: 5.0000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9051 - loss: 0.5039 - val_accuracy: 0.9542 - val_loss: 0.4313 - learning_rate: 5.0000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9044 - loss: 0.5046 - val_accuracy: 0.9500 - val_loss: 0.4336 - learning_rate: 5.0000e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9235 - loss: 0.4871 - val_accuracy: 0.9417 - val_loss: 0.4395 - learning_rate: 5.0000e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 72ms/step - accuracy: 0.9110 - loss: 0.4872 - val_accuracy: 0.9583 - val_loss: 0.4191 - learning_rate: 5.0000e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9184 - loss: 0.4813 - val_accuracy: 0.9583 - val_loss: 0.4195 - learning_rate: 5.0000e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9044 - loss: 0.4925 - val_accuracy: 0.9542 - val_loss: 0.4207 - learning_rate: 5.0000e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9206 - loss: 0.4662 - val_accuracy: 0.9542 - val_loss: 0.4134 - learning_rate: 5.0000e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9118 - loss: 0.4708 - val_accuracy: 0.9625 - val_loss: 0.4083 - learning_rate: 5.0000e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9176 - loss: 0.4629 - val_accuracy: 0.9583 - val_loss: 0.4073 - learning_rate: 5.0000e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9176 - loss: 0.4693 - val_accuracy: 0.9625 - val_loss: 0.3981 - learning_rate: 5.0000e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9243 - loss: 0.4565 - val_accuracy: 0.9667 - val_loss: 0.3970 - learning_rate: 5.0000e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9132 - loss: 0.4704 - val_accuracy: 0.9667 - val_loss: 0.3885 - learning_rate: 5.0000e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9066 - loss: 0.4579 - val_accuracy: 0.9667 - val_loss: 0.3842 - learning_rate: 5.0000e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9162 - loss: 0.4522 - val_accuracy: 0.9583 - val_loss: 0.3837 - learning_rate: 5.0000e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9110 - loss: 0.4600 - val_accuracy: 0.9500 - val_loss: 0.3833 - learning_rate: 5.0000e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9272 - loss: 0.4357 - val_accuracy: 0.9583 - val_loss: 0.3844 - learning_rate: 5.0000e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9169 - loss: 0.4496 - val_accuracy: 0.9583 - val_loss: 0.3853 - learning_rate: 5.0000e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9206 - loss: 0.4360 - val_accuracy: 0.9625 - val_loss: 0.3750 - learning_rate: 5.0000e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9213 - loss: 0.4487 - val_accuracy: 0.9583 - val_loss: 0.3806 - learning_rate: 5.0000e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9221 - loss: 0.4380 - val_accuracy: 0.9625 - val_loss: 0.3710 - learning_rate: 5.0000e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9316 - loss: 0.4254 - val_accuracy: 0.9667 - val_loss: 0.3692 - learning_rate: 5.0000e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9353 - loss: 0.4094 - val_accuracy: 0.9667 - val_loss: 0.3611 - learning_rate: 5.0000e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9287 - loss: 0.4244 - val_accuracy: 0.9708 - val_loss: 0.3609 - learning_rate: 5.0000e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9250 - loss: 0.4197 - val_accuracy: 0.9625 - val_loss: 0.3718 - learning_rate: 5.0000e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9221 - loss: 0.4192 - val_accuracy: 0.9583 - val_loss: 0.3589 - learning_rate: 5.0000e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9309 - loss: 0.4206 - val_accuracy: 0.9625 - val_loss: 0.3567 - learning_rate: 5.0000e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9162 - loss: 0.4107 - val_accuracy: 0.9625 - val_loss: 0.3720 - learning_rate: 5.0000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9176 - loss: 0.4119 - val_accuracy: 0.9583 - val_loss: 0.3593 - learning_rate: 5.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9184 - loss: 0.4196 - val_accuracy: 0.9583 - val_loss: 0.3556 - learning_rate: 5.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9279 - loss: 0.4047 - val_accuracy: 0.9625 - val_loss: 0.3556 - learning_rate: 5.0000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9265 - loss: 0.4093 - val_accuracy: 0.9625 - val_loss: 0.3612 - learning_rate: 5.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9272 - loss: 0.3987 - val_accuracy: 0.9667 - val_loss: 0.3429 - learning_rate: 5.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9147 - loss: 0.4280 - val_accuracy: 0.9583 - val_loss: 0.3463 - learning_rate: 5.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9309 - loss: 0.3956 - val_accuracy: 0.9667 - val_loss: 0.3418 - learning_rate: 5.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9154 - loss: 0.3985 - val_accuracy: 0.9625 - val_loss: 0.3449 - learning_rate: 5.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9294 - loss: 0.3865 - val_accuracy: 0.9667 - val_loss: 0.3365 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9235 - loss: 0.3992 - val_accuracy: 0.9625 - val_loss: 0.3408 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9338 - loss: 0.3875 - val_accuracy: 0.9625 - val_loss: 0.3306 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9324 - loss: 0.3951 - val_accuracy: 0.9583 - val_loss: 0.3403 - learning_rate: 5.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9316 - loss: 0.3793 - val_accuracy: 0.9708 - val_loss: 0.3300 - learning_rate: 5.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9353 - loss: 0.3678 - val_accuracy: 0.9542 - val_loss: 0.3332 - learning_rate: 5.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9243 - loss: 0.3815 - val_accuracy: 0.9458 - val_loss: 0.3356 - learning_rate: 5.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9353 - loss: 0.3718 - val_accuracy: 0.9625 - val_loss: 0.3192 - learning_rate: 5.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9272 - loss: 0.3816 - val_accuracy: 0.9625 - val_loss: 0.3197 - learning_rate: 5.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9272 - loss: 0.3828 - val_accuracy: 0.9708 - val_loss: 0.3204 - learning_rate: 5.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9257 - loss: 0.3654 - val_accuracy: 0.9583 - val_loss: 0.3187 - learning_rate: 5.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9478 - loss: 0.3605 - val_accuracy: 0.9708 - val_loss: 0.3158 - learning_rate: 5.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9353 - loss: 0.3619 - val_accuracy: 0.9708 - val_loss: 0.3176 - learning_rate: 5.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9294 - loss: 0.3661 - val_accuracy: 0.9583 - val_loss: 0.3112 - learning_rate: 5.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9272 - loss: 0.3713 - val_accuracy: 0.9708 - val_loss: 0.3110 - learning_rate: 5.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9272 - loss: 0.3726 - val_accuracy: 0.9708 - val_loss: 0.3098 - learning_rate: 5.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9412 - loss: 0.3442 - val_accuracy: 0.9583 - val_loss: 0.3175 - learning_rate: 5.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9316 - loss: 0.3706 - val_accuracy: 0.9625 - val_loss: 0.3009 - learning_rate: 5.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9360 - loss: 0.3531 - val_accuracy: 0.9667 - val_loss: 0.3016 - learning_rate: 5.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9382 - loss: 0.3457 - val_accuracy: 0.9625 - val_loss: 0.2989 - learning_rate: 5.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9250 - loss: 0.3651 - val_accuracy: 0.9708 - val_loss: 0.2987 - learning_rate: 5.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9360 - loss: 0.3528 - val_accuracy: 0.9708 - val_loss: 0.2993 - learning_rate: 5.0000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9301 - loss: 0.3548 - val_accuracy: 0.9708 - val_loss: 0.2991 - learning_rate: 5.0000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9294 - loss: 0.3564 - val_accuracy: 0.9708 - val_loss: 0.2976 - learning_rate: 5.0000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9294 - loss: 0.3495 - val_accuracy: 0.9667 - val_loss: 0.2918 - learning_rate: 5.0000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9404 - loss: 0.3305 - val_accuracy: 0.9708 - val_loss: 0.2895 - learning_rate: 5.0000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9390 - loss: 0.3459 - val_accuracy: 0.9708 - val_loss: 0.2996 - learning_rate: 5.0000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9360 - loss: 0.3451 - val_accuracy: 0.9667 - val_loss: 0.2921 - learning_rate: 5.0000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9412 - loss: 0.3276 - val_accuracy: 0.9625 - val_loss: 0.2876 - learning_rate: 5.0000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9419 - loss: 0.3348 - val_accuracy: 0.9708 - val_loss: 0.2930 - learning_rate: 5.0000e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9478 - loss: 0.3174 - val_accuracy: 0.9708 - val_loss: 0.2885 - learning_rate: 5.0000e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9463 - loss: 0.3221 - val_accuracy: 0.9708 - val_loss: 0.2905 - learning_rate: 5.0000e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9412 - loss: 0.3392 - val_accuracy: 0.9625 - val_loss: 0.2842 - learning_rate: 5.0000e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9346 - loss: 0.3379 - val_accuracy: 0.9667 - val_loss: 0.2828 - learning_rate: 5.0000e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9404 - loss: 0.3204 - val_accuracy: 0.9708 - val_loss: 0.2842 - learning_rate: 5.0000e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9375 - loss: 0.3152 - val_accuracy: 0.9708 - val_loss: 0.2800 - learning_rate: 5.0000e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9338 - loss: 0.3305 - val_accuracy: 0.9667 - val_loss: 0.2758 - learning_rate: 5.0000e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9412 - loss: 0.3272 - val_accuracy: 0.9667 - val_loss: 0.2766 - learning_rate: 5.0000e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9434 - loss: 0.3154 - val_accuracy: 0.9708 - val_loss: 0.2818 - learning_rate: 5.0000e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9397 - loss: 0.3193 - val_accuracy: 0.9667 - val_loss: 0.2741 - learning_rate: 5.0000e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9456 - loss: 0.3165 - val_accuracy: 0.9708 - val_loss: 0.2768 - learning_rate: 5.0000e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9382 - loss: 0.3190 - val_accuracy: 0.9667 - val_loss: 0.2832 - learning_rate: 5.0000e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9419 - loss: 0.3198 - val_accuracy: 0.9667 - val_loss: 0.2712 - learning_rate: 5.0000e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9463 - loss: 0.3077 - val_accuracy: 0.9625 - val_loss: 0.2693 - learning_rate: 5.0000e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9434 - loss: 0.3130 - val_accuracy: 0.9708 - val_loss: 0.2692 - learning_rate: 5.0000e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9368 - loss: 0.3224 - val_accuracy: 0.9708 - val_loss: 0.2661 - learning_rate: 5.0000e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9397 - loss: 0.3082 - val_accuracy: 0.9708 - val_loss: 0.2703 - learning_rate: 5.0000e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9360 - loss: 0.3148 - val_accuracy: 0.9667 - val_loss: 0.2648 - learning_rate: 5.0000e-05\n",
      "Epoch 198/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9390 - loss: 0.3031 - val_accuracy: 0.9708 - val_loss: 0.2748 - learning_rate: 5.0000e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9375 - loss: 0.3070 - val_accuracy: 0.9708 - val_loss: 0.2634 - learning_rate: 5.0000e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9463 - loss: 0.2948 - val_accuracy: 0.9667 - val_loss: 0.2598 - learning_rate: 5.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 200.\n",
      "\n",
      "âœ… Fold 2 Results:\n",
      "  Test Accuracy: 0.9575\n",
      "  Test AUC: 0.9939\n",
      "  Test Loss: 0.3607\n",
      "ğŸŒŸ New best model! Fold 2 with accuracy: 0.9575\n",
      "\n",
      "Fold 2 Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                NORMAL     0.9231    0.9750    0.9483       160\n",
      "ALL (INTERICTAL+ICTAL)     0.9827    0.9458    0.9639       240\n",
      "\n",
      "              accuracy                         0.9575       400\n",
      "             macro avg     0.9529    0.9604    0.9561       400\n",
      "          weighted avg     0.9588    0.9575    0.9577       400\n",
      "\n",
      "\n",
      "============================================================\n",
      " FOLD 3\n",
      "============================================================\n",
      "\n",
      "Train: 1360, Val: 240, Test: 400\n",
      "Test set distribution: (array([0, 1]), array([160, 240], dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Fold 3...\n",
      "ğŸ“Š Using data augmentation with real-time generator\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.5228 - loss: 1.5690 - val_accuracy: 0.6000 - val_loss: 1.5447 - learning_rate: 5.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.5184 - loss: 1.5513 - val_accuracy: 0.6000 - val_loss: 1.5290 - learning_rate: 5.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.5640 - loss: 1.5293 - val_accuracy: 0.6000 - val_loss: 1.5125 - learning_rate: 5.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.5647 - loss: 1.5144 - val_accuracy: 0.6000 - val_loss: 1.4965 - learning_rate: 5.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.5890 - loss: 1.4984 - val_accuracy: 0.6000 - val_loss: 1.4825 - learning_rate: 5.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.5787 - loss: 1.4873 - val_accuracy: 0.6000 - val_loss: 1.4678 - learning_rate: 5.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.5632 - loss: 1.4778 - val_accuracy: 0.6000 - val_loss: 1.4524 - learning_rate: 5.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6037 - loss: 1.4542 - val_accuracy: 0.6000 - val_loss: 1.4330 - learning_rate: 5.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.6059 - loss: 1.4432 - val_accuracy: 0.6042 - val_loss: 1.4139 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.5963 - loss: 1.4272 - val_accuracy: 0.6167 - val_loss: 1.3957 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6118 - loss: 1.4103 - val_accuracy: 0.6250 - val_loss: 1.3761 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6140 - loss: 1.3966 - val_accuracy: 0.6417 - val_loss: 1.3571 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.6338 - loss: 1.3768 - val_accuracy: 0.6667 - val_loss: 1.3347 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6096 - loss: 1.3676 - val_accuracy: 0.6958 - val_loss: 1.3096 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6603 - loss: 1.3350 - val_accuracy: 0.7250 - val_loss: 1.2822 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.6581 - loss: 1.3218 - val_accuracy: 0.7583 - val_loss: 1.2542 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.6941 - loss: 1.2982 - val_accuracy: 0.7667 - val_loss: 1.2329 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6787 - loss: 1.2900 - val_accuracy: 0.8000 - val_loss: 1.2041 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.7191 - loss: 1.2570 - val_accuracy: 0.8375 - val_loss: 1.1728 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.7375 - loss: 1.2373 - val_accuracy: 0.8250 - val_loss: 1.1628 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.7456 - loss: 1.2187 - val_accuracy: 0.8333 - val_loss: 1.1514 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.7515 - loss: 1.2147 - val_accuracy: 0.8708 - val_loss: 1.1123 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.7522 - loss: 1.2032 - val_accuracy: 0.8917 - val_loss: 1.0927 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.7713 - loss: 1.1784 - val_accuracy: 0.8792 - val_loss: 1.0795 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.7515 - loss: 1.1706 - val_accuracy: 0.8958 - val_loss: 1.0576 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.7831 - loss: 1.1478 - val_accuracy: 0.8667 - val_loss: 1.0648 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.7978 - loss: 1.1312 - val_accuracy: 0.8958 - val_loss: 1.0316 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.7860 - loss: 1.1334 - val_accuracy: 0.8917 - val_loss: 1.0125 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.7949 - loss: 1.1160 - val_accuracy: 0.9042 - val_loss: 1.0020 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.7971 - loss: 1.1061 - val_accuracy: 0.8958 - val_loss: 0.9990 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8022 - loss: 1.0951 - val_accuracy: 0.9125 - val_loss: 0.9791 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8022 - loss: 1.0796 - val_accuracy: 0.9083 - val_loss: 0.9687 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.7926 - loss: 1.0698 - val_accuracy: 0.8958 - val_loss: 0.9673 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8015 - loss: 1.0637 - val_accuracy: 0.9125 - val_loss: 0.9480 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8272 - loss: 1.0355 - val_accuracy: 0.8917 - val_loss: 0.9494 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.7912 - loss: 1.0520 - val_accuracy: 0.9083 - val_loss: 0.9269 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8081 - loss: 1.0199 - val_accuracy: 0.8958 - val_loss: 0.9175 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8213 - loss: 1.0056 - val_accuracy: 0.9000 - val_loss: 0.9019 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8301 - loss: 0.9949 - val_accuracy: 0.9042 - val_loss: 0.8911 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8103 - loss: 0.9973 - val_accuracy: 0.9208 - val_loss: 0.8831 - learning_rate: 5.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8338 - loss: 0.9739 - val_accuracy: 0.9167 - val_loss: 0.8727 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8176 - loss: 0.9852 - val_accuracy: 0.9167 - val_loss: 0.8604 - learning_rate: 5.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.8228 - loss: 0.9618 - val_accuracy: 0.9083 - val_loss: 0.8579 - learning_rate: 5.0000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8169 - loss: 0.9597 - val_accuracy: 0.9208 - val_loss: 0.8411 - learning_rate: 5.0000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8375 - loss: 0.9376 - val_accuracy: 0.9292 - val_loss: 0.8304 - learning_rate: 5.0000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8426 - loss: 0.9274 - val_accuracy: 0.9208 - val_loss: 0.8244 - learning_rate: 5.0000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8213 - loss: 0.9333 - val_accuracy: 0.9250 - val_loss: 0.8135 - learning_rate: 5.0000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8331 - loss: 0.9205 - val_accuracy: 0.9250 - val_loss: 0.8035 - learning_rate: 5.0000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8485 - loss: 0.9091 - val_accuracy: 0.9292 - val_loss: 0.7922 - learning_rate: 5.0000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8603 - loss: 0.8744 - val_accuracy: 0.9208 - val_loss: 0.7871 - learning_rate: 5.0000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.8603 - loss: 0.8703 - val_accuracy: 0.9250 - val_loss: 0.7754 - learning_rate: 5.0000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8706 - loss: 0.8584 - val_accuracy: 0.9250 - val_loss: 0.7669 - learning_rate: 5.0000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8471 - loss: 0.8625 - val_accuracy: 0.9250 - val_loss: 0.7535 - learning_rate: 5.0000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8441 - loss: 0.8676 - val_accuracy: 0.9292 - val_loss: 0.7466 - learning_rate: 5.0000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8625 - loss: 0.8344 - val_accuracy: 0.9250 - val_loss: 0.7378 - learning_rate: 5.0000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8662 - loss: 0.8182 - val_accuracy: 0.9333 - val_loss: 0.7293 - learning_rate: 5.0000e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8493 - loss: 0.8248 - val_accuracy: 0.9417 - val_loss: 0.7252 - learning_rate: 5.0000e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8551 - loss: 0.8141 - val_accuracy: 0.9208 - val_loss: 0.7265 - learning_rate: 5.0000e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8574 - loss: 0.8208 - val_accuracy: 0.9375 - val_loss: 0.7103 - learning_rate: 5.0000e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8618 - loss: 0.8049 - val_accuracy: 0.9250 - val_loss: 0.7034 - learning_rate: 5.0000e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8610 - loss: 0.7921 - val_accuracy: 0.9333 - val_loss: 0.6936 - learning_rate: 5.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8691 - loss: 0.7792 - val_accuracy: 0.9375 - val_loss: 0.6891 - learning_rate: 5.0000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.8596 - loss: 0.7808 - val_accuracy: 0.9333 - val_loss: 0.6789 - learning_rate: 5.0000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8765 - loss: 0.7620 - val_accuracy: 0.9333 - val_loss: 0.6680 - learning_rate: 5.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8743 - loss: 0.7669 - val_accuracy: 0.9333 - val_loss: 0.6625 - learning_rate: 5.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8743 - loss: 0.7560 - val_accuracy: 0.9333 - val_loss: 0.6559 - learning_rate: 5.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8853 - loss: 0.7466 - val_accuracy: 0.9333 - val_loss: 0.6559 - learning_rate: 5.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8713 - loss: 0.7528 - val_accuracy: 0.9458 - val_loss: 0.6443 - learning_rate: 5.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8765 - loss: 0.7298 - val_accuracy: 0.9375 - val_loss: 0.6292 - learning_rate: 5.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8838 - loss: 0.7196 - val_accuracy: 0.9375 - val_loss: 0.6242 - learning_rate: 5.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8912 - loss: 0.7176 - val_accuracy: 0.9417 - val_loss: 0.6181 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8831 - loss: 0.7138 - val_accuracy: 0.9500 - val_loss: 0.6142 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8743 - loss: 0.7160 - val_accuracy: 0.9375 - val_loss: 0.6039 - learning_rate: 5.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8625 - loss: 0.7163 - val_accuracy: 0.9500 - val_loss: 0.6020 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8890 - loss: 0.6892 - val_accuracy: 0.9417 - val_loss: 0.5899 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8625 - loss: 0.7130 - val_accuracy: 0.9458 - val_loss: 0.5894 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8824 - loss: 0.6846 - val_accuracy: 0.9500 - val_loss: 0.5797 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8853 - loss: 0.6703 - val_accuracy: 0.9500 - val_loss: 0.5739 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8860 - loss: 0.6773 - val_accuracy: 0.9417 - val_loss: 0.5664 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8846 - loss: 0.6554 - val_accuracy: 0.9500 - val_loss: 0.5634 - learning_rate: 5.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8941 - loss: 0.6616 - val_accuracy: 0.9542 - val_loss: 0.5629 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8816 - loss: 0.6575 - val_accuracy: 0.9500 - val_loss: 0.5494 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8794 - loss: 0.6454 - val_accuracy: 0.9583 - val_loss: 0.5495 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8934 - loss: 0.6365 - val_accuracy: 0.9542 - val_loss: 0.5474 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8831 - loss: 0.6510 - val_accuracy: 0.9500 - val_loss: 0.5381 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8868 - loss: 0.6337 - val_accuracy: 0.9583 - val_loss: 0.5328 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8890 - loss: 0.6308 - val_accuracy: 0.9583 - val_loss: 0.5266 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8890 - loss: 0.6173 - val_accuracy: 0.9500 - val_loss: 0.5200 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.9103 - loss: 0.6023 - val_accuracy: 0.9500 - val_loss: 0.5179 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8904 - loss: 0.6151 - val_accuracy: 0.9458 - val_loss: 0.5162 - learning_rate: 5.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9125 - loss: 0.5898 - val_accuracy: 0.9458 - val_loss: 0.5077 - learning_rate: 5.0000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.9022 - loss: 0.5887 - val_accuracy: 0.9458 - val_loss: 0.4994 - learning_rate: 5.0000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8971 - loss: 0.6066 - val_accuracy: 0.9542 - val_loss: 0.4936 - learning_rate: 5.0000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8956 - loss: 0.5873 - val_accuracy: 0.9583 - val_loss: 0.4949 - learning_rate: 5.0000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8868 - loss: 0.5935 - val_accuracy: 0.9542 - val_loss: 0.4907 - learning_rate: 5.0000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8949 - loss: 0.5952 - val_accuracy: 0.9458 - val_loss: 0.4850 - learning_rate: 5.0000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.9221 - loss: 0.5599 - val_accuracy: 0.9542 - val_loss: 0.4756 - learning_rate: 5.0000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8985 - loss: 0.5653 - val_accuracy: 0.9625 - val_loss: 0.4772 - learning_rate: 5.0000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9066 - loss: 0.5560 - val_accuracy: 0.9583 - val_loss: 0.4703 - learning_rate: 5.0000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8978 - loss: 0.5614 - val_accuracy: 0.9458 - val_loss: 0.4677 - learning_rate: 5.0000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.9037 - loss: 0.5603 - val_accuracy: 0.9542 - val_loss: 0.4673 - learning_rate: 5.0000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9132 - loss: 0.5351 - val_accuracy: 0.9458 - val_loss: 0.4606 - learning_rate: 5.0000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9029 - loss: 0.5545 - val_accuracy: 0.9458 - val_loss: 0.4572 - learning_rate: 5.0000e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.9184 - loss: 0.5273 - val_accuracy: 0.9583 - val_loss: 0.4585 - learning_rate: 5.0000e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9037 - loss: 0.5402 - val_accuracy: 0.9542 - val_loss: 0.4433 - learning_rate: 5.0000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9088 - loss: 0.5276 - val_accuracy: 0.9542 - val_loss: 0.4416 - learning_rate: 5.0000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9221 - loss: 0.5102 - val_accuracy: 0.9625 - val_loss: 0.4410 - learning_rate: 5.0000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9147 - loss: 0.5141 - val_accuracy: 0.9583 - val_loss: 0.4339 - learning_rate: 5.0000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8993 - loss: 0.5355 - val_accuracy: 0.9542 - val_loss: 0.4311 - learning_rate: 5.0000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8993 - loss: 0.5317 - val_accuracy: 0.9583 - val_loss: 0.4367 - learning_rate: 5.0000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8985 - loss: 0.5097 - val_accuracy: 0.9667 - val_loss: 0.4247 - learning_rate: 5.0000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9051 - loss: 0.5213 - val_accuracy: 0.9625 - val_loss: 0.4229 - learning_rate: 5.0000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9110 - loss: 0.5059 - val_accuracy: 0.9542 - val_loss: 0.4241 - learning_rate: 5.0000e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9074 - loss: 0.4987 - val_accuracy: 0.9542 - val_loss: 0.4179 - learning_rate: 5.0000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9147 - loss: 0.5040 - val_accuracy: 0.9583 - val_loss: 0.4076 - learning_rate: 5.0000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9221 - loss: 0.4905 - val_accuracy: 0.9625 - val_loss: 0.4116 - learning_rate: 5.0000e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9132 - loss: 0.4957 - val_accuracy: 0.9583 - val_loss: 0.4036 - learning_rate: 5.0000e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9147 - loss: 0.4940 - val_accuracy: 0.9542 - val_loss: 0.3993 - learning_rate: 5.0000e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9140 - loss: 0.4845 - val_accuracy: 0.9625 - val_loss: 0.3951 - learning_rate: 5.0000e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9132 - loss: 0.4775 - val_accuracy: 0.9625 - val_loss: 0.3951 - learning_rate: 5.0000e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9096 - loss: 0.4834 - val_accuracy: 0.9583 - val_loss: 0.4005 - learning_rate: 5.0000e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9132 - loss: 0.4839 - val_accuracy: 0.9625 - val_loss: 0.3867 - learning_rate: 5.0000e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9169 - loss: 0.4740 - val_accuracy: 0.9750 - val_loss: 0.3867 - learning_rate: 5.0000e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9191 - loss: 0.4616 - val_accuracy: 0.9625 - val_loss: 0.3825 - learning_rate: 5.0000e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9176 - loss: 0.4676 - val_accuracy: 0.9625 - val_loss: 0.3814 - learning_rate: 5.0000e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9228 - loss: 0.4554 - val_accuracy: 0.9708 - val_loss: 0.3782 - learning_rate: 5.0000e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.9213 - loss: 0.4635 - val_accuracy: 0.9625 - val_loss: 0.3834 - learning_rate: 5.0000e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9228 - loss: 0.4557 - val_accuracy: 0.9667 - val_loss: 0.3753 - learning_rate: 5.0000e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9191 - loss: 0.4474 - val_accuracy: 0.9625 - val_loss: 0.3732 - learning_rate: 5.0000e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9206 - loss: 0.4535 - val_accuracy: 0.9708 - val_loss: 0.3602 - learning_rate: 5.0000e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9037 - loss: 0.4652 - val_accuracy: 0.9708 - val_loss: 0.3631 - learning_rate: 5.0000e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.9235 - loss: 0.4425 - val_accuracy: 0.9708 - val_loss: 0.3660 - learning_rate: 5.0000e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9279 - loss: 0.4390 - val_accuracy: 0.9708 - val_loss: 0.3583 - learning_rate: 5.0000e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9287 - loss: 0.4346 - val_accuracy: 0.9708 - val_loss: 0.3595 - learning_rate: 5.0000e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9272 - loss: 0.4308 - val_accuracy: 0.9750 - val_loss: 0.3543 - learning_rate: 5.0000e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9221 - loss: 0.4289 - val_accuracy: 0.9750 - val_loss: 0.3516 - learning_rate: 5.0000e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9162 - loss: 0.4361 - val_accuracy: 0.9625 - val_loss: 0.3587 - learning_rate: 5.0000e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9265 - loss: 0.4197 - val_accuracy: 0.9708 - val_loss: 0.3465 - learning_rate: 5.0000e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9243 - loss: 0.4265 - val_accuracy: 0.9708 - val_loss: 0.3475 - learning_rate: 5.0000e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9154 - loss: 0.4282 - val_accuracy: 0.9625 - val_loss: 0.3449 - learning_rate: 5.0000e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9324 - loss: 0.4115 - val_accuracy: 0.9667 - val_loss: 0.3427 - learning_rate: 5.0000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9235 - loss: 0.4174 - val_accuracy: 0.9667 - val_loss: 0.3390 - learning_rate: 5.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9191 - loss: 0.4244 - val_accuracy: 0.9708 - val_loss: 0.3351 - learning_rate: 5.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9294 - loss: 0.4150 - val_accuracy: 0.9708 - val_loss: 0.3368 - learning_rate: 5.0000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9221 - loss: 0.4020 - val_accuracy: 0.9667 - val_loss: 0.3348 - learning_rate: 5.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9324 - loss: 0.4027 - val_accuracy: 0.9708 - val_loss: 0.3311 - learning_rate: 5.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9265 - loss: 0.4143 - val_accuracy: 0.9625 - val_loss: 0.3327 - learning_rate: 5.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9184 - loss: 0.4144 - val_accuracy: 0.9667 - val_loss: 0.3229 - learning_rate: 5.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9338 - loss: 0.4030 - val_accuracy: 0.9708 - val_loss: 0.3224 - learning_rate: 5.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9199 - loss: 0.3985 - val_accuracy: 0.9583 - val_loss: 0.3293 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9309 - loss: 0.3892 - val_accuracy: 0.9583 - val_loss: 0.3320 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9257 - loss: 0.4040 - val_accuracy: 0.9667 - val_loss: 0.3221 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9404 - loss: 0.3818 - val_accuracy: 0.9750 - val_loss: 0.3116 - learning_rate: 5.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9154 - loss: 0.4018 - val_accuracy: 0.9708 - val_loss: 0.3116 - learning_rate: 5.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9228 - loss: 0.3860 - val_accuracy: 0.9667 - val_loss: 0.3170 - learning_rate: 5.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9441 - loss: 0.3635 - val_accuracy: 0.9625 - val_loss: 0.3180 - learning_rate: 5.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9243 - loss: 0.3888 - val_accuracy: 0.9625 - val_loss: 0.3115 - learning_rate: 5.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9360 - loss: 0.3801 - val_accuracy: 0.9667 - val_loss: 0.3043 - learning_rate: 5.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9368 - loss: 0.3658 - val_accuracy: 0.9667 - val_loss: 0.3147 - learning_rate: 5.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9228 - loss: 0.3850 - val_accuracy: 0.9708 - val_loss: 0.3024 - learning_rate: 5.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9287 - loss: 0.3646 - val_accuracy: 0.9750 - val_loss: 0.2975 - learning_rate: 5.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9338 - loss: 0.3647 - val_accuracy: 0.9667 - val_loss: 0.3006 - learning_rate: 5.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9221 - loss: 0.3872 - val_accuracy: 0.9708 - val_loss: 0.2962 - learning_rate: 5.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9257 - loss: 0.3682 - val_accuracy: 0.9667 - val_loss: 0.2986 - learning_rate: 5.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9353 - loss: 0.3581 - val_accuracy: 0.9750 - val_loss: 0.2976 - learning_rate: 5.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9309 - loss: 0.3577 - val_accuracy: 0.9625 - val_loss: 0.2953 - learning_rate: 5.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9279 - loss: 0.3651 - val_accuracy: 0.9667 - val_loss: 0.2871 - learning_rate: 5.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9346 - loss: 0.3606 - val_accuracy: 0.9750 - val_loss: 0.2904 - learning_rate: 5.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9301 - loss: 0.3539 - val_accuracy: 0.9708 - val_loss: 0.2884 - learning_rate: 5.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9441 - loss: 0.3521 - val_accuracy: 0.9667 - val_loss: 0.2891 - learning_rate: 5.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9250 - loss: 0.3536 - val_accuracy: 0.9625 - val_loss: 0.2878 - learning_rate: 5.0000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9316 - loss: 0.3545 - val_accuracy: 0.9750 - val_loss: 0.2833 - learning_rate: 5.0000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9360 - loss: 0.3533 - val_accuracy: 0.9708 - val_loss: 0.2842 - learning_rate: 5.0000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9316 - loss: 0.3426 - val_accuracy: 0.9708 - val_loss: 0.2808 - learning_rate: 5.0000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9397 - loss: 0.3401 - val_accuracy: 0.9708 - val_loss: 0.2755 - learning_rate: 5.0000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9265 - loss: 0.3593 - val_accuracy: 0.9750 - val_loss: 0.2753 - learning_rate: 5.0000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9419 - loss: 0.3351 - val_accuracy: 0.9708 - val_loss: 0.2811 - learning_rate: 5.0000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9368 - loss: 0.3469 - val_accuracy: 0.9708 - val_loss: 0.2752 - learning_rate: 5.0000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9397 - loss: 0.3451 - val_accuracy: 0.9750 - val_loss: 0.2688 - learning_rate: 5.0000e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9316 - loss: 0.3337 - val_accuracy: 0.9708 - val_loss: 0.2659 - learning_rate: 5.0000e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9316 - loss: 0.3407 - val_accuracy: 0.9750 - val_loss: 0.2674 - learning_rate: 5.0000e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9324 - loss: 0.3410 - val_accuracy: 0.9750 - val_loss: 0.2653 - learning_rate: 5.0000e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9419 - loss: 0.3244 - val_accuracy: 0.9750 - val_loss: 0.2649 - learning_rate: 5.0000e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9294 - loss: 0.3349 - val_accuracy: 0.9750 - val_loss: 0.2640 - learning_rate: 5.0000e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9397 - loss: 0.3444 - val_accuracy: 0.9750 - val_loss: 0.2616 - learning_rate: 5.0000e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9456 - loss: 0.3137 - val_accuracy: 0.9792 - val_loss: 0.2596 - learning_rate: 5.0000e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9412 - loss: 0.3311 - val_accuracy: 0.9667 - val_loss: 0.2623 - learning_rate: 5.0000e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9257 - loss: 0.3269 - val_accuracy: 0.9792 - val_loss: 0.2606 - learning_rate: 5.0000e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9324 - loss: 0.3370 - val_accuracy: 0.9792 - val_loss: 0.2573 - learning_rate: 5.0000e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9419 - loss: 0.3138 - val_accuracy: 0.9708 - val_loss: 0.2555 - learning_rate: 5.0000e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9287 - loss: 0.3233 - val_accuracy: 0.9667 - val_loss: 0.2547 - learning_rate: 5.0000e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9441 - loss: 0.3108 - val_accuracy: 0.9708 - val_loss: 0.2603 - learning_rate: 5.0000e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9324 - loss: 0.3264 - val_accuracy: 0.9708 - val_loss: 0.2553 - learning_rate: 5.0000e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9390 - loss: 0.3158 - val_accuracy: 0.9667 - val_loss: 0.2479 - learning_rate: 5.0000e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9382 - loss: 0.3176 - val_accuracy: 0.9708 - val_loss: 0.2498 - learning_rate: 5.0000e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9397 - loss: 0.3110 - val_accuracy: 0.9708 - val_loss: 0.2470 - learning_rate: 5.0000e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.9331 - loss: 0.3270 - val_accuracy: 0.9750 - val_loss: 0.2426 - learning_rate: 5.0000e-05\n",
      "Epoch 198/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9412 - loss: 0.3019 - val_accuracy: 0.9750 - val_loss: 0.2427 - learning_rate: 5.0000e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9412 - loss: 0.3125 - val_accuracy: 0.9708 - val_loss: 0.2426 - learning_rate: 5.0000e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.9390 - loss: 0.3211 - val_accuracy: 0.9708 - val_loss: 0.2417 - learning_rate: 5.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 200.\n",
      "\n",
      "âœ… Fold 3 Results:\n",
      "  Test Accuracy: 0.9625\n",
      "  Test AUC: 0.9919\n",
      "  Test Loss: 0.2815\n",
      "ğŸŒŸ New best model! Fold 3 with accuracy: 0.9625\n",
      "\n",
      "Fold 3 Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                NORMAL     0.9503    0.9563    0.9533       160\n",
      "ALL (INTERICTAL+ICTAL)     0.9707    0.9667    0.9687       240\n",
      "\n",
      "              accuracy                         0.9625       400\n",
      "             macro avg     0.9605    0.9615    0.9610       400\n",
      "          weighted avg     0.9626    0.9625    0.9625       400\n",
      "\n",
      "\n",
      "============================================================\n",
      " FOLD 4\n",
      "============================================================\n",
      "\n",
      "Train: 1360, Val: 240, Test: 400\n",
      "Test set distribution: (array([0, 1]), array([160, 240], dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Fold 4...\n",
      "ğŸ“Š Using data augmentation with real-time generator\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 89ms/step - accuracy: 0.5199 - loss: 1.5644 - val_accuracy: 0.6000 - val_loss: 1.5472 - learning_rate: 5.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.5213 - loss: 1.5497 - val_accuracy: 0.6000 - val_loss: 1.5329 - learning_rate: 5.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.5449 - loss: 1.5296 - val_accuracy: 0.6000 - val_loss: 1.5175 - learning_rate: 5.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.5375 - loss: 1.5163 - val_accuracy: 0.6000 - val_loss: 1.5012 - learning_rate: 5.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.5743 - loss: 1.4958 - val_accuracy: 0.6000 - val_loss: 1.4836 - learning_rate: 5.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.5640 - loss: 1.4879 - val_accuracy: 0.6000 - val_loss: 1.4669 - learning_rate: 5.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.5794 - loss: 1.4671 - val_accuracy: 0.6000 - val_loss: 1.4485 - learning_rate: 5.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.6162 - loss: 1.4450 - val_accuracy: 0.6000 - val_loss: 1.4281 - learning_rate: 5.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.5647 - loss: 1.4439 - val_accuracy: 0.6000 - val_loss: 1.4091 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.5691 - loss: 1.4253 - val_accuracy: 0.6000 - val_loss: 1.3914 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.5963 - loss: 1.4094 - val_accuracy: 0.6000 - val_loss: 1.3735 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.5860 - loss: 1.3948 - val_accuracy: 0.6000 - val_loss: 1.3561 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6118 - loss: 1.3785 - val_accuracy: 0.6042 - val_loss: 1.3371 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6132 - loss: 1.3590 - val_accuracy: 0.6083 - val_loss: 1.3174 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6132 - loss: 1.3474 - val_accuracy: 0.6125 - val_loss: 1.2981 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6265 - loss: 1.3202 - val_accuracy: 0.6208 - val_loss: 1.2785 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6529 - loss: 1.3065 - val_accuracy: 0.6625 - val_loss: 1.2539 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6500 - loss: 1.2899 - val_accuracy: 0.6625 - val_loss: 1.2386 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6596 - loss: 1.2746 - val_accuracy: 0.6792 - val_loss: 1.2194 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6721 - loss: 1.2443 - val_accuracy: 0.7125 - val_loss: 1.1967 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6801 - loss: 1.2331 - val_accuracy: 0.7333 - val_loss: 1.1816 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7294 - loss: 1.2036 - val_accuracy: 0.7417 - val_loss: 1.1682 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.7434 - loss: 1.1841 - val_accuracy: 0.7917 - val_loss: 1.1391 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.7397 - loss: 1.1792 - val_accuracy: 0.8042 - val_loss: 1.1238 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.7419 - loss: 1.1570 - val_accuracy: 0.8083 - val_loss: 1.1072 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.7581 - loss: 1.1322 - val_accuracy: 0.7833 - val_loss: 1.1249 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.7544 - loss: 1.1348 - val_accuracy: 0.8167 - val_loss: 1.0805 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7728 - loss: 1.1124 - val_accuracy: 0.8458 - val_loss: 1.0527 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.7735 - loss: 1.1036 - val_accuracy: 0.8458 - val_loss: 1.0402 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.7779 - loss: 1.0842 - val_accuracy: 0.8417 - val_loss: 1.0237 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8125 - loss: 1.0611 - val_accuracy: 0.8333 - val_loss: 1.0340 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.7875 - loss: 1.0712 - val_accuracy: 0.8625 - val_loss: 1.0005 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8044 - loss: 1.0387 - val_accuracy: 0.8542 - val_loss: 0.9842 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8029 - loss: 1.0306 - val_accuracy: 0.8458 - val_loss: 0.9930 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8243 - loss: 1.0110 - val_accuracy: 0.8292 - val_loss: 1.0039 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8140 - loss: 1.0080 - val_accuracy: 0.8583 - val_loss: 0.9555 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8132 - loss: 0.9922 - val_accuracy: 0.8625 - val_loss: 0.9503 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8235 - loss: 0.9918 - val_accuracy: 0.8708 - val_loss: 0.9255 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8103 - loss: 0.9735 - val_accuracy: 0.8625 - val_loss: 0.9277 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8316 - loss: 0.9513 - val_accuracy: 0.8667 - val_loss: 0.9022 - learning_rate: 5.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8316 - loss: 0.9563 - val_accuracy: 0.8833 - val_loss: 0.8871 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8265 - loss: 0.9506 - val_accuracy: 0.8750 - val_loss: 0.8796 - learning_rate: 5.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8478 - loss: 0.9243 - val_accuracy: 0.8708 - val_loss: 0.8705 - learning_rate: 5.0000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8426 - loss: 0.9214 - val_accuracy: 0.8625 - val_loss: 0.8864 - learning_rate: 5.0000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8426 - loss: 0.9046 - val_accuracy: 0.8750 - val_loss: 0.8471 - learning_rate: 5.0000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8221 - loss: 0.9147 - val_accuracy: 0.8750 - val_loss: 0.8555 - learning_rate: 5.0000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8404 - loss: 0.8957 - val_accuracy: 0.8750 - val_loss: 0.8422 - learning_rate: 5.0000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8441 - loss: 0.8857 - val_accuracy: 0.8833 - val_loss: 0.8176 - learning_rate: 5.0000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8390 - loss: 0.8803 - val_accuracy: 0.8958 - val_loss: 0.8071 - learning_rate: 5.0000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8574 - loss: 0.8577 - val_accuracy: 0.9000 - val_loss: 0.7962 - learning_rate: 5.0000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8676 - loss: 0.8431 - val_accuracy: 0.9083 - val_loss: 0.7881 - learning_rate: 5.0000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8397 - loss: 0.8536 - val_accuracy: 0.9125 - val_loss: 0.7783 - learning_rate: 5.0000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8544 - loss: 0.8240 - val_accuracy: 0.9125 - val_loss: 0.7686 - learning_rate: 5.0000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8522 - loss: 0.8333 - val_accuracy: 0.9125 - val_loss: 0.7597 - learning_rate: 5.0000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8588 - loss: 0.8164 - val_accuracy: 0.9000 - val_loss: 0.7556 - learning_rate: 5.0000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8654 - loss: 0.8099 - val_accuracy: 0.9167 - val_loss: 0.7442 - learning_rate: 5.0000e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8515 - loss: 0.7978 - val_accuracy: 0.9083 - val_loss: 0.7402 - learning_rate: 5.0000e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8596 - loss: 0.7980 - val_accuracy: 0.9042 - val_loss: 0.7364 - learning_rate: 5.0000e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8537 - loss: 0.7824 - val_accuracy: 0.9208 - val_loss: 0.7211 - learning_rate: 5.0000e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8684 - loss: 0.7657 - val_accuracy: 0.9167 - val_loss: 0.7118 - learning_rate: 5.0000e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8706 - loss: 0.7648 - val_accuracy: 0.9208 - val_loss: 0.7046 - learning_rate: 5.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.8743 - loss: 0.7578 - val_accuracy: 0.9125 - val_loss: 0.6970 - learning_rate: 5.0000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8794 - loss: 0.7433 - val_accuracy: 0.9167 - val_loss: 0.6889 - learning_rate: 5.0000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8721 - loss: 0.7430 - val_accuracy: 0.9125 - val_loss: 0.6875 - learning_rate: 5.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8860 - loss: 0.7193 - val_accuracy: 0.9208 - val_loss: 0.6785 - learning_rate: 5.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8860 - loss: 0.7103 - val_accuracy: 0.9208 - val_loss: 0.6755 - learning_rate: 5.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8824 - loss: 0.7051 - val_accuracy: 0.9000 - val_loss: 0.6688 - learning_rate: 5.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8699 - loss: 0.7188 - val_accuracy: 0.9208 - val_loss: 0.6513 - learning_rate: 5.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8838 - loss: 0.6995 - val_accuracy: 0.9250 - val_loss: 0.6477 - learning_rate: 5.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8949 - loss: 0.6874 - val_accuracy: 0.9292 - val_loss: 0.6397 - learning_rate: 5.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8949 - loss: 0.6863 - val_accuracy: 0.9333 - val_loss: 0.6334 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8890 - loss: 0.6792 - val_accuracy: 0.9292 - val_loss: 0.6278 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8809 - loss: 0.6740 - val_accuracy: 0.9250 - val_loss: 0.6237 - learning_rate: 5.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8779 - loss: 0.6829 - val_accuracy: 0.9292 - val_loss: 0.6117 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8882 - loss: 0.6543 - val_accuracy: 0.9292 - val_loss: 0.6137 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8985 - loss: 0.6413 - val_accuracy: 0.9250 - val_loss: 0.6131 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8875 - loss: 0.6514 - val_accuracy: 0.9208 - val_loss: 0.6020 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8809 - loss: 0.6505 - val_accuracy: 0.9250 - val_loss: 0.6011 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9029 - loss: 0.6352 - val_accuracy: 0.9292 - val_loss: 0.5877 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8868 - loss: 0.6597 - val_accuracy: 0.9250 - val_loss: 0.5739 - learning_rate: 5.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9000 - loss: 0.6274 - val_accuracy: 0.9208 - val_loss: 0.5872 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8868 - loss: 0.6249 - val_accuracy: 0.9250 - val_loss: 0.5791 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8956 - loss: 0.6141 - val_accuracy: 0.9375 - val_loss: 0.5683 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9000 - loss: 0.5928 - val_accuracy: 0.9375 - val_loss: 0.5635 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9015 - loss: 0.6111 - val_accuracy: 0.9333 - val_loss: 0.5555 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8956 - loss: 0.6101 - val_accuracy: 0.9250 - val_loss: 0.5641 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8963 - loss: 0.5933 - val_accuracy: 0.9375 - val_loss: 0.5417 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9007 - loss: 0.5850 - val_accuracy: 0.9417 - val_loss: 0.5301 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8926 - loss: 0.5813 - val_accuracy: 0.9333 - val_loss: 0.5338 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9051 - loss: 0.5779 - val_accuracy: 0.9375 - val_loss: 0.5294 - learning_rate: 5.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8904 - loss: 0.5750 - val_accuracy: 0.9375 - val_loss: 0.5246 - learning_rate: 5.0000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9162 - loss: 0.5616 - val_accuracy: 0.9458 - val_loss: 0.5182 - learning_rate: 5.0000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.8934 - loss: 0.5633 - val_accuracy: 0.9500 - val_loss: 0.5100 - learning_rate: 5.0000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9147 - loss: 0.5477 - val_accuracy: 0.9333 - val_loss: 0.5260 - learning_rate: 5.0000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9051 - loss: 0.5502 - val_accuracy: 0.9292 - val_loss: 0.5205 - learning_rate: 5.0000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9103 - loss: 0.5531 - val_accuracy: 0.9375 - val_loss: 0.5084 - learning_rate: 5.0000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9103 - loss: 0.5436 - val_accuracy: 0.9417 - val_loss: 0.4977 - learning_rate: 5.0000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9066 - loss: 0.5463 - val_accuracy: 0.9333 - val_loss: 0.4974 - learning_rate: 5.0000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8963 - loss: 0.5531 - val_accuracy: 0.9500 - val_loss: 0.4882 - learning_rate: 5.0000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9147 - loss: 0.5273 - val_accuracy: 0.9333 - val_loss: 0.4936 - learning_rate: 5.0000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9074 - loss: 0.5291 - val_accuracy: 0.9542 - val_loss: 0.4765 - learning_rate: 5.0000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8971 - loss: 0.5316 - val_accuracy: 0.9458 - val_loss: 0.4782 - learning_rate: 5.0000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9066 - loss: 0.5238 - val_accuracy: 0.9542 - val_loss: 0.4724 - learning_rate: 5.0000e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9132 - loss: 0.5200 - val_accuracy: 0.9542 - val_loss: 0.4626 - learning_rate: 5.0000e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9059 - loss: 0.5188 - val_accuracy: 0.9500 - val_loss: 0.4639 - learning_rate: 5.0000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9051 - loss: 0.5162 - val_accuracy: 0.9542 - val_loss: 0.4596 - learning_rate: 5.0000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9074 - loss: 0.5077 - val_accuracy: 0.9500 - val_loss: 0.4643 - learning_rate: 5.0000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9184 - loss: 0.4964 - val_accuracy: 0.9500 - val_loss: 0.4589 - learning_rate: 5.0000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9000 - loss: 0.5036 - val_accuracy: 0.9542 - val_loss: 0.4521 - learning_rate: 5.0000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9206 - loss: 0.4895 - val_accuracy: 0.9500 - val_loss: 0.4432 - learning_rate: 5.0000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9206 - loss: 0.4888 - val_accuracy: 0.9500 - val_loss: 0.4429 - learning_rate: 5.0000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9221 - loss: 0.4730 - val_accuracy: 0.9542 - val_loss: 0.4431 - learning_rate: 5.0000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9066 - loss: 0.4931 - val_accuracy: 0.9583 - val_loss: 0.4386 - learning_rate: 5.0000e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9140 - loss: 0.4848 - val_accuracy: 0.9500 - val_loss: 0.4340 - learning_rate: 5.0000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9191 - loss: 0.4740 - val_accuracy: 0.9458 - val_loss: 0.4391 - learning_rate: 5.0000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9250 - loss: 0.4663 - val_accuracy: 0.9500 - val_loss: 0.4366 - learning_rate: 5.0000e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9147 - loss: 0.4730 - val_accuracy: 0.9500 - val_loss: 0.4338 - learning_rate: 5.0000e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9118 - loss: 0.4768 - val_accuracy: 0.9542 - val_loss: 0.4303 - learning_rate: 5.0000e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9096 - loss: 0.4585 - val_accuracy: 0.9542 - val_loss: 0.4218 - learning_rate: 5.0000e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9235 - loss: 0.4493 - val_accuracy: 0.9542 - val_loss: 0.4227 - learning_rate: 5.0000e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 76ms/step - accuracy: 0.9199 - loss: 0.4492 - val_accuracy: 0.9542 - val_loss: 0.4184 - learning_rate: 5.0000e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8971 - loss: 0.4705 - val_accuracy: 0.9417 - val_loss: 0.4020 - learning_rate: 5.0000e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9243 - loss: 0.4488 - val_accuracy: 0.9542 - val_loss: 0.4041 - learning_rate: 5.0000e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9154 - loss: 0.4395 - val_accuracy: 0.9500 - val_loss: 0.4150 - learning_rate: 5.0000e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9125 - loss: 0.4522 - val_accuracy: 0.9542 - val_loss: 0.3901 - learning_rate: 5.0000e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9213 - loss: 0.4358 - val_accuracy: 0.9542 - val_loss: 0.4011 - learning_rate: 5.0000e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9265 - loss: 0.4281 - val_accuracy: 0.9500 - val_loss: 0.4035 - learning_rate: 5.0000e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9176 - loss: 0.4337 - val_accuracy: 0.9542 - val_loss: 0.3989 - learning_rate: 5.0000e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9184 - loss: 0.4360 - val_accuracy: 0.9542 - val_loss: 0.3907 - learning_rate: 5.0000e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9118 - loss: 0.4259 - val_accuracy: 0.9417 - val_loss: 0.3895 - learning_rate: 5.0000e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9243 - loss: 0.4188 - val_accuracy: 0.9542 - val_loss: 0.3956 - learning_rate: 5.0000e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9191 - loss: 0.4259 - val_accuracy: 0.9500 - val_loss: 0.3859 - learning_rate: 5.0000e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9301 - loss: 0.4163 - val_accuracy: 0.9542 - val_loss: 0.3776 - learning_rate: 5.0000e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9272 - loss: 0.4128 - val_accuracy: 0.9458 - val_loss: 0.3973 - learning_rate: 5.0000e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9331 - loss: 0.4182 - val_accuracy: 0.9542 - val_loss: 0.3726 - learning_rate: 5.0000e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9272 - loss: 0.4049 - val_accuracy: 0.9500 - val_loss: 0.3744 - learning_rate: 5.0000e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9235 - loss: 0.4064 - val_accuracy: 0.9583 - val_loss: 0.3641 - learning_rate: 5.0000e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9154 - loss: 0.4106 - val_accuracy: 0.9500 - val_loss: 0.3709 - learning_rate: 5.0000e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9191 - loss: 0.4069 - val_accuracy: 0.9542 - val_loss: 0.3782 - learning_rate: 5.0000e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9257 - loss: 0.4024 - val_accuracy: 0.9542 - val_loss: 0.3787 - learning_rate: 5.0000e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9301 - loss: 0.3944 - val_accuracy: 0.9500 - val_loss: 0.3632 - learning_rate: 5.0000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9316 - loss: 0.4023 - val_accuracy: 0.9500 - val_loss: 0.3601 - learning_rate: 5.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9235 - loss: 0.4024 - val_accuracy: 0.9458 - val_loss: 0.3709 - learning_rate: 5.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9250 - loss: 0.3917 - val_accuracy: 0.9542 - val_loss: 0.3611 - learning_rate: 5.0000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9169 - loss: 0.3980 - val_accuracy: 0.9500 - val_loss: 0.3509 - learning_rate: 5.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9235 - loss: 0.4007 - val_accuracy: 0.9542 - val_loss: 0.3563 - learning_rate: 5.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9324 - loss: 0.3897 - val_accuracy: 0.9542 - val_loss: 0.3546 - learning_rate: 5.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9257 - loss: 0.3863 - val_accuracy: 0.9500 - val_loss: 0.3476 - learning_rate: 5.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9346 - loss: 0.3708 - val_accuracy: 0.9542 - val_loss: 0.3571 - learning_rate: 5.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9235 - loss: 0.3854 - val_accuracy: 0.9500 - val_loss: 0.3463 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9287 - loss: 0.3712 - val_accuracy: 0.9542 - val_loss: 0.3462 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9360 - loss: 0.3649 - val_accuracy: 0.9500 - val_loss: 0.3560 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9235 - loss: 0.3808 - val_accuracy: 0.9542 - val_loss: 0.3332 - learning_rate: 5.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9360 - loss: 0.3596 - val_accuracy: 0.9458 - val_loss: 0.3457 - learning_rate: 5.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9301 - loss: 0.3752 - val_accuracy: 0.9542 - val_loss: 0.3360 - learning_rate: 5.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9316 - loss: 0.3633 - val_accuracy: 0.9542 - val_loss: 0.3392 - learning_rate: 5.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9250 - loss: 0.3777 - val_accuracy: 0.9542 - val_loss: 0.3304 - learning_rate: 5.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9265 - loss: 0.3631 - val_accuracy: 0.9542 - val_loss: 0.3306 - learning_rate: 5.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9309 - loss: 0.3662 - val_accuracy: 0.9583 - val_loss: 0.3288 - learning_rate: 5.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9309 - loss: 0.3601 - val_accuracy: 0.9458 - val_loss: 0.3336 - learning_rate: 5.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9221 - loss: 0.3619 - val_accuracy: 0.9500 - val_loss: 0.3309 - learning_rate: 5.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9235 - loss: 0.3609 - val_accuracy: 0.9583 - val_loss: 0.3181 - learning_rate: 5.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9404 - loss: 0.3464 - val_accuracy: 0.9542 - val_loss: 0.3227 - learning_rate: 5.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9279 - loss: 0.3426 - val_accuracy: 0.9583 - val_loss: 0.3144 - learning_rate: 5.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9324 - loss: 0.3506 - val_accuracy: 0.9625 - val_loss: 0.3098 - learning_rate: 5.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9301 - loss: 0.3528 - val_accuracy: 0.9542 - val_loss: 0.3163 - learning_rate: 5.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9294 - loss: 0.3440 - val_accuracy: 0.9500 - val_loss: 0.3319 - learning_rate: 5.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9294 - loss: 0.3526 - val_accuracy: 0.9625 - val_loss: 0.3051 - learning_rate: 5.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9412 - loss: 0.3366 - val_accuracy: 0.9500 - val_loss: 0.3206 - learning_rate: 5.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9346 - loss: 0.3305 - val_accuracy: 0.9500 - val_loss: 0.3172 - learning_rate: 5.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9338 - loss: 0.3439 - val_accuracy: 0.9542 - val_loss: 0.3139 - learning_rate: 5.0000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9324 - loss: 0.3326 - val_accuracy: 0.9625 - val_loss: 0.2972 - learning_rate: 5.0000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9375 - loss: 0.3322 - val_accuracy: 0.9500 - val_loss: 0.3087 - learning_rate: 5.0000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9375 - loss: 0.3234 - val_accuracy: 0.9625 - val_loss: 0.2965 - learning_rate: 5.0000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9360 - loss: 0.3309 - val_accuracy: 0.9583 - val_loss: 0.3023 - learning_rate: 5.0000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9419 - loss: 0.3169 - val_accuracy: 0.9500 - val_loss: 0.3145 - learning_rate: 5.0000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9353 - loss: 0.3386 - val_accuracy: 0.9583 - val_loss: 0.3019 - learning_rate: 5.0000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9441 - loss: 0.3282 - val_accuracy: 0.9542 - val_loss: 0.3048 - learning_rate: 5.0000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9404 - loss: 0.3169 - val_accuracy: 0.9542 - val_loss: 0.3051 - learning_rate: 5.0000e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9324 - loss: 0.3321 - val_accuracy: 0.9625 - val_loss: 0.2984 - learning_rate: 5.0000e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9353 - loss: 0.3231 - val_accuracy: 0.9625 - val_loss: 0.2887 - learning_rate: 5.0000e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9382 - loss: 0.3237 - val_accuracy: 0.9625 - val_loss: 0.2899 - learning_rate: 5.0000e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9353 - loss: 0.3209 - val_accuracy: 0.9583 - val_loss: 0.2897 - learning_rate: 5.0000e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9301 - loss: 0.3104 - val_accuracy: 0.9583 - val_loss: 0.2888 - learning_rate: 5.0000e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9441 - loss: 0.3250 - val_accuracy: 0.9542 - val_loss: 0.2926 - learning_rate: 5.0000e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9426 - loss: 0.3051 - val_accuracy: 0.9542 - val_loss: 0.2942 - learning_rate: 5.0000e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9360 - loss: 0.3112 - val_accuracy: 0.9625 - val_loss: 0.2860 - learning_rate: 5.0000e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9419 - loss: 0.3059 - val_accuracy: 0.9583 - val_loss: 0.2910 - learning_rate: 5.0000e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9412 - loss: 0.3142 - val_accuracy: 0.9625 - val_loss: 0.2922 - learning_rate: 5.0000e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9382 - loss: 0.3096 - val_accuracy: 0.9542 - val_loss: 0.2937 - learning_rate: 5.0000e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9309 - loss: 0.3141 - val_accuracy: 0.9583 - val_loss: 0.2856 - learning_rate: 5.0000e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9426 - loss: 0.3025 - val_accuracy: 0.9583 - val_loss: 0.2862 - learning_rate: 5.0000e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 87ms/step - accuracy: 0.9324 - loss: 0.3151 - val_accuracy: 0.9500 - val_loss: 0.3033 - learning_rate: 5.0000e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9382 - loss: 0.3140 - val_accuracy: 0.9625 - val_loss: 0.2769 - learning_rate: 5.0000e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9441 - loss: 0.2976 - val_accuracy: 0.9583 - val_loss: 0.2797 - learning_rate: 5.0000e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9412 - loss: 0.2859 - val_accuracy: 0.9583 - val_loss: 0.2842 - learning_rate: 5.0000e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9515 - loss: 0.2795 - val_accuracy: 0.9625 - val_loss: 0.2794 - learning_rate: 5.0000e-05\n",
      "Epoch 198/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9360 - loss: 0.3093 - val_accuracy: 0.9625 - val_loss: 0.2713 - learning_rate: 5.0000e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9375 - loss: 0.2928 - val_accuracy: 0.9583 - val_loss: 0.2849 - learning_rate: 5.0000e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9390 - loss: 0.2938 - val_accuracy: 0.9625 - val_loss: 0.2690 - learning_rate: 5.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 200.\n",
      "\n",
      "âœ… Fold 4 Results:\n",
      "  Test Accuracy: 0.9675\n",
      "  Test AUC: 0.9957\n",
      "  Test Loss: 0.2826\n",
      "ğŸŒŸ New best model! Fold 4 with accuracy: 0.9675\n",
      "\n",
      "Fold 4 Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                NORMAL     0.9682    0.9500    0.9590       160\n",
      "ALL (INTERICTAL+ICTAL)     0.9671    0.9792    0.9731       240\n",
      "\n",
      "              accuracy                         0.9675       400\n",
      "             macro avg     0.9676    0.9646    0.9660       400\n",
      "          weighted avg     0.9675    0.9675    0.9674       400\n",
      "\n",
      "\n",
      "============================================================\n",
      " FOLD 5\n",
      "============================================================\n",
      "\n",
      "Train: 1360, Val: 240, Test: 400\n",
      "Test set distribution: (array([0, 1]), array([160, 240], dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Fold 5...\n",
      "ğŸ“Š Using data augmentation with real-time generator\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 89ms/step - accuracy: 0.5169 - loss: 1.5750 - val_accuracy: 0.6000 - val_loss: 1.5480 - learning_rate: 5.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.5551 - loss: 1.5506 - val_accuracy: 0.6000 - val_loss: 1.5271 - learning_rate: 5.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.5787 - loss: 1.5266 - val_accuracy: 0.6000 - val_loss: 1.5083 - learning_rate: 5.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.5801 - loss: 1.5133 - val_accuracy: 0.6000 - val_loss: 1.4915 - learning_rate: 5.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.5735 - loss: 1.4973 - val_accuracy: 0.6000 - val_loss: 1.4753 - learning_rate: 5.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.5831 - loss: 1.4843 - val_accuracy: 0.6000 - val_loss: 1.4595 - learning_rate: 5.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.5963 - loss: 1.4624 - val_accuracy: 0.6000 - val_loss: 1.4420 - learning_rate: 5.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.5816 - loss: 1.4511 - val_accuracy: 0.6000 - val_loss: 1.4224 - learning_rate: 5.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.5882 - loss: 1.4347 - val_accuracy: 0.6000 - val_loss: 1.4032 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.5934 - loss: 1.4188 - val_accuracy: 0.6000 - val_loss: 1.3846 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6169 - loss: 1.3962 - val_accuracy: 0.6042 - val_loss: 1.3652 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6140 - loss: 1.3811 - val_accuracy: 0.6208 - val_loss: 1.3466 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6257 - loss: 1.3573 - val_accuracy: 0.6333 - val_loss: 1.3263 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6184 - loss: 1.3485 - val_accuracy: 0.6333 - val_loss: 1.3090 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6368 - loss: 1.3247 - val_accuracy: 0.6417 - val_loss: 1.2933 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6324 - loss: 1.3069 - val_accuracy: 0.6625 - val_loss: 1.2712 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6699 - loss: 1.2786 - val_accuracy: 0.6583 - val_loss: 1.2490 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6824 - loss: 1.2634 - val_accuracy: 0.6625 - val_loss: 1.2364 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6897 - loss: 1.2482 - val_accuracy: 0.7083 - val_loss: 1.2100 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.7051 - loss: 1.2218 - val_accuracy: 0.6958 - val_loss: 1.2159 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.7059 - loss: 1.2182 - val_accuracy: 0.7083 - val_loss: 1.2004 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.7074 - loss: 1.1958 - val_accuracy: 0.7208 - val_loss: 1.1717 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.7243 - loss: 1.1706 - val_accuracy: 0.7333 - val_loss: 1.1627 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.7449 - loss: 1.1585 - val_accuracy: 0.7833 - val_loss: 1.1406 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.7515 - loss: 1.1396 - val_accuracy: 0.7542 - val_loss: 1.1458 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.7544 - loss: 1.1354 - val_accuracy: 0.7083 - val_loss: 1.1769 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.7397 - loss: 1.1198 - val_accuracy: 0.7667 - val_loss: 1.1105 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.7640 - loss: 1.1082 - val_accuracy: 0.7625 - val_loss: 1.1118 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.7787 - loss: 1.0808 - val_accuracy: 0.8167 - val_loss: 1.0693 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.7919 - loss: 1.0703 - val_accuracy: 0.8458 - val_loss: 1.0163 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.7985 - loss: 1.0514 - val_accuracy: 0.8208 - val_loss: 1.0507 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8044 - loss: 1.0375 - val_accuracy: 0.8208 - val_loss: 1.0500 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8022 - loss: 1.0407 - val_accuracy: 0.7500 - val_loss: 1.1031 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8132 - loss: 1.0152 - val_accuracy: 0.8417 - val_loss: 0.9700 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8191 - loss: 1.0131 - val_accuracy: 0.8375 - val_loss: 0.9839 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8191 - loss: 0.9917 - val_accuracy: 0.8583 - val_loss: 0.9439 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8221 - loss: 0.9771 - val_accuracy: 0.8500 - val_loss: 0.9534 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8176 - loss: 0.9829 - val_accuracy: 0.8500 - val_loss: 0.9292 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8029 - loss: 0.9781 - val_accuracy: 0.8458 - val_loss: 0.9314 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8206 - loss: 0.9597 - val_accuracy: 0.8458 - val_loss: 0.9178 - learning_rate: 5.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8368 - loss: 0.9429 - val_accuracy: 0.8458 - val_loss: 0.9123 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8088 - loss: 0.9445 - val_accuracy: 0.8292 - val_loss: 0.9429 - learning_rate: 5.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8162 - loss: 0.9232 - val_accuracy: 0.7833 - val_loss: 0.9845 - learning_rate: 5.0000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8169 - loss: 0.9193 - val_accuracy: 0.8583 - val_loss: 0.8661 - learning_rate: 5.0000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8199 - loss: 0.9010 - val_accuracy: 0.8542 - val_loss: 0.8628 - learning_rate: 5.0000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8544 - loss: 0.8852 - val_accuracy: 0.8500 - val_loss: 0.8708 - learning_rate: 5.0000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8301 - loss: 0.8933 - val_accuracy: 0.8542 - val_loss: 0.8543 - learning_rate: 5.0000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8522 - loss: 0.8692 - val_accuracy: 0.8125 - val_loss: 0.8996 - learning_rate: 5.0000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8456 - loss: 0.8633 - val_accuracy: 0.8542 - val_loss: 0.8489 - learning_rate: 5.0000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8449 - loss: 0.8537 - val_accuracy: 0.8667 - val_loss: 0.8308 - learning_rate: 5.0000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8507 - loss: 0.8333 - val_accuracy: 0.8667 - val_loss: 0.8221 - learning_rate: 5.0000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8471 - loss: 0.8463 - val_accuracy: 0.8667 - val_loss: 0.8109 - learning_rate: 5.0000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8537 - loss: 0.8315 - val_accuracy: 0.8792 - val_loss: 0.7690 - learning_rate: 5.0000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8551 - loss: 0.8104 - val_accuracy: 0.8792 - val_loss: 0.7779 - learning_rate: 5.0000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8625 - loss: 0.8112 - val_accuracy: 0.8833 - val_loss: 0.7665 - learning_rate: 5.0000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8574 - loss: 0.8011 - val_accuracy: 0.8750 - val_loss: 0.7827 - learning_rate: 5.0000e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8559 - loss: 0.7908 - val_accuracy: 0.8708 - val_loss: 0.7816 - learning_rate: 5.0000e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8618 - loss: 0.7914 - val_accuracy: 0.8958 - val_loss: 0.7366 - learning_rate: 5.0000e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8765 - loss: 0.7546 - val_accuracy: 0.8958 - val_loss: 0.7325 - learning_rate: 5.0000e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8728 - loss: 0.7742 - val_accuracy: 0.8917 - val_loss: 0.7111 - learning_rate: 5.0000e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8625 - loss: 0.7679 - val_accuracy: 0.8833 - val_loss: 0.7333 - learning_rate: 5.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8713 - loss: 0.7449 - val_accuracy: 0.8958 - val_loss: 0.7022 - learning_rate: 5.0000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8750 - loss: 0.7389 - val_accuracy: 0.9000 - val_loss: 0.6961 - learning_rate: 5.0000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8721 - loss: 0.7331 - val_accuracy: 0.9000 - val_loss: 0.6819 - learning_rate: 5.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8640 - loss: 0.7282 - val_accuracy: 0.8875 - val_loss: 0.7146 - learning_rate: 5.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8728 - loss: 0.7203 - val_accuracy: 0.9000 - val_loss: 0.6691 - learning_rate: 5.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8772 - loss: 0.7061 - val_accuracy: 0.8917 - val_loss: 0.6669 - learning_rate: 5.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8757 - loss: 0.7098 - val_accuracy: 0.8917 - val_loss: 0.6678 - learning_rate: 5.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8801 - loss: 0.7010 - val_accuracy: 0.8958 - val_loss: 0.6391 - learning_rate: 5.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8603 - loss: 0.6983 - val_accuracy: 0.9042 - val_loss: 0.6317 - learning_rate: 5.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8691 - loss: 0.6933 - val_accuracy: 0.9042 - val_loss: 0.6221 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8801 - loss: 0.6761 - val_accuracy: 0.9125 - val_loss: 0.6253 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8941 - loss: 0.6668 - val_accuracy: 0.9125 - val_loss: 0.6082 - learning_rate: 5.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8875 - loss: 0.6625 - val_accuracy: 0.9208 - val_loss: 0.6043 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8743 - loss: 0.6775 - val_accuracy: 0.9125 - val_loss: 0.6164 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8868 - loss: 0.6546 - val_accuracy: 0.9292 - val_loss: 0.5822 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8882 - loss: 0.6470 - val_accuracy: 0.9292 - val_loss: 0.5779 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9000 - loss: 0.6283 - val_accuracy: 0.9292 - val_loss: 0.5725 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8934 - loss: 0.6295 - val_accuracy: 0.9292 - val_loss: 0.5633 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8978 - loss: 0.6207 - val_accuracy: 0.9208 - val_loss: 0.5634 - learning_rate: 5.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8875 - loss: 0.6337 - val_accuracy: 0.9292 - val_loss: 0.5619 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8904 - loss: 0.6151 - val_accuracy: 0.9167 - val_loss: 0.5595 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8853 - loss: 0.6274 - val_accuracy: 0.9250 - val_loss: 0.5514 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8941 - loss: 0.6202 - val_accuracy: 0.9292 - val_loss: 0.5408 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9110 - loss: 0.5935 - val_accuracy: 0.9208 - val_loss: 0.5437 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8912 - loss: 0.5907 - val_accuracy: 0.9292 - val_loss: 0.5315 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.8846 - loss: 0.6030 - val_accuracy: 0.9250 - val_loss: 0.5287 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9162 - loss: 0.5771 - val_accuracy: 0.9292 - val_loss: 0.5156 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8860 - loss: 0.5996 - val_accuracy: 0.9292 - val_loss: 0.5073 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9044 - loss: 0.5705 - val_accuracy: 0.9333 - val_loss: 0.5043 - learning_rate: 5.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9110 - loss: 0.5597 - val_accuracy: 0.9333 - val_loss: 0.5040 - learning_rate: 5.0000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9029 - loss: 0.5560 - val_accuracy: 0.9292 - val_loss: 0.5052 - learning_rate: 5.0000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8949 - loss: 0.5666 - val_accuracy: 0.9292 - val_loss: 0.5012 - learning_rate: 5.0000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8971 - loss: 0.5629 - val_accuracy: 0.9167 - val_loss: 0.4919 - learning_rate: 5.0000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9059 - loss: 0.5483 - val_accuracy: 0.9167 - val_loss: 0.5050 - learning_rate: 5.0000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 77ms/step - accuracy: 0.9029 - loss: 0.5511 - val_accuracy: 0.9125 - val_loss: 0.5082 - learning_rate: 5.0000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9154 - loss: 0.5403 - val_accuracy: 0.9208 - val_loss: 0.4965 - learning_rate: 5.0000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9022 - loss: 0.5288 - val_accuracy: 0.9417 - val_loss: 0.4643 - learning_rate: 5.0000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8985 - loss: 0.5369 - val_accuracy: 0.9292 - val_loss: 0.4725 - learning_rate: 5.0000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9125 - loss: 0.5171 - val_accuracy: 0.9375 - val_loss: 0.4633 - learning_rate: 5.0000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9074 - loss: 0.5452 - val_accuracy: 0.9417 - val_loss: 0.4636 - learning_rate: 5.0000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9074 - loss: 0.5229 - val_accuracy: 0.9333 - val_loss: 0.4671 - learning_rate: 5.0000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9007 - loss: 0.5053 - val_accuracy: 0.9125 - val_loss: 0.4657 - learning_rate: 5.0000e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9044 - loss: 0.5184 - val_accuracy: 0.9292 - val_loss: 0.4492 - learning_rate: 5.0000e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9044 - loss: 0.5223 - val_accuracy: 0.9167 - val_loss: 0.4456 - learning_rate: 5.0000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8985 - loss: 0.5135 - val_accuracy: 0.9333 - val_loss: 0.4477 - learning_rate: 5.0000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9228 - loss: 0.4908 - val_accuracy: 0.9333 - val_loss: 0.4424 - learning_rate: 5.0000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9199 - loss: 0.4872 - val_accuracy: 0.9500 - val_loss: 0.4287 - learning_rate: 5.0000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9125 - loss: 0.5001 - val_accuracy: 0.9375 - val_loss: 0.4400 - learning_rate: 5.0000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9184 - loss: 0.4860 - val_accuracy: 0.9167 - val_loss: 0.4397 - learning_rate: 5.0000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9147 - loss: 0.4953 - val_accuracy: 0.9208 - val_loss: 0.4265 - learning_rate: 5.0000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9228 - loss: 0.4824 - val_accuracy: 0.9375 - val_loss: 0.4162 - learning_rate: 5.0000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9213 - loss: 0.4783 - val_accuracy: 0.9292 - val_loss: 0.4161 - learning_rate: 5.0000e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9206 - loss: 0.4763 - val_accuracy: 0.9417 - val_loss: 0.4037 - learning_rate: 5.0000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9051 - loss: 0.4908 - val_accuracy: 0.9375 - val_loss: 0.4175 - learning_rate: 5.0000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9184 - loss: 0.4755 - val_accuracy: 0.9375 - val_loss: 0.4014 - learning_rate: 5.0000e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9118 - loss: 0.4821 - val_accuracy: 0.9375 - val_loss: 0.4024 - learning_rate: 5.0000e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9176 - loss: 0.4572 - val_accuracy: 0.9458 - val_loss: 0.4033 - learning_rate: 5.0000e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9279 - loss: 0.4552 - val_accuracy: 0.9375 - val_loss: 0.3958 - learning_rate: 5.0000e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.8985 - loss: 0.4617 - val_accuracy: 0.9375 - val_loss: 0.3970 - learning_rate: 5.0000e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9081 - loss: 0.4610 - val_accuracy: 0.9208 - val_loss: 0.4126 - learning_rate: 5.0000e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9287 - loss: 0.4471 - val_accuracy: 0.9375 - val_loss: 0.3919 - learning_rate: 5.0000e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9206 - loss: 0.4466 - val_accuracy: 0.9375 - val_loss: 0.3919 - learning_rate: 5.0000e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9140 - loss: 0.4500 - val_accuracy: 0.9292 - val_loss: 0.3884 - learning_rate: 5.0000e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9243 - loss: 0.4402 - val_accuracy: 0.9375 - val_loss: 0.3827 - learning_rate: 5.0000e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.8971 - loss: 0.4741 - val_accuracy: 0.9375 - val_loss: 0.3780 - learning_rate: 5.0000e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9235 - loss: 0.4359 - val_accuracy: 0.9333 - val_loss: 0.3722 - learning_rate: 5.0000e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9176 - loss: 0.4359 - val_accuracy: 0.9375 - val_loss: 0.3645 - learning_rate: 5.0000e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9176 - loss: 0.4350 - val_accuracy: 0.9417 - val_loss: 0.3704 - learning_rate: 5.0000e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9147 - loss: 0.4372 - val_accuracy: 0.9250 - val_loss: 0.3858 - learning_rate: 5.0000e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9279 - loss: 0.4325 - val_accuracy: 0.9458 - val_loss: 0.3612 - learning_rate: 5.0000e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9184 - loss: 0.4351 - val_accuracy: 0.9500 - val_loss: 0.3595 - learning_rate: 5.0000e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9257 - loss: 0.4178 - val_accuracy: 0.9417 - val_loss: 0.3586 - learning_rate: 5.0000e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9265 - loss: 0.4110 - val_accuracy: 0.9458 - val_loss: 0.3551 - learning_rate: 5.0000e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9338 - loss: 0.4102 - val_accuracy: 0.9542 - val_loss: 0.3511 - learning_rate: 5.0000e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9265 - loss: 0.4247 - val_accuracy: 0.9458 - val_loss: 0.3634 - learning_rate: 5.0000e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9324 - loss: 0.4106 - val_accuracy: 0.9375 - val_loss: 0.3579 - learning_rate: 5.0000e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9243 - loss: 0.4185 - val_accuracy: 0.9417 - val_loss: 0.3543 - learning_rate: 5.0000e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9331 - loss: 0.4043 - val_accuracy: 0.9292 - val_loss: 0.3602 - learning_rate: 5.0000e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9301 - loss: 0.4025 - val_accuracy: 0.9333 - val_loss: 0.3500 - learning_rate: 5.0000e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9272 - loss: 0.3974 - val_accuracy: 0.9333 - val_loss: 0.3483 - learning_rate: 5.0000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9228 - loss: 0.4090 - val_accuracy: 0.9375 - val_loss: 0.3427 - learning_rate: 5.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9206 - loss: 0.4117 - val_accuracy: 0.9458 - val_loss: 0.3301 - learning_rate: 5.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9265 - loss: 0.4029 - val_accuracy: 0.9500 - val_loss: 0.3339 - learning_rate: 5.0000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9301 - loss: 0.3855 - val_accuracy: 0.9417 - val_loss: 0.3306 - learning_rate: 5.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9279 - loss: 0.3909 - val_accuracy: 0.9375 - val_loss: 0.3348 - learning_rate: 5.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9272 - loss: 0.3886 - val_accuracy: 0.9375 - val_loss: 0.3364 - learning_rate: 5.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9206 - loss: 0.3978 - val_accuracy: 0.9417 - val_loss: 0.3310 - learning_rate: 5.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9368 - loss: 0.3665 - val_accuracy: 0.9417 - val_loss: 0.3333 - learning_rate: 5.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9360 - loss: 0.3793 - val_accuracy: 0.9458 - val_loss: 0.3295 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9184 - loss: 0.3810 - val_accuracy: 0.9417 - val_loss: 0.3217 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9235 - loss: 0.3857 - val_accuracy: 0.9208 - val_loss: 0.3401 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9243 - loss: 0.3692 - val_accuracy: 0.9542 - val_loss: 0.3144 - learning_rate: 5.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9346 - loss: 0.3676 - val_accuracy: 0.9583 - val_loss: 0.3108 - learning_rate: 5.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9279 - loss: 0.3710 - val_accuracy: 0.9500 - val_loss: 0.3210 - learning_rate: 5.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9294 - loss: 0.3706 - val_accuracy: 0.9458 - val_loss: 0.3124 - learning_rate: 5.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9360 - loss: 0.3661 - val_accuracy: 0.9542 - val_loss: 0.3057 - learning_rate: 5.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9353 - loss: 0.3585 - val_accuracy: 0.9500 - val_loss: 0.3111 - learning_rate: 5.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9331 - loss: 0.3559 - val_accuracy: 0.9625 - val_loss: 0.3037 - learning_rate: 5.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9390 - loss: 0.3533 - val_accuracy: 0.9542 - val_loss: 0.3030 - learning_rate: 5.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9449 - loss: 0.3488 - val_accuracy: 0.9625 - val_loss: 0.2939 - learning_rate: 5.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9324 - loss: 0.3534 - val_accuracy: 0.9417 - val_loss: 0.3061 - learning_rate: 5.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9257 - loss: 0.3505 - val_accuracy: 0.9542 - val_loss: 0.2964 - learning_rate: 5.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9390 - loss: 0.3558 - val_accuracy: 0.9417 - val_loss: 0.2942 - learning_rate: 5.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9360 - loss: 0.3476 - val_accuracy: 0.9500 - val_loss: 0.2976 - learning_rate: 5.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9235 - loss: 0.3600 - val_accuracy: 0.9583 - val_loss: 0.2881 - learning_rate: 5.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9309 - loss: 0.3524 - val_accuracy: 0.9583 - val_loss: 0.2842 - learning_rate: 5.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9301 - loss: 0.3532 - val_accuracy: 0.9458 - val_loss: 0.2927 - learning_rate: 5.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9412 - loss: 0.3477 - val_accuracy: 0.9417 - val_loss: 0.2960 - learning_rate: 5.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9382 - loss: 0.3421 - val_accuracy: 0.9500 - val_loss: 0.2811 - learning_rate: 5.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9471 - loss: 0.3418 - val_accuracy: 0.9458 - val_loss: 0.2880 - learning_rate: 5.0000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9346 - loss: 0.3395 - val_accuracy: 0.9458 - val_loss: 0.2994 - learning_rate: 5.0000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9404 - loss: 0.3372 - val_accuracy: 0.9583 - val_loss: 0.2804 - learning_rate: 5.0000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9309 - loss: 0.3389 - val_accuracy: 0.9500 - val_loss: 0.2837 - learning_rate: 5.0000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9353 - loss: 0.3311 - val_accuracy: 0.9667 - val_loss: 0.2713 - learning_rate: 5.0000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9257 - loss: 0.3445 - val_accuracy: 0.9667 - val_loss: 0.2705 - learning_rate: 5.0000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9346 - loss: 0.3378 - val_accuracy: 0.9625 - val_loss: 0.2713 - learning_rate: 5.0000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9331 - loss: 0.3279 - val_accuracy: 0.9625 - val_loss: 0.2688 - learning_rate: 5.0000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9375 - loss: 0.3279 - val_accuracy: 0.9542 - val_loss: 0.2696 - learning_rate: 5.0000e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9346 - loss: 0.3169 - val_accuracy: 0.9458 - val_loss: 0.2800 - learning_rate: 5.0000e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9360 - loss: 0.3228 - val_accuracy: 0.9458 - val_loss: 0.2748 - learning_rate: 5.0000e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9279 - loss: 0.3247 - val_accuracy: 0.9500 - val_loss: 0.2724 - learning_rate: 5.0000e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9353 - loss: 0.3222 - val_accuracy: 0.9542 - val_loss: 0.2773 - learning_rate: 5.0000e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9375 - loss: 0.3210 - val_accuracy: 0.9417 - val_loss: 0.2842 - learning_rate: 5.0000e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9449 - loss: 0.3103 - val_accuracy: 0.9625 - val_loss: 0.2598 - learning_rate: 5.0000e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9382 - loss: 0.3148 - val_accuracy: 0.9625 - val_loss: 0.2600 - learning_rate: 5.0000e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9419 - loss: 0.3023 - val_accuracy: 0.9583 - val_loss: 0.2644 - learning_rate: 5.0000e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9412 - loss: 0.3068 - val_accuracy: 0.9458 - val_loss: 0.2707 - learning_rate: 5.0000e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9338 - loss: 0.3104 - val_accuracy: 0.9333 - val_loss: 0.2939 - learning_rate: 5.0000e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9412 - loss: 0.3075 - val_accuracy: 0.9583 - val_loss: 0.2578 - learning_rate: 5.0000e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9368 - loss: 0.3151 - val_accuracy: 0.9583 - val_loss: 0.2589 - learning_rate: 5.0000e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9419 - loss: 0.3028 - val_accuracy: 0.9667 - val_loss: 0.2511 - learning_rate: 5.0000e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9404 - loss: 0.3043 - val_accuracy: 0.9583 - val_loss: 0.2587 - learning_rate: 5.0000e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9279 - loss: 0.3232 - val_accuracy: 0.9583 - val_loss: 0.2499 - learning_rate: 5.0000e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9154 - loss: 0.3233 - val_accuracy: 0.9417 - val_loss: 0.2685 - learning_rate: 5.0000e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9368 - loss: 0.3085 - val_accuracy: 0.9667 - val_loss: 0.2453 - learning_rate: 5.0000e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9412 - loss: 0.3002 - val_accuracy: 0.9625 - val_loss: 0.2451 - learning_rate: 5.0000e-05\n",
      "Epoch 198/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9471 - loss: 0.2948 - val_accuracy: 0.9542 - val_loss: 0.2544 - learning_rate: 5.0000e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9375 - loss: 0.2976 - val_accuracy: 0.9583 - val_loss: 0.2530 - learning_rate: 5.0000e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9404 - loss: 0.2949 - val_accuracy: 0.9625 - val_loss: 0.2506 - learning_rate: 5.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 197.\n",
      "\n",
      "âœ… Fold 5 Results:\n",
      "  Test Accuracy: 0.9725\n",
      "  Test AUC: 0.9959\n",
      "  Test Loss: 0.2654\n",
      "ğŸŒŸ New best model! Fold 5 with accuracy: 0.9725\n",
      "\n",
      "Fold 5 Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                NORMAL     0.9571    0.9750    0.9659       160\n",
      "ALL (INTERICTAL+ICTAL)     0.9831    0.9708    0.9769       240\n",
      "\n",
      "              accuracy                         0.9725       400\n",
      "             macro avg     0.9701    0.9729    0.9714       400\n",
      "          weighted avg     0.9727    0.9725    0.9725       400\n",
      "\n",
      "\n",
      "============================================================\n",
      " CROSS-VALIDATION SUMMARY\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Mean Test Accuracy across folds: 0.9620 (Â±0.0078)\n",
      "ğŸ“Š Mean Test AUC across folds: 0.9922 (Â±0.0046)\n",
      "\n",
      "ğŸ“‹ Fold-wise Metrics Summary:\n",
      "\n",
      "ğŸ”¸ Fold 1 Metrics:\n",
      "  Train Accuracy : 0.9537\n",
      "  Val Accuracy   : 0.9625\n",
      "  Test Accuracy  : 0.9500\n",
      "  Test Loss      : 0.4609\n",
      "  Precision      : 0.9507\n",
      "  Recall         : 0.9500\n",
      "  F1 Score       : 0.9501\n",
      "  Test AUC       : 0.9834\n",
      "\n",
      "ğŸ”¸ Fold 2 Metrics:\n",
      "  Train Accuracy : 0.9478\n",
      "  Val Accuracy   : 0.9708\n",
      "  Test Accuracy  : 0.9575\n",
      "  Test Loss      : 0.3607\n",
      "  Precision      : 0.9588\n",
      "  Recall         : 0.9575\n",
      "  F1 Score       : 0.9577\n",
      "  Test AUC       : 0.9939\n",
      "\n",
      "ğŸ”¸ Fold 3 Metrics:\n",
      "  Train Accuracy : 0.9456\n",
      "  Val Accuracy   : 0.9792\n",
      "  Test Accuracy  : 0.9625\n",
      "  Test Loss      : 0.2815\n",
      "  Precision      : 0.9626\n",
      "  Recall         : 0.9625\n",
      "  F1 Score       : 0.9625\n",
      "  Test AUC       : 0.9919\n",
      "\n",
      "ğŸ”¸ Fold 4 Metrics:\n",
      "  Train Accuracy : 0.9515\n",
      "  Val Accuracy   : 0.9625\n",
      "  Test Accuracy  : 0.9675\n",
      "  Test Loss      : 0.2826\n",
      "  Precision      : 0.9675\n",
      "  Recall         : 0.9675\n",
      "  F1 Score       : 0.9674\n",
      "  Test AUC       : 0.9957\n",
      "\n",
      "ğŸ”¸ Fold 5 Metrics:\n",
      "  Train Accuracy : 0.9471\n",
      "  Val Accuracy   : 0.9667\n",
      "  Test Accuracy  : 0.9725\n",
      "  Test Loss      : 0.2654\n",
      "  Precision      : 0.9727\n",
      "  Recall         : 0.9725\n",
      "  F1 Score       : 0.9725\n",
      "  Test AUC       : 0.9959\n",
      "\n",
      "ğŸ’¾ Best model (Fold 5) saved as 'results/best_model.keras'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D, MaxPooling1D, Dense, Dropout, BatchNormalization, \n",
    "    GlobalAveragePooling1D, Input, Activation, SpatialDropout1D, \n",
    "    LSTM, Bidirectional, Multiply, Reshape, LeakyReLU\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# ===================== DATA AUGMENTATION =====================\n",
    "def augment_signal(segment, augmentation_prob=0.5):\n",
    "    \"\"\"\n",
    "    Apply random augmentation to EEG segment\n",
    "    \n",
    "    Args:\n",
    "        segment: Input EEG segment (1D array)\n",
    "        augmentation_prob: Probability of applying augmentation\n",
    "    \n",
    "    Returns:\n",
    "        Augmented segment\n",
    "    \"\"\"\n",
    "    if np.random.random() > augmentation_prob:\n",
    "        return segment  # No augmentation\n",
    "    \n",
    "    # Choose augmentation type\n",
    "    aug_type = np.random.choice(['noise', 'scale', 'shift', 'time_shift'], p=[0.3, 0.3, 0.2, 0.2])\n",
    "    \n",
    "    if aug_type == 'noise':\n",
    "        # Add Gaussian noise\n",
    "        noise_level = np.random.uniform(0.01, 0.05)\n",
    "        noise = np.random.normal(0, noise_level, segment.shape)\n",
    "        return segment + noise\n",
    "    \n",
    "    elif aug_type == 'scale':\n",
    "        # Random amplitude scaling\n",
    "        scale = np.random.uniform(0.9, 1.1)\n",
    "        return segment * scale\n",
    "    \n",
    "    elif aug_type == 'shift':\n",
    "        # Random DC shift\n",
    "        shift = np.random.uniform(-0.1, 0.1)\n",
    "        return segment + shift\n",
    "    \n",
    "    elif aug_type == 'time_shift':\n",
    "        # Random time shift (circular shift)\n",
    "        shift_amount = np.random.randint(-20, 20)\n",
    "        return np.roll(segment, shift_amount)\n",
    "    \n",
    "    return segment\n",
    "\n",
    "\n",
    "def augment_batch(X_batch, y_batch, augmentation_prob=0.5):\n",
    "    \"\"\"\n",
    "    Apply augmentation to a batch of data\n",
    "    \n",
    "    Args:\n",
    "        X_batch: Batch of EEG segments (batch_size, time_steps, channels)\n",
    "        y_batch: Batch of labels\n",
    "        augmentation_prob: Probability of applying augmentation\n",
    "    \n",
    "    Returns:\n",
    "        Augmented batch\n",
    "    \"\"\"\n",
    "    X_augmented = np.zeros_like(X_batch)\n",
    "    \n",
    "    for i in range(len(X_batch)):\n",
    "        # Only augment positive class (seizure) more aggressively\n",
    "        if y_batch[i] == 1:\n",
    "            prob = augmentation_prob * 1.5  # Higher probability for minority class\n",
    "        else:\n",
    "            prob = augmentation_prob\n",
    "        \n",
    "        X_augmented[i, :, 0] = augment_signal(X_batch[i, :, 0], prob)\n",
    "    \n",
    "    return X_augmented\n",
    "\n",
    "\n",
    "class DataAugmentationCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Custom callback to apply data augmentation during training\"\"\"\n",
    "    \n",
    "    def __init__(self, X_train, y_train, augmentation_prob=0.5):\n",
    "        super().__init__()\n",
    "        self.X_train_original = X_train.copy()\n",
    "        self.y_train = y_train\n",
    "        self.augmentation_prob = augmentation_prob\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Apply augmentation at the start of each epoch\n",
    "        if epoch > 0:  # Skip first epoch to see baseline performance\n",
    "            X_augmented = augment_batch(\n",
    "                self.X_train_original, \n",
    "                self.y_train, \n",
    "                self.augmentation_prob\n",
    "            )\n",
    "            # Update model's training data\n",
    "            self.model.stop_training = False\n",
    "\n",
    "\n",
    "# ===================== CUSTOM DATA GENERATOR =====================\n",
    "class AugmentedDataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Custom data generator with real-time augmentation\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size=32, augmentation_prob=0.5, shuffle=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.augmentation_prob = augmentation_prob\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        start_idx = index * self.batch_size\n",
    "        end_idx = min((index + 1) * self.batch_size, len(self.X))\n",
    "        batch_indices = self.indices[start_idx:end_idx]\n",
    "        \n",
    "        # Get batch data\n",
    "        X_batch = self.X[batch_indices].copy()\n",
    "        y_batch = self.y[batch_indices]\n",
    "        \n",
    "        # Apply augmentation\n",
    "        X_batch = augment_batch(X_batch, y_batch, self.augmentation_prob)\n",
    "        \n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "\n",
    "# ===================== SE BLOCK IMPLEMENTATION =====================\n",
    "class SEBlock(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation Block for channel attention\n",
    "    Paper: \"Interpretable classification of epileptic EEG signals...\"\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction=8, **kwargs):\n",
    "        super(SEBlock, self).__init__(**kwargs)\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        channels = input_shape[-1]\n",
    "        self.squeeze = GlobalAveragePooling1D()\n",
    "        \n",
    "        # Excitation network\n",
    "        self.fc1 = Dense(\n",
    "            channels // self.reduction, \n",
    "            activation='relu', \n",
    "            kernel_initializer='he_normal'\n",
    "        )\n",
    "        self.fc2 = Dense(\n",
    "            channels, \n",
    "            activation='sigmoid', \n",
    "            kernel_initializer='he_normal'\n",
    "        )\n",
    "        \n",
    "        super(SEBlock, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Squeeze: Global average pooling\n",
    "        squeeze = self.squeeze(inputs)\n",
    "        \n",
    "        # Excitation: Learn channel importance\n",
    "        excitation = self.fc1(squeeze)\n",
    "        excitation = self.fc2(excitation)\n",
    "        \n",
    "        # Reshape for broadcasting\n",
    "        excitation = tf.reshape(excitation, [-1, 1, tf.shape(inputs)[-1]])\n",
    "        \n",
    "        # Scale: Multiply input with learned weights\n",
    "        return Multiply()([inputs, excitation])\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(SEBlock, self).get_config()\n",
    "        config.update({\"reduction\": self.reduction})\n",
    "        return config\n",
    "\n",
    "\n",
    "# ===================== LOAD DATA =====================\n",
    "X = np.load(r\"preprocessed\\ALL_X.npy\")\n",
    "y = np.load(r\"preprocessed\\ALL_y.npy\")\n",
    "\n",
    "# Convert to Binary Classification \n",
    "y_encoded = np.where(y == 'NORMAL', 0, 1)\n",
    "\n",
    "print(\"Original classes:\", np.unique(y))\n",
    "print(\"Binary classes: 0 (NORMAL) vs 1 (INTERICTAL + ICTAL)\")\n",
    "print(\"Binary labels distribution:\", np.unique(y_encoded, return_counts=True))\n",
    "\n",
    "# Prepare Data\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "\n",
    "# Compute Class Weights \n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_encoded), y=y_encoded)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "print(f\"Class weights: {class_weight_dict}\")\n",
    "\n",
    "# ===================== PREPARE CROSS VALIDATION =====================\n",
    "random_state = np.random.randint(0, 10000)\n",
    "print(f\"ğŸ² Random state used for this run: {random_state}\")\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "fold_indices = [(train_val_idx, test_idx) for train_val_idx, test_idx in kfold.split(X, y_encoded)]\n",
    "\n",
    "# Save indices for reproducibility\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "np.save(\"results/fold_indices.npy\", np.array(fold_indices, dtype=object), allow_pickle=True)\n",
    "\n",
    "\n",
    "# ===================== LOSS FUNCTIONS =====================\n",
    "def focal_loss(alpha=0.75, gamma=2.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        cross_entropy = -y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred)\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        focal_term = K.pow(1 - p_t, gamma)\n",
    "        alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        \n",
    "        return K.mean(alpha_t * focal_term * cross_entropy)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def hybrid_focal_loss(alpha=0.75, gamma=1.7, focal_weight=0.55):\n",
    "    \"\"\"Hybrid: Focal + BCE\"\"\"\n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        bce = -y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred)\n",
    "        \n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        focal_term = K.pow(1 - p_t, gamma)\n",
    "        alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        focal = alpha_t * focal_term * bce\n",
    "        \n",
    "        combined = focal_weight * focal + (1 - focal_weight) * bce\n",
    "        return K.mean(combined)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "# ===================== MODEL BUILDING =====================\n",
    "def build_model(input_shape):\n",
    "    \"\"\"\n",
    "    MODIFIED MODEL:\n",
    "    - Added 4th CNN block\n",
    "    - Changed Bidirectional LSTM to regular LSTM\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # ========== Block 1: Local patterns ==========\n",
    "    x = Conv1D(48, kernel_size=7, padding='same', kernel_regularizer=l2(0.002))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = SEBlock(reduction=8)(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = SpatialDropout1D(0.28)(x)\n",
    "    \n",
    "    # ========== Block 2: Mid-level features ==========\n",
    "    x = Conv1D(96, kernel_size=5, padding='same', kernel_regularizer=l2(0.002))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = SEBlock(reduction=8)(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = SpatialDropout1D(0.32)(x)\n",
    "    \n",
    "    # ========== Block 3: High-level features ==========\n",
    "    x = Conv1D(128, kernel_size=3, padding='same', kernel_regularizer=l2(0.002))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = SEBlock(reduction=8)(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = SpatialDropout1D(0.38)(x)\n",
    "    \n",
    "    # ========== Block 4: Deep features (NEW LAYER) ==========\n",
    "    x = Conv1D(160, kernel_size=3, padding='same', kernel_regularizer=l2(0.002))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = SEBlock(reduction=8)(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = SpatialDropout1D(0.38)(x)\n",
    "    \n",
    "    # ========== LSTM Temporal Modeling (Changed from Bidirectional to regular LSTM) ==========\n",
    "    x = LSTM(64, return_sequences=False, kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    # ========== Dense Classification ==========\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.003))(x)\n",
    "    x = Dropout(0.48)(x)\n",
    "    \n",
    "    x = Dense(32, activation='relu', kernel_regularizer=l2(0.003))(x)\n",
    "    x = Dropout(0.48)(x)\n",
    "    \n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "# ===================== TRAINING =====================\n",
    "# Choose which model to use\n",
    "\n",
    "USE_DATA_AUGMENTATION = True  \n",
    "\n",
    "acc_per_fold = []\n",
    "auc_per_fold = []\n",
    "conf_matrices = []\n",
    "class_names = ['NORMAL', 'ALL (INTERICTAL+ICTAL)']\n",
    "\n",
    "# Track metrics for best model selection\n",
    "fold_metrics = {\n",
    "    'fold_no': [],\n",
    "    'test_acc': [],\n",
    "    'test_loss': [],\n",
    "    'test_auc': [],\n",
    "    'val_acc': [],\n",
    "    'train_acc': [],\n",
    "    'f1_score': [],\n",
    "    'precision': [],\n",
    "    'recall': []\n",
    "}\n",
    "best_model = None\n",
    "best_fold = None\n",
    "best_acc = 0\n",
    "\n",
    "\n",
    "for fold_no, (train_val_idx, test_idx) in enumerate(fold_indices, start=1):\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\" FOLD {fold_no}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Split into train/val/test\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y_encoded[train_val_idx], y_encoded[test_idx]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.15, stratify=y_train_val, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "    print(f\"Test set distribution: {np.unique(y_test, return_counts=True)}\")\n",
    "\n",
    "    # Build model\n",
    "    model = build_model(input_shape=(X.shape[1], 1))\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=5e-5),\n",
    "        loss=hybrid_focal_loss(alpha=0.7, gamma=1.5, focal_weight=0.5),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Callbacks \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=25, \n",
    "        restore_best_weights=True, \n",
    "        verbose=1, \n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.6,\n",
    "        patience=8, \n",
    "        min_lr=1e-7,\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        f\"results/model_fold{fold_no}.weights.h5\", \n",
    "        monitor='val_accuracy', \n",
    "        save_best_only=True, \n",
    "        save_weights_only=True,\n",
    "        verbose=0,  \n",
    "        mode='max'\n",
    "    )\n",
    "    \n",
    "    callbacks = [early_stop, reduce_lr, checkpoint]\n",
    "    \n",
    "    # Train Model\n",
    "    print(f\"\\nğŸš€ Training Fold {fold_no}...\")\n",
    "    \n",
    "    if USE_DATA_AUGMENTATION:\n",
    "        print(\"ğŸ“Š Using data augmentation with real-time generator\")\n",
    "        \n",
    "        # Create data generators\n",
    "        train_generator = AugmentedDataGenerator(\n",
    "            X_train, y_train, \n",
    "            batch_size=12, \n",
    "            augmentation_prob=0.55,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        # Note: Validation data is NOT augmented\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=200,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=callbacks,\n",
    "            class_weight=class_weight_dict,\n",
    "            verbose=1\n",
    "        )\n",
    "    else:\n",
    "        print(\"ğŸ“Š Training without data augmentation\")\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=150,\n",
    "            batch_size=32,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=callbacks,\n",
    "            class_weight=class_weight_dict,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    # Load best weights\n",
    "    model.load_weights(f\"results/model_fold{fold_no}.weights.h5\")\n",
    "\n",
    "    # Evaluate\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    acc_per_fold.append(test_acc)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_prob = model.predict(X_test, verbose=0)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # AUC Score\n",
    "    test_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    auc_per_fold.append(test_auc)\n",
    "    \n",
    "    print(f\"\\nâœ… Fold {fold_no} Results:\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  Test AUC: {test_auc:.4f}\")\n",
    "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrices.append(cm)\n",
    "    \n",
    "    # Classification Metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Store metrics\n",
    "    fold_metrics['fold_no'].append(fold_no)\n",
    "    fold_metrics['test_acc'].append(test_acc)\n",
    "    fold_metrics['test_loss'].append(test_loss)\n",
    "    fold_metrics['test_auc'].append(test_auc)\n",
    "    fold_metrics['val_acc'].append(max(history.history['val_accuracy']))\n",
    "    fold_metrics['train_acc'].append(max(history.history['accuracy']))\n",
    "    fold_metrics['f1_score'].append(f1)\n",
    "    fold_metrics['precision'].append(precision)\n",
    "    fold_metrics['recall'].append(recall)\n",
    "    \n",
    "    # Check if this is the best model\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        best_fold = fold_no\n",
    "        best_model = model\n",
    "        best_cm = cm\n",
    "        best_y_test = y_test\n",
    "        best_y_pred = y_pred\n",
    "        best_y_pred_prob = y_pred_prob\n",
    "        print(f\"ğŸŒŸ New best model! Fold {fold_no} with accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    print(f\"\\nFold {fold_no} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                annot_kws={'size': 14})\n",
    "    plt.title(f\"Fold {fold_no} Confusion Matrix\\nAcc: {test_acc:.4f} | AUC: {test_auc:.4f}\", \n",
    "              fontsize=14)\n",
    "    plt.xlabel(\"Predicted\", fontsize=12)\n",
    "    plt.ylabel(\"True\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"results/confusion_fold{fold_no}.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Training History \n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "    plt.axhline(y=test_acc, color='r', linestyle='--', label=f'Test Acc: {test_acc:.4f}')\n",
    "    plt.title(f'Fold {fold_no} - Model Accuracy', fontsize=13)\n",
    "    plt.xlabel('Epoch', fontsize=11)\n",
    "    plt.ylabel('Accuracy', fontsize=11)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    plt.title(f'Fold {fold_no} - Model Loss', fontsize=13)\n",
    "    plt.xlabel('Epoch', fontsize=11)\n",
    "    plt.ylabel('Loss', fontsize=11)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"results/training_history_fold{fold_no}.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ===================== SUMMARY =====================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" CROSS-VALIDATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nğŸ“Š Mean Test Accuracy across folds: {np.mean(acc_per_fold):.4f} (Â±{np.std(acc_per_fold):.4f})\")\n",
    "print(f\"ğŸ“Š Mean Test AUC across folds: {np.mean(auc_per_fold):.4f} (Â±{np.std(auc_per_fold):.4f})\")\n",
    "\n",
    "# Combine confusion matrices\n",
    "total_cm = np.sum(conf_matrices, axis=0)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(total_cm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            annot_kws={'size': 14})\n",
    "plt.title(\"Overall Confusion Matrix (All Folds)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/confusion_overall.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Print Fold Metrics\n",
    "print(\"\\nğŸ“‹ Fold-wise Metrics Summary:\")\n",
    "for i in range(len(fold_metrics['fold_no'])):\n",
    "    print(f\"\\nğŸ”¸ Fold {fold_metrics['fold_no'][i]} Metrics:\")\n",
    "    print(f\"  Train Accuracy : {fold_metrics['train_acc'][i]:.4f}\")\n",
    "    print(f\"  Val Accuracy   : {fold_metrics['val_acc'][i]:.4f}\")\n",
    "    print(f\"  Test Accuracy  : {fold_metrics['test_acc'][i]:.4f}\")\n",
    "    print(f\"  Test Loss      : {fold_metrics['test_loss'][i]:.4f}\")\n",
    "    print(f\"  Precision      : {fold_metrics['precision'][i]:.4f}\")\n",
    "    print(f\"  Recall         : {fold_metrics['recall'][i]:.4f}\")\n",
    "    print(f\"  F1 Score       : {fold_metrics['f1_score'][i]:.4f}\")\n",
    "    print(f\"  Test AUC       : {fold_metrics['test_auc'][i]:.4f}\")\n",
    "\n",
    "# Save best model\n",
    "best_model.save(\"results/best_model.keras\")\n",
    "print(f\"\\nğŸ’¾ Best model (Fold {best_fold}) saved as 'results/best_model.keras'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
