{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b5b6d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (11000, 347, 1)\n",
      "Labels distribution: (array([0, 1]), array([4400, 6600]))\n",
      "ğŸ² Random state used for this run: 5393\n",
      "\n",
      "ğŸ”¹ Fold 1\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_37\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_37\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_78          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_79          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_80          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_78 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_78          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_78 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_123 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_79 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_79          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_79 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_124 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_80 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_80          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_80 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_125 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_32 (\u001b[38;5;33mLSTM\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_53 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_126 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_54 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,793</span> (350.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,793\u001b[0m (350.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,345</span> (349.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,345\u001b[0m (349.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.7904 - loss: 0.2530 - val_accuracy: 0.8867 - val_loss: 0.2395\n",
      "Epoch 2/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9080 - loss: 0.1437 - val_accuracy: 0.8378 - val_loss: 0.2139\n",
      "Epoch 3/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9197 - loss: 0.1205 - val_accuracy: 0.8752 - val_loss: 0.1757\n",
      "Epoch 4/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9253 - loss: 0.1106 - val_accuracy: 0.8912 - val_loss: 0.1650\n",
      "Epoch 5/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9271 - loss: 0.1062 - val_accuracy: 0.9176 - val_loss: 0.1283\n",
      "Epoch 6/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9315 - loss: 0.0966 - val_accuracy: 0.9163 - val_loss: 0.1240\n",
      "Epoch 7/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9370 - loss: 0.0921 - val_accuracy: 0.9311 - val_loss: 0.1020\n",
      "Epoch 8/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9384 - loss: 0.0916 - val_accuracy: 0.9311 - val_loss: 0.1049\n",
      "Epoch 9/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9391 - loss: 0.0881 - val_accuracy: 0.9299 - val_loss: 0.1144\n",
      "Epoch 10/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9377 - loss: 0.0860 - val_accuracy: 0.9453 - val_loss: 0.0744\n",
      "Epoch 11/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9419 - loss: 0.0840 - val_accuracy: 0.9395 - val_loss: 0.0910\n",
      "Epoch 12/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9462 - loss: 0.0805 - val_accuracy: 0.9472 - val_loss: 0.0709\n",
      "Epoch 13/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9438 - loss: 0.0801 - val_accuracy: 0.9427 - val_loss: 0.0910\n",
      "Epoch 14/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9462 - loss: 0.0777 - val_accuracy: 0.9550 - val_loss: 0.0646\n",
      "Epoch 15/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9477 - loss: 0.0762 - val_accuracy: 0.9492 - val_loss: 0.0684\n",
      "Epoch 16/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9474 - loss: 0.0771 - val_accuracy: 0.9575 - val_loss: 0.0611\n",
      "Epoch 17/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9495 - loss: 0.0735 - val_accuracy: 0.9556 - val_loss: 0.0696\n",
      "Epoch 18/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9499 - loss: 0.0727 - val_accuracy: 0.9633 - val_loss: 0.0584\n",
      "Epoch 19/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9494 - loss: 0.0721 - val_accuracy: 0.9620 - val_loss: 0.0597\n",
      "Epoch 20/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9509 - loss: 0.0708 - val_accuracy: 0.9620 - val_loss: 0.0591\n",
      "Epoch 21/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9522 - loss: 0.0703 - val_accuracy: 0.9582 - val_loss: 0.0599\n",
      "Epoch 22/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9541 - loss: 0.0678 - val_accuracy: 0.9646 - val_loss: 0.0552\n",
      "Epoch 23/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9545 - loss: 0.0661 - val_accuracy: 0.9601 - val_loss: 0.0581\n",
      "Epoch 24/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9562 - loss: 0.0664 - val_accuracy: 0.9620 - val_loss: 0.0559\n",
      "Epoch 25/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9545 - loss: 0.0648 - val_accuracy: 0.9633 - val_loss: 0.0579\n",
      "Epoch 26/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9558 - loss: 0.0639 - val_accuracy: 0.9620 - val_loss: 0.0528\n",
      "Epoch 27/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.9553 - loss: 0.0638 - val_accuracy: 0.9640 - val_loss: 0.0515\n",
      "Epoch 28/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9583 - loss: 0.0607 - val_accuracy: 0.9627 - val_loss: 0.0549\n",
      "Epoch 29/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 39ms/step - accuracy: 0.9580 - loss: 0.0614 - val_accuracy: 0.9633 - val_loss: 0.0505\n",
      "Epoch 30/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9595 - loss: 0.0589 - val_accuracy: 0.9659 - val_loss: 0.0510\n",
      "Epoch 31/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9582 - loss: 0.0590 - val_accuracy: 0.9646 - val_loss: 0.0508\n",
      "Epoch 32/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9607 - loss: 0.0575 - val_accuracy: 0.9691 - val_loss: 0.0495\n",
      "Epoch 33/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 40ms/step - accuracy: 0.9601 - loss: 0.0587 - val_accuracy: 0.9633 - val_loss: 0.0533\n",
      "Epoch 34/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9620 - loss: 0.0584 - val_accuracy: 0.9646 - val_loss: 0.0491\n",
      "Epoch 35/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9634 - loss: 0.0546 - val_accuracy: 0.9678 - val_loss: 0.0578\n",
      "Epoch 36/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9609 - loss: 0.0548 - val_accuracy: 0.9723 - val_loss: 0.0480\n",
      "Epoch 37/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9618 - loss: 0.0535 - val_accuracy: 0.9704 - val_loss: 0.0521\n",
      "Epoch 38/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9597 - loss: 0.0568 - val_accuracy: 0.9672 - val_loss: 0.0503\n",
      "Epoch 39/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9639 - loss: 0.0512 - val_accuracy: 0.9691 - val_loss: 0.0478\n",
      "Epoch 40/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.9685 - val_loss: 0.0507\n",
      "Epoch 41/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9641 - loss: 0.0512 - val_accuracy: 0.9710 - val_loss: 0.0459\n",
      "Epoch 42/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9654 - loss: 0.0486 - val_accuracy: 0.9710 - val_loss: 0.0469\n",
      "Epoch 43/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9658 - loss: 0.0501 - val_accuracy: 0.9704 - val_loss: 0.0511\n",
      "Epoch 44/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9659 - loss: 0.0491 - val_accuracy: 0.9710 - val_loss: 0.0468\n",
      "Epoch 45/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 40ms/step - accuracy: 0.9674 - loss: 0.0460 - val_accuracy: 0.9736 - val_loss: 0.0492\n",
      "Epoch 46/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9657 - loss: 0.0479 - val_accuracy: 0.9736 - val_loss: 0.0425\n",
      "Epoch 47/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9687 - loss: 0.0470 - val_accuracy: 0.9730 - val_loss: 0.0483\n",
      "Epoch 48/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9685 - loss: 0.0454 - val_accuracy: 0.9775 - val_loss: 0.0444\n",
      "Epoch 49/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9689 - loss: 0.0472 - val_accuracy: 0.9749 - val_loss: 0.0436\n",
      "Epoch 50/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - accuracy: 0.9681 - loss: 0.0457 - val_accuracy: 0.9768 - val_loss: 0.0448\n",
      "Epoch 51/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9684 - loss: 0.0447 - val_accuracy: 0.9710 - val_loss: 0.0484\n",
      "Epoch 52/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9694 - loss: 0.0439 - val_accuracy: 0.9755 - val_loss: 0.0435\n",
      "Epoch 53/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9701 - loss: 0.0434 - val_accuracy: 0.9730 - val_loss: 0.0486\n",
      "Epoch 54/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9701 - loss: 0.0442 - val_accuracy: 0.9749 - val_loss: 0.0428\n",
      "Epoch 55/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9705 - loss: 0.0440 - val_accuracy: 0.9723 - val_loss: 0.0453\n",
      "Epoch 56/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9699 - loss: 0.0443 - val_accuracy: 0.9775 - val_loss: 0.0412\n",
      "Epoch 57/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9705 - loss: 0.0414 - val_accuracy: 0.9743 - val_loss: 0.0441\n",
      "Epoch 58/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9708 - loss: 0.0409 - val_accuracy: 0.9698 - val_loss: 0.0495\n",
      "Epoch 59/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9731 - loss: 0.0386 - val_accuracy: 0.9704 - val_loss: 0.0527\n",
      "Epoch 60/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9725 - loss: 0.0389 - val_accuracy: 0.9736 - val_loss: 0.0444\n",
      "Epoch 61/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 40ms/step - accuracy: 0.9736 - loss: 0.0389 - val_accuracy: 0.9749 - val_loss: 0.0474\n",
      "Epoch 62/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9723 - loss: 0.0396 - val_accuracy: 0.9749 - val_loss: 0.0453\n",
      "Epoch 63/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9736 - loss: 0.0373 - val_accuracy: 0.9768 - val_loss: 0.0425\n",
      "Epoch 64/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9725 - loss: 0.0387 - val_accuracy: 0.9775 - val_loss: 0.0435\n",
      "Epoch 65/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9772 - loss: 0.0372 - val_accuracy: 0.9717 - val_loss: 0.0478\n",
      "Epoch 66/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9732 - loss: 0.0380 - val_accuracy: 0.9749 - val_loss: 0.0439\n",
      "Epoch 67/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9739 - loss: 0.0362 - val_accuracy: 0.9755 - val_loss: 0.0429\n",
      "Epoch 68/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9749 - loss: 0.0355 - val_accuracy: 0.9749 - val_loss: 0.0456\n",
      "Epoch 69/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9770 - loss: 0.0345 - val_accuracy: 0.9775 - val_loss: 0.0459\n",
      "Epoch 70/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9743 - loss: 0.0355 - val_accuracy: 0.9749 - val_loss: 0.0475\n",
      "Epoch 71/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9758 - loss: 0.0349 - val_accuracy: 0.9698 - val_loss: 0.0508\n",
      "Epoch 72/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - accuracy: 0.9750 - loss: 0.0366 - val_accuracy: 0.9736 - val_loss: 0.0420\n",
      "Epoch 73/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9757 - loss: 0.0349 - val_accuracy: 0.9743 - val_loss: 0.0447\n",
      "Epoch 74/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9776 - loss: 0.0334 - val_accuracy: 0.9743 - val_loss: 0.0410\n",
      "Epoch 75/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9774 - loss: 0.0307 - val_accuracy: 0.9743 - val_loss: 0.0448\n",
      "Epoch 76/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9775 - loss: 0.0325 - val_accuracy: 0.9762 - val_loss: 0.0410\n",
      "Epoch 77/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9799 - loss: 0.0322 - val_accuracy: 0.9736 - val_loss: 0.0461\n",
      "Epoch 78/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9779 - loss: 0.0321 - val_accuracy: 0.9704 - val_loss: 0.0470\n",
      "Epoch 79/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9761 - loss: 0.0318 - val_accuracy: 0.9762 - val_loss: 0.0443\n",
      "Epoch 80/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9792 - loss: 0.0308 - val_accuracy: 0.9736 - val_loss: 0.0416\n",
      "Epoch 81/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9794 - loss: 0.0309 - val_accuracy: 0.9743 - val_loss: 0.0460\n",
      "Epoch 82/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9790 - loss: 0.0308 - val_accuracy: 0.9762 - val_loss: 0.0515\n",
      "Epoch 83/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9789 - loss: 0.0304 - val_accuracy: 0.9768 - val_loss: 0.0454\n",
      "Epoch 84/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9783 - loss: 0.0304 - val_accuracy: 0.9755 - val_loss: 0.0442\n",
      "Epoch 85/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9795 - loss: 0.0296 - val_accuracy: 0.9755 - val_loss: 0.0504\n",
      "Epoch 86/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9787 - loss: 0.0306 - val_accuracy: 0.9730 - val_loss: 0.0466\n",
      "Epoch 87/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9821 - loss: 0.0269 - val_accuracy: 0.9768 - val_loss: 0.0423\n",
      "Epoch 88/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9798 - loss: 0.0287 - val_accuracy: 0.9788 - val_loss: 0.0444\n",
      "Epoch 89/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9825 - loss: 0.0265 - val_accuracy: 0.9736 - val_loss: 0.0527\n",
      "Epoch 90/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9797 - loss: 0.0294 - val_accuracy: 0.9775 - val_loss: 0.0437\n",
      "Epoch 91/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9814 - loss: 0.0264 - val_accuracy: 0.9775 - val_loss: 0.0446\n",
      "Epoch 92/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9819 - loss: 0.0272 - val_accuracy: 0.9762 - val_loss: 0.0459\n",
      "Epoch 93/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9807 - loss: 0.0276 - val_accuracy: 0.9781 - val_loss: 0.0446\n",
      "Epoch 94/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9810 - loss: 0.0281 - val_accuracy: 0.9768 - val_loss: 0.0437\n",
      "Epoch 95/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9815 - loss: 0.0275 - val_accuracy: 0.9755 - val_loss: 0.0453\n",
      "Epoch 96/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9814 - loss: 0.0265 - val_accuracy: 0.9794 - val_loss: 0.0448\n",
      "Epoch 97/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9822 - loss: 0.0261 - val_accuracy: 0.9775 - val_loss: 0.0430\n",
      "Epoch 98/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9812 - loss: 0.0271 - val_accuracy: 0.9755 - val_loss: 0.0464\n",
      "Epoch 99/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9820 - loss: 0.0258 - val_accuracy: 0.9775 - val_loss: 0.0450\n",
      "Epoch 100/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9825 - loss: 0.0253 - val_accuracy: 0.9794 - val_loss: 0.0447\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9727 - loss: 0.0641\n",
      "Fold 1 - Test Accuracy: 0.9727\n",
      "âœ… Weights saved to results/cnn_lstm_fold1.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "ğŸ”¹ Fold 2\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_38\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_38\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_81          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_127 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_82          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_83          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_129 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_130 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_81 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_81          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_81 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_127 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_82 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_82          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_82 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_128 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_83 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_83          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_83 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_129 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_33 (\u001b[38;5;33mLSTM\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_55 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_130 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_56 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,793</span> (350.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,793\u001b[0m (350.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,345</span> (349.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,345\u001b[0m (349.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.7880 - loss: 0.2540 - val_accuracy: 0.8366 - val_loss: 0.2335\n",
      "Epoch 2/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9106 - loss: 0.1439 - val_accuracy: 0.8784 - val_loss: 0.1807\n",
      "Epoch 3/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9240 - loss: 0.1181 - val_accuracy: 0.8887 - val_loss: 0.1794\n",
      "Epoch 4/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9240 - loss: 0.1108 - val_accuracy: 0.9041 - val_loss: 0.1465\n",
      "Epoch 5/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9318 - loss: 0.1008 - val_accuracy: 0.9022 - val_loss: 0.1565\n",
      "Epoch 6/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9329 - loss: 0.0954 - val_accuracy: 0.9183 - val_loss: 0.1215\n",
      "Epoch 7/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9349 - loss: 0.0891 - val_accuracy: 0.9099 - val_loss: 0.1412\n",
      "Epoch 8/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9342 - loss: 0.0935 - val_accuracy: 0.9151 - val_loss: 0.1278\n",
      "Epoch 9/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9359 - loss: 0.0902 - val_accuracy: 0.9266 - val_loss: 0.1180\n",
      "Epoch 10/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9399 - loss: 0.0841 - val_accuracy: 0.9369 - val_loss: 0.0999\n",
      "Epoch 11/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9397 - loss: 0.0848 - val_accuracy: 0.9337 - val_loss: 0.1162\n",
      "Epoch 12/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9401 - loss: 0.0798 - val_accuracy: 0.9459 - val_loss: 0.0871\n",
      "Epoch 13/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9440 - loss: 0.0780 - val_accuracy: 0.9434 - val_loss: 0.0932\n",
      "Epoch 14/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9436 - loss: 0.0782 - val_accuracy: 0.9459 - val_loss: 0.0928\n",
      "Epoch 15/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9442 - loss: 0.0778 - val_accuracy: 0.9414 - val_loss: 0.0965\n",
      "Epoch 16/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9449 - loss: 0.0757 - val_accuracy: 0.9511 - val_loss: 0.0836\n",
      "Epoch 17/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9492 - loss: 0.0721 - val_accuracy: 0.9582 - val_loss: 0.0723\n",
      "Epoch 18/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9464 - loss: 0.0727 - val_accuracy: 0.9492 - val_loss: 0.0831\n",
      "Epoch 19/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9482 - loss: 0.0723 - val_accuracy: 0.9447 - val_loss: 0.0951\n",
      "Epoch 20/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9500 - loss: 0.0706 - val_accuracy: 0.9447 - val_loss: 0.0911\n",
      "Epoch 21/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9514 - loss: 0.0692 - val_accuracy: 0.9588 - val_loss: 0.0731\n",
      "Epoch 22/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9520 - loss: 0.0682 - val_accuracy: 0.9440 - val_loss: 0.0910\n",
      "Epoch 23/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9527 - loss: 0.0680 - val_accuracy: 0.9498 - val_loss: 0.0838\n",
      "Epoch 24/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9505 - loss: 0.0665 - val_accuracy: 0.9505 - val_loss: 0.0847\n",
      "Epoch 25/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9547 - loss: 0.0632 - val_accuracy: 0.9575 - val_loss: 0.0758\n",
      "Epoch 26/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9528 - loss: 0.0646 - val_accuracy: 0.9550 - val_loss: 0.0786\n",
      "Epoch 27/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9537 - loss: 0.0630 - val_accuracy: 0.9447 - val_loss: 0.0905\n",
      "Epoch 28/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9536 - loss: 0.0653 - val_accuracy: 0.9620 - val_loss: 0.0604\n",
      "Epoch 29/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9563 - loss: 0.0630 - val_accuracy: 0.9601 - val_loss: 0.0720\n",
      "Epoch 30/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9577 - loss: 0.0584 - val_accuracy: 0.9607 - val_loss: 0.0732\n",
      "Epoch 31/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9576 - loss: 0.0609 - val_accuracy: 0.9646 - val_loss: 0.0550\n",
      "Epoch 32/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9575 - loss: 0.0585 - val_accuracy: 0.9627 - val_loss: 0.0632\n",
      "Epoch 33/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9575 - loss: 0.0586 - val_accuracy: 0.9672 - val_loss: 0.0530\n",
      "Epoch 34/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9591 - loss: 0.0559 - val_accuracy: 0.9665 - val_loss: 0.0560\n",
      "Epoch 35/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9589 - loss: 0.0573 - val_accuracy: 0.9678 - val_loss: 0.0558\n",
      "Epoch 36/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9605 - loss: 0.0570 - val_accuracy: 0.9607 - val_loss: 0.0635\n",
      "Epoch 37/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9605 - loss: 0.0532 - val_accuracy: 0.9678 - val_loss: 0.0575\n",
      "Epoch 38/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9600 - loss: 0.0541 - val_accuracy: 0.9678 - val_loss: 0.0548\n",
      "Epoch 39/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9608 - loss: 0.0527 - val_accuracy: 0.9646 - val_loss: 0.0580\n",
      "Epoch 40/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9607 - loss: 0.0526 - val_accuracy: 0.9620 - val_loss: 0.0665\n",
      "Epoch 41/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9607 - loss: 0.0528 - val_accuracy: 0.9556 - val_loss: 0.0761\n",
      "Epoch 42/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9622 - loss: 0.0512 - val_accuracy: 0.9646 - val_loss: 0.0585\n",
      "Epoch 43/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9641 - loss: 0.0505 - val_accuracy: 0.9646 - val_loss: 0.0638\n",
      "Epoch 44/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9627 - loss: 0.0505 - val_accuracy: 0.9653 - val_loss: 0.0591\n",
      "Epoch 45/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9639 - loss: 0.0487 - val_accuracy: 0.9607 - val_loss: 0.0636\n",
      "Epoch 46/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9639 - loss: 0.0489 - val_accuracy: 0.9691 - val_loss: 0.0571\n",
      "Epoch 47/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9649 - loss: 0.0480 - val_accuracy: 0.9646 - val_loss: 0.0631\n",
      "Epoch 48/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9659 - loss: 0.0467 - val_accuracy: 0.9556 - val_loss: 0.0636\n",
      "Epoch 49/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9647 - loss: 0.0480 - val_accuracy: 0.9620 - val_loss: 0.0577\n",
      "Epoch 50/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9650 - loss: 0.0485 - val_accuracy: 0.9730 - val_loss: 0.0503\n",
      "Epoch 51/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9674 - loss: 0.0453 - val_accuracy: 0.9710 - val_loss: 0.0525\n",
      "Epoch 52/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9686 - loss: 0.0449 - val_accuracy: 0.9653 - val_loss: 0.0548\n",
      "Epoch 53/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9657 - loss: 0.0463 - val_accuracy: 0.9646 - val_loss: 0.0513\n",
      "Epoch 54/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9672 - loss: 0.0451 - val_accuracy: 0.9659 - val_loss: 0.0548\n",
      "Epoch 55/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9694 - loss: 0.0422 - val_accuracy: 0.9659 - val_loss: 0.0587\n",
      "Epoch 56/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9686 - loss: 0.0444 - val_accuracy: 0.9678 - val_loss: 0.0564\n",
      "Epoch 57/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9666 - loss: 0.0464 - val_accuracy: 0.9704 - val_loss: 0.0523\n",
      "Epoch 58/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9694 - loss: 0.0431 - val_accuracy: 0.9678 - val_loss: 0.0513\n",
      "Epoch 59/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9696 - loss: 0.0434 - val_accuracy: 0.9736 - val_loss: 0.0549\n",
      "Epoch 60/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9698 - loss: 0.0410 - val_accuracy: 0.9685 - val_loss: 0.0579\n",
      "Epoch 61/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9701 - loss: 0.0400 - val_accuracy: 0.9698 - val_loss: 0.0583\n",
      "Epoch 62/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9690 - loss: 0.0420 - val_accuracy: 0.9736 - val_loss: 0.0546\n",
      "Epoch 63/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9711 - loss: 0.0403 - val_accuracy: 0.9710 - val_loss: 0.0508\n",
      "Epoch 64/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9710 - loss: 0.0392 - val_accuracy: 0.9717 - val_loss: 0.0542\n",
      "Epoch 65/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9707 - loss: 0.0403 - val_accuracy: 0.9704 - val_loss: 0.0509\n",
      "Epoch 66/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9736 - loss: 0.0375 - val_accuracy: 0.9717 - val_loss: 0.0531\n",
      "Epoch 67/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9739 - loss: 0.0384 - val_accuracy: 0.9665 - val_loss: 0.0613\n",
      "Epoch 68/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9737 - loss: 0.0372 - val_accuracy: 0.9717 - val_loss: 0.0548\n",
      "Epoch 69/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9725 - loss: 0.0364 - val_accuracy: 0.9749 - val_loss: 0.0586\n",
      "Epoch 70/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9716 - loss: 0.0388 - val_accuracy: 0.9730 - val_loss: 0.0554\n",
      "Epoch 71/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9741 - loss: 0.0360 - val_accuracy: 0.9704 - val_loss: 0.0605\n",
      "Epoch 72/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9740 - loss: 0.0363 - val_accuracy: 0.9665 - val_loss: 0.0534\n",
      "Epoch 73/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9761 - loss: 0.0348 - val_accuracy: 0.9698 - val_loss: 0.0517\n",
      "Epoch 74/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9732 - loss: 0.0363 - val_accuracy: 0.9717 - val_loss: 0.0509\n",
      "Epoch 75/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9730 - loss: 0.0373 - val_accuracy: 0.9736 - val_loss: 0.0524\n",
      "Epoch 76/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9743 - loss: 0.0334 - val_accuracy: 0.9607 - val_loss: 0.0582\n",
      "Epoch 77/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9744 - loss: 0.0342 - val_accuracy: 0.9633 - val_loss: 0.0599\n",
      "Epoch 78/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9744 - loss: 0.0352 - val_accuracy: 0.9736 - val_loss: 0.0568\n",
      "Epoch 79/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9756 - loss: 0.0333 - val_accuracy: 0.9698 - val_loss: 0.0528\n",
      "Epoch 80/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9752 - loss: 0.0347 - val_accuracy: 0.9723 - val_loss: 0.0517\n",
      "Epoch 81/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9752 - loss: 0.0348 - val_accuracy: 0.9743 - val_loss: 0.0517\n",
      "Epoch 82/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9767 - loss: 0.0322 - val_accuracy: 0.9665 - val_loss: 0.0561\n",
      "Epoch 83/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9765 - loss: 0.0331 - val_accuracy: 0.9723 - val_loss: 0.0523\n",
      "Epoch 84/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9765 - loss: 0.0331 - val_accuracy: 0.9717 - val_loss: 0.0533\n",
      "Epoch 85/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9774 - loss: 0.0307 - val_accuracy: 0.9723 - val_loss: 0.0599\n",
      "Epoch 86/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9814 - loss: 0.0286 - val_accuracy: 0.9730 - val_loss: 0.0635\n",
      "Epoch 87/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9773 - loss: 0.0316 - val_accuracy: 0.9698 - val_loss: 0.0548\n",
      "Epoch 88/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9794 - loss: 0.0297 - val_accuracy: 0.9743 - val_loss: 0.0592\n",
      "Epoch 89/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9781 - loss: 0.0321 - val_accuracy: 0.9717 - val_loss: 0.0542\n",
      "Epoch 90/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9799 - loss: 0.0293 - val_accuracy: 0.9653 - val_loss: 0.0592\n",
      "Epoch 91/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9773 - loss: 0.0317 - val_accuracy: 0.9717 - val_loss: 0.0546\n",
      "Epoch 92/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9783 - loss: 0.0292 - val_accuracy: 0.9717 - val_loss: 0.0563\n",
      "Epoch 93/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9811 - loss: 0.0279 - val_accuracy: 0.9685 - val_loss: 0.0579\n",
      "Epoch 94/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9793 - loss: 0.0282 - val_accuracy: 0.9730 - val_loss: 0.0555\n",
      "Epoch 95/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9770 - loss: 0.0310 - val_accuracy: 0.9723 - val_loss: 0.0536\n",
      "Epoch 96/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9787 - loss: 0.0286 - val_accuracy: 0.9698 - val_loss: 0.0506\n",
      "Epoch 97/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9794 - loss: 0.0278 - val_accuracy: 0.9743 - val_loss: 0.0544\n",
      "Epoch 98/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9788 - loss: 0.0298 - val_accuracy: 0.9749 - val_loss: 0.0542\n",
      "Epoch 99/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9810 - loss: 0.0265 - val_accuracy: 0.9710 - val_loss: 0.0556\n",
      "Epoch 100/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9810 - loss: 0.0272 - val_accuracy: 0.9723 - val_loss: 0.0573\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9745 - loss: 0.0568\n",
      "Fold 2 - Test Accuracy: 0.9745\n",
      "âœ… Weights saved to results/cnn_lstm_fold2.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "ğŸ”¹ Fold 3\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_39\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_39\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_84          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_131 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_85          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_132 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_86          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_133 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_134 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_84 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_84          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_84 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_131 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_85 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_85          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_85 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_132 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_86 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_86          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_86 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_133 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_34 (\u001b[38;5;33mLSTM\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_57 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_134 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_58 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,793</span> (350.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,793\u001b[0m (350.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,345</span> (349.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,345\u001b[0m (349.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.7829 - loss: 0.2566 - val_accuracy: 0.8501 - val_loss: 0.2899\n",
      "Epoch 2/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9111 - loss: 0.1397 - val_accuracy: 0.9118 - val_loss: 0.1438\n",
      "Epoch 3/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9194 - loss: 0.1215 - val_accuracy: 0.9189 - val_loss: 0.1259\n",
      "Epoch 4/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9246 - loss: 0.1136 - val_accuracy: 0.9189 - val_loss: 0.1201\n",
      "Epoch 5/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9228 - loss: 0.1101 - val_accuracy: 0.9382 - val_loss: 0.0952\n",
      "Epoch 6/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9280 - loss: 0.1005 - val_accuracy: 0.9440 - val_loss: 0.0853\n",
      "Epoch 7/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9318 - loss: 0.0967 - val_accuracy: 0.9447 - val_loss: 0.0812\n",
      "Epoch 8/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9321 - loss: 0.0949 - val_accuracy: 0.9517 - val_loss: 0.0765\n",
      "Epoch 9/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9397 - loss: 0.0880 - val_accuracy: 0.9543 - val_loss: 0.0694\n",
      "Epoch 10/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9381 - loss: 0.0895 - val_accuracy: 0.9453 - val_loss: 0.0763\n",
      "Epoch 11/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9386 - loss: 0.0862 - val_accuracy: 0.9505 - val_loss: 0.0711\n",
      "Epoch 12/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9380 - loss: 0.0839 - val_accuracy: 0.9569 - val_loss: 0.0676\n",
      "Epoch 13/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9429 - loss: 0.0811 - val_accuracy: 0.9498 - val_loss: 0.0749\n",
      "Epoch 14/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9419 - loss: 0.0814 - val_accuracy: 0.9575 - val_loss: 0.0660\n",
      "Epoch 15/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9438 - loss: 0.0777 - val_accuracy: 0.9614 - val_loss: 0.0657\n",
      "Epoch 16/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9447 - loss: 0.0771 - val_accuracy: 0.9620 - val_loss: 0.0687\n",
      "Epoch 17/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9485 - loss: 0.0749 - val_accuracy: 0.9646 - val_loss: 0.0599\n",
      "Epoch 18/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9468 - loss: 0.0742 - val_accuracy: 0.9646 - val_loss: 0.0610\n",
      "Epoch 19/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9463 - loss: 0.0736 - val_accuracy: 0.9646 - val_loss: 0.0612\n",
      "Epoch 20/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9471 - loss: 0.0704 - val_accuracy: 0.9633 - val_loss: 0.0610\n",
      "Epoch 21/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9507 - loss: 0.0704 - val_accuracy: 0.9659 - val_loss: 0.0596\n",
      "Epoch 22/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9496 - loss: 0.0714 - val_accuracy: 0.9627 - val_loss: 0.0651\n",
      "Epoch 23/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9494 - loss: 0.0674 - val_accuracy: 0.9672 - val_loss: 0.0562\n",
      "Epoch 24/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9507 - loss: 0.0678 - val_accuracy: 0.9665 - val_loss: 0.0599\n",
      "Epoch 25/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9550 - loss: 0.0638 - val_accuracy: 0.9665 - val_loss: 0.0602\n",
      "Epoch 26/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9512 - loss: 0.0641 - val_accuracy: 0.9678 - val_loss: 0.0574\n",
      "Epoch 27/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9559 - loss: 0.0619 - val_accuracy: 0.9685 - val_loss: 0.0568\n",
      "Epoch 28/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9550 - loss: 0.0626 - val_accuracy: 0.9672 - val_loss: 0.0555\n",
      "Epoch 29/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9557 - loss: 0.0606 - val_accuracy: 0.9640 - val_loss: 0.0569\n",
      "Epoch 30/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9558 - loss: 0.0611 - val_accuracy: 0.9653 - val_loss: 0.0576\n",
      "Epoch 31/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9589 - loss: 0.0583 - val_accuracy: 0.9659 - val_loss: 0.0542\n",
      "Epoch 32/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9560 - loss: 0.0592 - val_accuracy: 0.9691 - val_loss: 0.0536\n",
      "Epoch 33/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9591 - loss: 0.0573 - val_accuracy: 0.9678 - val_loss: 0.0544\n",
      "Epoch 34/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9567 - loss: 0.0576 - val_accuracy: 0.9685 - val_loss: 0.0546\n",
      "Epoch 35/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9606 - loss: 0.0551 - val_accuracy: 0.9704 - val_loss: 0.0517\n",
      "Epoch 36/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9605 - loss: 0.0547 - val_accuracy: 0.9704 - val_loss: 0.0558\n",
      "Epoch 37/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9610 - loss: 0.0542 - val_accuracy: 0.9659 - val_loss: 0.0600\n",
      "Epoch 38/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9600 - loss: 0.0538 - val_accuracy: 0.9665 - val_loss: 0.0546\n",
      "Epoch 39/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9618 - loss: 0.0529 - val_accuracy: 0.9698 - val_loss: 0.0543\n",
      "Epoch 40/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9618 - loss: 0.0533 - val_accuracy: 0.9704 - val_loss: 0.0505\n",
      "Epoch 41/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9634 - loss: 0.0517 - val_accuracy: 0.9678 - val_loss: 0.0542\n",
      "Epoch 42/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9642 - loss: 0.0494 - val_accuracy: 0.9730 - val_loss: 0.0511\n",
      "Epoch 43/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9641 - loss: 0.0522 - val_accuracy: 0.9717 - val_loss: 0.0539\n",
      "Epoch 44/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9632 - loss: 0.0491 - val_accuracy: 0.9717 - val_loss: 0.0509\n",
      "Epoch 45/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9635 - loss: 0.0499 - val_accuracy: 0.9704 - val_loss: 0.0528\n",
      "Epoch 46/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9651 - loss: 0.0473 - val_accuracy: 0.9730 - val_loss: 0.0506\n",
      "Epoch 47/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9636 - loss: 0.0500 - val_accuracy: 0.9698 - val_loss: 0.0520\n",
      "Epoch 48/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9661 - loss: 0.0482 - val_accuracy: 0.9717 - val_loss: 0.0539\n",
      "Epoch 49/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9658 - loss: 0.0469 - val_accuracy: 0.9730 - val_loss: 0.0502\n",
      "Epoch 50/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9665 - loss: 0.0450 - val_accuracy: 0.9730 - val_loss: 0.0525\n",
      "Epoch 51/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9665 - loss: 0.0448 - val_accuracy: 0.9704 - val_loss: 0.0517\n",
      "Epoch 52/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9693 - loss: 0.0438 - val_accuracy: 0.9723 - val_loss: 0.0484\n",
      "Epoch 53/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9684 - loss: 0.0455 - val_accuracy: 0.9730 - val_loss: 0.0516\n",
      "Epoch 54/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9676 - loss: 0.0437 - val_accuracy: 0.9723 - val_loss: 0.0553\n",
      "Epoch 55/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9691 - loss: 0.0443 - val_accuracy: 0.9710 - val_loss: 0.0525\n",
      "Epoch 56/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9701 - loss: 0.0422 - val_accuracy: 0.9723 - val_loss: 0.0523\n",
      "Epoch 57/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9701 - loss: 0.0411 - val_accuracy: 0.9736 - val_loss: 0.0495\n",
      "Epoch 58/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9681 - loss: 0.0428 - val_accuracy: 0.9743 - val_loss: 0.0501\n",
      "Epoch 59/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9711 - loss: 0.0408 - val_accuracy: 0.9736 - val_loss: 0.0525\n",
      "Epoch 60/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9703 - loss: 0.0422 - val_accuracy: 0.9762 - val_loss: 0.0550\n",
      "Epoch 61/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9715 - loss: 0.0405 - val_accuracy: 0.9736 - val_loss: 0.0511\n",
      "Epoch 62/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9716 - loss: 0.0396 - val_accuracy: 0.9743 - val_loss: 0.0519\n",
      "Epoch 63/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9720 - loss: 0.0394 - val_accuracy: 0.9743 - val_loss: 0.0521\n",
      "Epoch 64/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9723 - loss: 0.0404 - val_accuracy: 0.9755 - val_loss: 0.0508\n",
      "Epoch 65/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9730 - loss: 0.0371 - val_accuracy: 0.9755 - val_loss: 0.0501\n",
      "Epoch 66/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9734 - loss: 0.0379 - val_accuracy: 0.9768 - val_loss: 0.0485\n",
      "Epoch 67/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9728 - loss: 0.0381 - val_accuracy: 0.9743 - val_loss: 0.0478\n",
      "Epoch 68/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9730 - loss: 0.0373 - val_accuracy: 0.9762 - val_loss: 0.0483\n",
      "Epoch 69/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9739 - loss: 0.0360 - val_accuracy: 0.9768 - val_loss: 0.0496\n",
      "Epoch 70/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9736 - loss: 0.0371 - val_accuracy: 0.9775 - val_loss: 0.0496\n",
      "Epoch 71/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9758 - loss: 0.0347 - val_accuracy: 0.9788 - val_loss: 0.0468\n",
      "Epoch 72/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9754 - loss: 0.0357 - val_accuracy: 0.9768 - val_loss: 0.0525\n",
      "Epoch 73/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9760 - loss: 0.0338 - val_accuracy: 0.9723 - val_loss: 0.0569\n",
      "Epoch 74/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9752 - loss: 0.0340 - val_accuracy: 0.9762 - val_loss: 0.0515\n",
      "Epoch 75/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9774 - loss: 0.0328 - val_accuracy: 0.9762 - val_loss: 0.0495\n",
      "Epoch 76/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9784 - loss: 0.0318 - val_accuracy: 0.9736 - val_loss: 0.0522\n",
      "Epoch 77/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9765 - loss: 0.0331 - val_accuracy: 0.9781 - val_loss: 0.0526\n",
      "Epoch 78/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9770 - loss: 0.0336 - val_accuracy: 0.9788 - val_loss: 0.0512\n",
      "Epoch 79/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9774 - loss: 0.0322 - val_accuracy: 0.9788 - val_loss: 0.0456\n",
      "Epoch 80/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9752 - loss: 0.0325 - val_accuracy: 0.9794 - val_loss: 0.0485\n",
      "Epoch 81/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9784 - loss: 0.0306 - val_accuracy: 0.9775 - val_loss: 0.0474\n",
      "Epoch 82/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9772 - loss: 0.0339 - val_accuracy: 0.9762 - val_loss: 0.0504\n",
      "Epoch 83/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9785 - loss: 0.0292 - val_accuracy: 0.9768 - val_loss: 0.0542\n",
      "Epoch 84/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9779 - loss: 0.0313 - val_accuracy: 0.9762 - val_loss: 0.0520\n",
      "Epoch 85/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9778 - loss: 0.0310 - val_accuracy: 0.9743 - val_loss: 0.0562\n",
      "Epoch 86/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9790 - loss: 0.0300 - val_accuracy: 0.9775 - val_loss: 0.0505\n",
      "Epoch 87/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9786 - loss: 0.0305 - val_accuracy: 0.9755 - val_loss: 0.0530\n",
      "Epoch 88/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9790 - loss: 0.0296 - val_accuracy: 0.9768 - val_loss: 0.0495\n",
      "Epoch 89/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9810 - loss: 0.0270 - val_accuracy: 0.9736 - val_loss: 0.0559\n",
      "Epoch 90/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9805 - loss: 0.0285 - val_accuracy: 0.9768 - val_loss: 0.0546\n",
      "Epoch 91/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9789 - loss: 0.0299 - val_accuracy: 0.9762 - val_loss: 0.0501\n",
      "Epoch 92/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9801 - loss: 0.0276 - val_accuracy: 0.9723 - val_loss: 0.0497\n",
      "Epoch 93/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9814 - loss: 0.0281 - val_accuracy: 0.9749 - val_loss: 0.0471\n",
      "Epoch 94/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9819 - loss: 0.0264 - val_accuracy: 0.9749 - val_loss: 0.0534\n",
      "Epoch 95/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9826 - loss: 0.0262 - val_accuracy: 0.9659 - val_loss: 0.0581\n",
      "Epoch 96/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9821 - loss: 0.0264 - val_accuracy: 0.9749 - val_loss: 0.0531\n",
      "Epoch 97/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9803 - loss: 0.0275 - val_accuracy: 0.9801 - val_loss: 0.0458\n",
      "Epoch 98/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9825 - loss: 0.0257 - val_accuracy: 0.9768 - val_loss: 0.0519\n",
      "Epoch 99/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9836 - loss: 0.0264 - val_accuracy: 0.9736 - val_loss: 0.0515\n",
      "Epoch 100/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9823 - loss: 0.0266 - val_accuracy: 0.9768 - val_loss: 0.0498\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9691 - loss: 0.0728\n",
      "Fold 3 - Test Accuracy: 0.9691\n",
      "âœ… Weights saved to results/cnn_lstm_fold3.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "ğŸ”¹ Fold 4\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_40\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_40\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_87          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_135 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_88          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_136 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_89          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_137 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_138 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_87 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_87          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_87 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_135 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_88 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_88          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_88 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_136 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_89 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_89          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_89 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_137 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_35 (\u001b[38;5;33mLSTM\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_59 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_138 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_60 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,793</span> (350.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,793\u001b[0m (350.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,345</span> (349.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,345\u001b[0m (349.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.7777 - loss: 0.2553 - val_accuracy: 0.6924 - val_loss: 0.4164\n",
      "Epoch 2/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9108 - loss: 0.1423 - val_accuracy: 0.9299 - val_loss: 0.1178\n",
      "Epoch 3/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9202 - loss: 0.1260 - val_accuracy: 0.9215 - val_loss: 0.1223\n",
      "Epoch 4/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9227 - loss: 0.1151 - val_accuracy: 0.9228 - val_loss: 0.1147\n",
      "Epoch 5/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9272 - loss: 0.1047 - val_accuracy: 0.9350 - val_loss: 0.1016\n",
      "Epoch 6/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9280 - loss: 0.1005 - val_accuracy: 0.9440 - val_loss: 0.0949\n",
      "Epoch 7/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9356 - loss: 0.0934 - val_accuracy: 0.9479 - val_loss: 0.0901\n",
      "Epoch 8/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9360 - loss: 0.0920 - val_accuracy: 0.9466 - val_loss: 0.0829\n",
      "Epoch 9/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9376 - loss: 0.0879 - val_accuracy: 0.9459 - val_loss: 0.0837\n",
      "Epoch 10/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9371 - loss: 0.0862 - val_accuracy: 0.9562 - val_loss: 0.0856\n",
      "Epoch 11/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9399 - loss: 0.0852 - val_accuracy: 0.9492 - val_loss: 0.0743\n",
      "Epoch 12/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9440 - loss: 0.0793 - val_accuracy: 0.9440 - val_loss: 0.0914\n",
      "Epoch 13/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9427 - loss: 0.0800 - val_accuracy: 0.9582 - val_loss: 0.0778\n",
      "Epoch 14/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9450 - loss: 0.0776 - val_accuracy: 0.9582 - val_loss: 0.0667\n",
      "Epoch 15/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9485 - loss: 0.0742 - val_accuracy: 0.9614 - val_loss: 0.0712\n",
      "Epoch 16/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9442 - loss: 0.0753 - val_accuracy: 0.9550 - val_loss: 0.0788\n",
      "Epoch 17/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9471 - loss: 0.0729 - val_accuracy: 0.9582 - val_loss: 0.0689\n",
      "Epoch 18/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9480 - loss: 0.0703 - val_accuracy: 0.9595 - val_loss: 0.0773\n",
      "Epoch 19/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9487 - loss: 0.0707 - val_accuracy: 0.9633 - val_loss: 0.0685\n",
      "Epoch 20/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9511 - loss: 0.0691 - val_accuracy: 0.9646 - val_loss: 0.0673\n",
      "Epoch 21/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9527 - loss: 0.0673 - val_accuracy: 0.9595 - val_loss: 0.0776\n",
      "Epoch 22/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9533 - loss: 0.0644 - val_accuracy: 0.9601 - val_loss: 0.0749\n",
      "Epoch 23/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9556 - loss: 0.0643 - val_accuracy: 0.9627 - val_loss: 0.0686\n",
      "Epoch 24/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9560 - loss: 0.0603 - val_accuracy: 0.9659 - val_loss: 0.0609\n",
      "Epoch 25/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9576 - loss: 0.0608 - val_accuracy: 0.9620 - val_loss: 0.0668\n",
      "Epoch 26/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9582 - loss: 0.0597 - val_accuracy: 0.9665 - val_loss: 0.0625\n",
      "Epoch 27/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9573 - loss: 0.0593 - val_accuracy: 0.9665 - val_loss: 0.0627\n",
      "Epoch 28/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9570 - loss: 0.0600 - val_accuracy: 0.9685 - val_loss: 0.0570\n",
      "Epoch 29/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9596 - loss: 0.0559 - val_accuracy: 0.9678 - val_loss: 0.0584\n",
      "Epoch 30/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9571 - loss: 0.0607 - val_accuracy: 0.9672 - val_loss: 0.0642\n",
      "Epoch 31/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9627 - loss: 0.0530 - val_accuracy: 0.9665 - val_loss: 0.0637\n",
      "Epoch 32/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9618 - loss: 0.0546 - val_accuracy: 0.9698 - val_loss: 0.0594\n",
      "Epoch 33/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9620 - loss: 0.0549 - val_accuracy: 0.9723 - val_loss: 0.0604\n",
      "Epoch 34/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9623 - loss: 0.0534 - val_accuracy: 0.9672 - val_loss: 0.0589\n",
      "Epoch 35/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9652 - loss: 0.0535 - val_accuracy: 0.9710 - val_loss: 0.0574\n",
      "Epoch 36/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9640 - loss: 0.0510 - val_accuracy: 0.9614 - val_loss: 0.0691\n",
      "Epoch 37/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9642 - loss: 0.0506 - val_accuracy: 0.9710 - val_loss: 0.0574\n",
      "Epoch 38/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9645 - loss: 0.0489 - val_accuracy: 0.9620 - val_loss: 0.0752\n",
      "Epoch 39/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9655 - loss: 0.0484 - val_accuracy: 0.9691 - val_loss: 0.0567\n",
      "Epoch 40/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9645 - loss: 0.0502 - val_accuracy: 0.9730 - val_loss: 0.0536\n",
      "Epoch 41/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9639 - loss: 0.0497 - val_accuracy: 0.9730 - val_loss: 0.0575\n",
      "Epoch 42/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9667 - loss: 0.0470 - val_accuracy: 0.9743 - val_loss: 0.0542\n",
      "Epoch 43/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9677 - loss: 0.0469 - val_accuracy: 0.9749 - val_loss: 0.0542\n",
      "Epoch 44/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9667 - loss: 0.0489 - val_accuracy: 0.9749 - val_loss: 0.0547\n",
      "Epoch 45/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9669 - loss: 0.0465 - val_accuracy: 0.9755 - val_loss: 0.0533\n",
      "Epoch 46/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9678 - loss: 0.0457 - val_accuracy: 0.9768 - val_loss: 0.0522\n",
      "Epoch 47/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9657 - loss: 0.0464 - val_accuracy: 0.9704 - val_loss: 0.0582\n",
      "Epoch 48/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9672 - loss: 0.0451 - val_accuracy: 0.9743 - val_loss: 0.0541\n",
      "Epoch 49/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9683 - loss: 0.0435 - val_accuracy: 0.9710 - val_loss: 0.0560\n",
      "Epoch 50/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9687 - loss: 0.0431 - val_accuracy: 0.9691 - val_loss: 0.0568\n",
      "Epoch 51/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9705 - loss: 0.0440 - val_accuracy: 0.9736 - val_loss: 0.0548\n",
      "Epoch 52/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9696 - loss: 0.0411 - val_accuracy: 0.9717 - val_loss: 0.0570\n",
      "Epoch 53/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9708 - loss: 0.0413 - val_accuracy: 0.9736 - val_loss: 0.0568\n",
      "Epoch 54/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9708 - loss: 0.0403 - val_accuracy: 0.9749 - val_loss: 0.0552\n",
      "Epoch 55/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9716 - loss: 0.0424 - val_accuracy: 0.9749 - val_loss: 0.0543\n",
      "Epoch 56/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9714 - loss: 0.0398 - val_accuracy: 0.9755 - val_loss: 0.0517\n",
      "Epoch 57/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9701 - loss: 0.0395 - val_accuracy: 0.9755 - val_loss: 0.0589\n",
      "Epoch 58/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9701 - loss: 0.0418 - val_accuracy: 0.9755 - val_loss: 0.0513\n",
      "Epoch 59/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9738 - loss: 0.0390 - val_accuracy: 0.9755 - val_loss: 0.0547\n",
      "Epoch 60/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9732 - loss: 0.0380 - val_accuracy: 0.9749 - val_loss: 0.0598\n",
      "Epoch 61/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9744 - loss: 0.0381 - val_accuracy: 0.9723 - val_loss: 0.0531\n",
      "Epoch 62/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9738 - loss: 0.0373 - val_accuracy: 0.9749 - val_loss: 0.0552\n",
      "Epoch 63/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9725 - loss: 0.0390 - val_accuracy: 0.9749 - val_loss: 0.0571\n",
      "Epoch 64/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9730 - loss: 0.0373 - val_accuracy: 0.9743 - val_loss: 0.0504\n",
      "Epoch 65/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9751 - loss: 0.0388 - val_accuracy: 0.9768 - val_loss: 0.0517\n",
      "Epoch 66/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9747 - loss: 0.0369 - val_accuracy: 0.9768 - val_loss: 0.0567\n",
      "Epoch 67/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9762 - loss: 0.0344 - val_accuracy: 0.9755 - val_loss: 0.0533\n",
      "Epoch 68/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9752 - loss: 0.0343 - val_accuracy: 0.9743 - val_loss: 0.0568\n",
      "Epoch 69/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9744 - loss: 0.0359 - val_accuracy: 0.9736 - val_loss: 0.0534\n",
      "Epoch 70/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9753 - loss: 0.0359 - val_accuracy: 0.9768 - val_loss: 0.0531\n",
      "Epoch 71/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9765 - loss: 0.0340 - val_accuracy: 0.9755 - val_loss: 0.0506\n",
      "Epoch 72/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9756 - loss: 0.0338 - val_accuracy: 0.9743 - val_loss: 0.0545\n",
      "Epoch 73/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9767 - loss: 0.0324 - val_accuracy: 0.9730 - val_loss: 0.0559\n",
      "Epoch 74/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9780 - loss: 0.0310 - val_accuracy: 0.9723 - val_loss: 0.0656\n",
      "Epoch 75/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9788 - loss: 0.0314 - val_accuracy: 0.9749 - val_loss: 0.0609\n",
      "Epoch 76/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9775 - loss: 0.0320 - val_accuracy: 0.9749 - val_loss: 0.0550\n",
      "Epoch 77/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9770 - loss: 0.0321 - val_accuracy: 0.9730 - val_loss: 0.0571\n",
      "Epoch 78/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9777 - loss: 0.0319 - val_accuracy: 0.9762 - val_loss: 0.0546\n",
      "Epoch 79/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9780 - loss: 0.0316 - val_accuracy: 0.9781 - val_loss: 0.0515\n",
      "Epoch 80/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9792 - loss: 0.0302 - val_accuracy: 0.9755 - val_loss: 0.0539\n",
      "Epoch 81/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9796 - loss: 0.0300 - val_accuracy: 0.9749 - val_loss: 0.0564\n",
      "Epoch 82/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9781 - loss: 0.0310 - val_accuracy: 0.9768 - val_loss: 0.0579\n",
      "Epoch 83/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9785 - loss: 0.0313 - val_accuracy: 0.9768 - val_loss: 0.0575\n",
      "Epoch 84/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9798 - loss: 0.0294 - val_accuracy: 0.9768 - val_loss: 0.0560\n",
      "Epoch 85/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9819 - loss: 0.0258 - val_accuracy: 0.9755 - val_loss: 0.0587\n",
      "Epoch 86/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9809 - loss: 0.0284 - val_accuracy: 0.9794 - val_loss: 0.0643\n",
      "Epoch 87/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9817 - loss: 0.0259 - val_accuracy: 0.9736 - val_loss: 0.0693\n",
      "Epoch 88/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9823 - loss: 0.0268 - val_accuracy: 0.9775 - val_loss: 0.0598\n",
      "Epoch 89/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9806 - loss: 0.0256 - val_accuracy: 0.9762 - val_loss: 0.0659\n",
      "Epoch 90/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9805 - loss: 0.0272 - val_accuracy: 0.9743 - val_loss: 0.0534\n",
      "Epoch 91/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9809 - loss: 0.0287 - val_accuracy: 0.9743 - val_loss: 0.0587\n",
      "Epoch 92/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9816 - loss: 0.0277 - val_accuracy: 0.9736 - val_loss: 0.0725\n",
      "Epoch 93/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9832 - loss: 0.0253 - val_accuracy: 0.9781 - val_loss: 0.0668\n",
      "Epoch 94/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9820 - loss: 0.0255 - val_accuracy: 0.9743 - val_loss: 0.0681\n",
      "Epoch 95/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9828 - loss: 0.0258 - val_accuracy: 0.9749 - val_loss: 0.0598\n",
      "Epoch 96/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9823 - loss: 0.0246 - val_accuracy: 0.9743 - val_loss: 0.0593\n",
      "Epoch 97/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9819 - loss: 0.0261 - val_accuracy: 0.9768 - val_loss: 0.0675\n",
      "Epoch 98/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9834 - loss: 0.0245 - val_accuracy: 0.9755 - val_loss: 0.0681\n",
      "Epoch 99/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9832 - loss: 0.0239 - val_accuracy: 0.9775 - val_loss: 0.0650\n",
      "Epoch 100/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9832 - loss: 0.0240 - val_accuracy: 0.9781 - val_loss: 0.0672\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9705 - loss: 0.0665\n",
      "Fold 4 - Test Accuracy: 0.9705\n",
      "âœ… Weights saved to results/cnn_lstm_fold4.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "ğŸ”¹ Fold 5\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_41\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_41\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_90          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_139 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_91          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_140 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_92          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_141 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_142 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_90 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_90          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_90 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_139 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_91 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_91          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_91 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_140 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_92 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_92          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_92 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_141 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_36 (\u001b[38;5;33mLSTM\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_61 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_142 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_62 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,793</span> (350.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,793\u001b[0m (350.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,345</span> (349.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,345\u001b[0m (349.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.7790 - loss: 0.2532 - val_accuracy: 0.8829 - val_loss: 0.2220\n",
      "Epoch 2/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9053 - loss: 0.1463 - val_accuracy: 0.8739 - val_loss: 0.1844\n",
      "Epoch 3/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9202 - loss: 0.1232 - val_accuracy: 0.8726 - val_loss: 0.1962\n",
      "Epoch 4/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9293 - loss: 0.1094 - val_accuracy: 0.8925 - val_loss: 0.1689\n",
      "Epoch 5/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9295 - loss: 0.1044 - val_accuracy: 0.8925 - val_loss: 0.1650\n",
      "Epoch 6/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9293 - loss: 0.0995 - val_accuracy: 0.9106 - val_loss: 0.1376\n",
      "Epoch 7/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9315 - loss: 0.0963 - val_accuracy: 0.9299 - val_loss: 0.1098\n",
      "Epoch 8/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9373 - loss: 0.0891 - val_accuracy: 0.9254 - val_loss: 0.1123\n",
      "Epoch 9/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9400 - loss: 0.0862 - val_accuracy: 0.9382 - val_loss: 0.0954\n",
      "Epoch 10/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9373 - loss: 0.0881 - val_accuracy: 0.9292 - val_loss: 0.1016\n",
      "Epoch 11/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9398 - loss: 0.0834 - val_accuracy: 0.9427 - val_loss: 0.0918\n",
      "Epoch 12/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9422 - loss: 0.0812 - val_accuracy: 0.9498 - val_loss: 0.0786\n",
      "Epoch 13/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9414 - loss: 0.0806 - val_accuracy: 0.9517 - val_loss: 0.0814\n",
      "Epoch 14/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9473 - loss: 0.0772 - val_accuracy: 0.9530 - val_loss: 0.0847\n",
      "Epoch 15/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9474 - loss: 0.0772 - val_accuracy: 0.9556 - val_loss: 0.0688\n",
      "Epoch 16/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9447 - loss: 0.0772 - val_accuracy: 0.9550 - val_loss: 0.0780\n",
      "Epoch 17/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9479 - loss: 0.0759 - val_accuracy: 0.9575 - val_loss: 0.0729\n",
      "Epoch 18/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9485 - loss: 0.0726 - val_accuracy: 0.9588 - val_loss: 0.0682\n",
      "Epoch 19/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9514 - loss: 0.0733 - val_accuracy: 0.9614 - val_loss: 0.0732\n",
      "Epoch 20/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9524 - loss: 0.0706 - val_accuracy: 0.9562 - val_loss: 0.0694\n",
      "Epoch 21/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9540 - loss: 0.0684 - val_accuracy: 0.9575 - val_loss: 0.0675\n",
      "Epoch 22/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9544 - loss: 0.0654 - val_accuracy: 0.9620 - val_loss: 0.0634\n",
      "Epoch 23/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9558 - loss: 0.0649 - val_accuracy: 0.9620 - val_loss: 0.0680\n",
      "Epoch 24/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9574 - loss: 0.0647 - val_accuracy: 0.9575 - val_loss: 0.0640\n",
      "Epoch 25/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9565 - loss: 0.0628 - val_accuracy: 0.9575 - val_loss: 0.0670\n",
      "Epoch 26/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9556 - loss: 0.0632 - val_accuracy: 0.9601 - val_loss: 0.0643\n",
      "Epoch 27/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9574 - loss: 0.0628 - val_accuracy: 0.9582 - val_loss: 0.0658\n",
      "Epoch 28/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9572 - loss: 0.0616 - val_accuracy: 0.9614 - val_loss: 0.0639\n",
      "Epoch 29/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9580 - loss: 0.0582 - val_accuracy: 0.9601 - val_loss: 0.0606\n",
      "Epoch 30/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9587 - loss: 0.0582 - val_accuracy: 0.9627 - val_loss: 0.0588\n",
      "Epoch 31/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9575 - loss: 0.0590 - val_accuracy: 0.9595 - val_loss: 0.0596\n",
      "Epoch 32/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9618 - loss: 0.0547 - val_accuracy: 0.9704 - val_loss: 0.0581\n",
      "Epoch 33/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9612 - loss: 0.0551 - val_accuracy: 0.9665 - val_loss: 0.0603\n",
      "Epoch 34/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9614 - loss: 0.0551 - val_accuracy: 0.9595 - val_loss: 0.0621\n",
      "Epoch 35/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9635 - loss: 0.0552 - val_accuracy: 0.9672 - val_loss: 0.0587\n",
      "Epoch 36/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9645 - loss: 0.0521 - val_accuracy: 0.9659 - val_loss: 0.0590\n",
      "Epoch 37/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9608 - loss: 0.0548 - val_accuracy: 0.9685 - val_loss: 0.0555\n",
      "Epoch 38/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9645 - loss: 0.0524 - val_accuracy: 0.9640 - val_loss: 0.0623\n",
      "Epoch 39/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9649 - loss: 0.0510 - val_accuracy: 0.9672 - val_loss: 0.0593\n",
      "Epoch 40/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9639 - loss: 0.0526 - val_accuracy: 0.9640 - val_loss: 0.0596\n",
      "Epoch 41/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9656 - loss: 0.0495 - val_accuracy: 0.9685 - val_loss: 0.0622\n",
      "Epoch 42/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9666 - loss: 0.0498 - val_accuracy: 0.9698 - val_loss: 0.0567\n",
      "Epoch 43/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9671 - loss: 0.0485 - val_accuracy: 0.9665 - val_loss: 0.0616\n",
      "Epoch 44/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9660 - loss: 0.0479 - val_accuracy: 0.9672 - val_loss: 0.0560\n",
      "Epoch 45/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9656 - loss: 0.0470 - val_accuracy: 0.9678 - val_loss: 0.0609\n",
      "Epoch 46/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9668 - loss: 0.0479 - val_accuracy: 0.9691 - val_loss: 0.0630\n",
      "Epoch 47/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9679 - loss: 0.0448 - val_accuracy: 0.9646 - val_loss: 0.0634\n",
      "Epoch 48/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9699 - loss: 0.0443 - val_accuracy: 0.9704 - val_loss: 0.0561\n",
      "Epoch 49/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9683 - loss: 0.0460 - val_accuracy: 0.9698 - val_loss: 0.0588\n",
      "Epoch 50/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9697 - loss: 0.0437 - val_accuracy: 0.9698 - val_loss: 0.0622\n",
      "Epoch 51/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9685 - loss: 0.0434 - val_accuracy: 0.9698 - val_loss: 0.0585\n",
      "Epoch 52/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9712 - loss: 0.0429 - val_accuracy: 0.9678 - val_loss: 0.0595\n",
      "Epoch 53/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9697 - loss: 0.0422 - val_accuracy: 0.9698 - val_loss: 0.0608\n",
      "Epoch 54/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9709 - loss: 0.0413 - val_accuracy: 0.9698 - val_loss: 0.0561\n",
      "Epoch 55/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9718 - loss: 0.0395 - val_accuracy: 0.9710 - val_loss: 0.0563\n",
      "Epoch 56/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9703 - loss: 0.0414 - val_accuracy: 0.9755 - val_loss: 0.0503\n",
      "Epoch 57/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9736 - loss: 0.0394 - val_accuracy: 0.9698 - val_loss: 0.0619\n",
      "Epoch 58/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9725 - loss: 0.0385 - val_accuracy: 0.9730 - val_loss: 0.0527\n",
      "Epoch 59/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9725 - loss: 0.0394 - val_accuracy: 0.9627 - val_loss: 0.0681\n",
      "Epoch 60/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9741 - loss: 0.0394 - val_accuracy: 0.9723 - val_loss: 0.0579\n",
      "Epoch 61/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9721 - loss: 0.0400 - val_accuracy: 0.9730 - val_loss: 0.0514\n",
      "Epoch 62/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9753 - loss: 0.0355 - val_accuracy: 0.9723 - val_loss: 0.0650\n",
      "Epoch 63/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9758 - loss: 0.0354 - val_accuracy: 0.9620 - val_loss: 0.0731\n",
      "Epoch 64/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9747 - loss: 0.0373 - val_accuracy: 0.9723 - val_loss: 0.0578\n",
      "Epoch 65/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9756 - loss: 0.0348 - val_accuracy: 0.9710 - val_loss: 0.0619\n",
      "Epoch 66/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9761 - loss: 0.0343 - val_accuracy: 0.9710 - val_loss: 0.0612\n",
      "Epoch 67/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9748 - loss: 0.0367 - val_accuracy: 0.9685 - val_loss: 0.0561\n",
      "Epoch 68/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9746 - loss: 0.0347 - val_accuracy: 0.9698 - val_loss: 0.0552\n",
      "Epoch 69/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9759 - loss: 0.0358 - val_accuracy: 0.9685 - val_loss: 0.0578\n",
      "Epoch 70/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9756 - loss: 0.0349 - val_accuracy: 0.9743 - val_loss: 0.0585\n",
      "Epoch 71/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9787 - loss: 0.0312 - val_accuracy: 0.9730 - val_loss: 0.0550\n",
      "Epoch 72/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9761 - loss: 0.0360 - val_accuracy: 0.9704 - val_loss: 0.0589\n",
      "Epoch 73/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9785 - loss: 0.0310 - val_accuracy: 0.9685 - val_loss: 0.0616\n",
      "Epoch 74/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9786 - loss: 0.0325 - val_accuracy: 0.9710 - val_loss: 0.0587\n",
      "Epoch 75/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9769 - loss: 0.0335 - val_accuracy: 0.9743 - val_loss: 0.0502\n",
      "Epoch 76/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9767 - loss: 0.0323 - val_accuracy: 0.9717 - val_loss: 0.0558\n",
      "Epoch 77/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9785 - loss: 0.0327 - val_accuracy: 0.9710 - val_loss: 0.0613\n",
      "Epoch 78/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9791 - loss: 0.0309 - val_accuracy: 0.9698 - val_loss: 0.0649\n",
      "Epoch 79/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9806 - loss: 0.0285 - val_accuracy: 0.9736 - val_loss: 0.0552\n",
      "Epoch 80/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9786 - loss: 0.0306 - val_accuracy: 0.9672 - val_loss: 0.0556\n",
      "Epoch 81/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9812 - loss: 0.0289 - val_accuracy: 0.9698 - val_loss: 0.0600\n",
      "Epoch 82/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9792 - loss: 0.0296 - val_accuracy: 0.9698 - val_loss: 0.0651\n",
      "Epoch 83/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9810 - loss: 0.0278 - val_accuracy: 0.9685 - val_loss: 0.0660\n",
      "Epoch 84/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9814 - loss: 0.0284 - val_accuracy: 0.9678 - val_loss: 0.0661\n",
      "Epoch 85/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9793 - loss: 0.0312 - val_accuracy: 0.9717 - val_loss: 0.0556\n",
      "Epoch 86/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9806 - loss: 0.0290 - val_accuracy: 0.9710 - val_loss: 0.0596\n",
      "Epoch 87/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9823 - loss: 0.0269 - val_accuracy: 0.9717 - val_loss: 0.0551\n",
      "Epoch 88/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9821 - loss: 0.0256 - val_accuracy: 0.9736 - val_loss: 0.0565\n",
      "Epoch 89/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9818 - loss: 0.0259 - val_accuracy: 0.9736 - val_loss: 0.0603\n",
      "Epoch 90/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9825 - loss: 0.0269 - val_accuracy: 0.9691 - val_loss: 0.0601\n",
      "Epoch 91/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9819 - loss: 0.0266 - val_accuracy: 0.9704 - val_loss: 0.0607\n",
      "Epoch 92/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9816 - loss: 0.0251 - val_accuracy: 0.9704 - val_loss: 0.0627\n",
      "Epoch 93/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9822 - loss: 0.0260 - val_accuracy: 0.9730 - val_loss: 0.0528\n",
      "Epoch 94/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9843 - loss: 0.0232 - val_accuracy: 0.9717 - val_loss: 0.0576\n",
      "Epoch 95/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9842 - loss: 0.0229 - val_accuracy: 0.9717 - val_loss: 0.0599\n",
      "Epoch 96/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9836 - loss: 0.0247 - val_accuracy: 0.9730 - val_loss: 0.0561\n",
      "Epoch 97/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9839 - loss: 0.0241 - val_accuracy: 0.9736 - val_loss: 0.0565\n",
      "Epoch 98/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9833 - loss: 0.0244 - val_accuracy: 0.9743 - val_loss: 0.0551\n",
      "Epoch 99/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9852 - loss: 0.0233 - val_accuracy: 0.9691 - val_loss: 0.0646\n",
      "Epoch 100/100\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9852 - loss: 0.0211 - val_accuracy: 0.9730 - val_loss: 0.0616\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9741 - loss: 0.0607\n",
      "Fold 5 - Test Accuracy: 0.9741\n",
      "âœ… Weights saved to results/cnn_lstm_fold5.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "ğŸ“Š Mean Accuracy: 0.9721818447113038\n",
      "\n",
      "ğŸ“Š Overall Metrics:\n",
      "  Accuracy : 0.9722\n",
      "  Precision: 0.9824\n",
      "  Recall   : 0.9711\n",
      "  F1-score : 0.9767\n",
      "âœ… CNN+LSTM Training Completed!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D, MaxPooling1D, LSTM, Dense, Dropout,\n",
    "    LayerNormalization, Add, Bidirectional,\n",
    "    GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- Load Data --------------------\n",
    "X = np.load(r\"preprocessed\\ALL_X.npy\")\n",
    "y = np.load(r\"preprocessed\\ALL_y.npy\")\n",
    "\n",
    "# Convert to binary: NORMAL = 0, ALL OTHERS = 1\n",
    "y_encoded = np.where(y == 'NORMAL', 0, 1)\n",
    "\n",
    "# Reshape for CNN input\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Labels distribution:\", np.unique(y_encoded, return_counts=True))\n",
    "\n",
    "# -------------------- Prepare Cross Validation --------------------\n",
    "random_state = np.random.randint(0, 10000)\n",
    "print(f\"ğŸ² Random state used for this run: {random_state}\")\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "fold_indices = [(train_idx, test_idx) for train_idx, test_idx in kfold.split(X, y_encoded)]\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "np.save(\"results/fold_indices.npy\", np.array(fold_indices, dtype=object), allow_pickle=True)\n",
    "\n",
    "def hybrid_focal_loss(alpha=0.25, gamma=2.0, bce_weight=0.5):\n",
    "    \"\"\"\n",
    "    Hybrid = BCE * bce_weight + FocalLoss * (1 - bce_weight)\n",
    "    \"\"\"\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        # --- Binary Cross Entropy ---\n",
    "        bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "        # --- Focal Loss ---\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        focal = -alpha * (1 - y_pred) ** gamma * y_true * K.log(y_pred) \\\n",
    "                - (1 - alpha) * y_pred ** gamma * (1 - y_true) * K.log(1 - y_pred)\n",
    "\n",
    "        focal = K.mean(focal, axis=-1)\n",
    "\n",
    "        # --- Combine Both ---\n",
    "        return bce_weight * bce + (1 - bce_weight) * focal\n",
    "\n",
    "    return loss\n",
    "\n",
    "# -------------------- CNN + LSTM Model --------------------\n",
    "def build_cnn_lstm(input_length):\n",
    "    model = Sequential([\n",
    "        # --- CNN Layers ---\n",
    "        Conv1D(32, kernel_size=7, activation='relu', input_shape=(input_length, 1)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Conv1D(64, kernel_size=5, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Conv1D(128, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.4),\n",
    "\n",
    "         # --- NEW Conv1D Layer ---\n",
    "        # Conv1D(256, kernel_size=3, activation='relu'),\n",
    "        # BatchNormalization(),\n",
    "        # MaxPooling1D(2),\n",
    "        # Dropout(0.4),\n",
    "\n",
    "        \n",
    "        # --- LSTM ---\n",
    "        LSTM(64, return_sequences=False),\n",
    "\n",
    "        # --- Dense Layers ---\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=hybrid_focal_loss(alpha=0.25, gamma=2.0, bce_weight=0.5),\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- Data Augmentation for 1D EEG (Optimized Version) --------------------\n",
    "def augment_signal(signal):\n",
    "    # 1) Very Light Noise\n",
    "    noise = np.random.normal(0, 0.005, signal.shape)\n",
    "    signal_noisy = signal + noise\n",
    "\n",
    "    # 2) Small Time Shift\n",
    "    shift = np.random.randint(-5, 5)\n",
    "    signal_shifted = np.roll(signal_noisy, shift)\n",
    "\n",
    "    # 3) Gentle Scaling\n",
    "    scale = np.random.uniform(0.97, 1.03)\n",
    "    signal_scaled = signal_shifted * scale\n",
    "\n",
    "    return signal_scaled\n",
    "\n",
    "\n",
    "\n",
    "def augment_batch(X, y):\n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        X_aug.append(X[i])\n",
    "        y_aug.append(y[i])\n",
    "\n",
    "        # Generate **1 weakly augmented version**\n",
    "        X_aug.append(augment_signal(X[i]))\n",
    "        y_aug.append(y[i])\n",
    "\n",
    "    return np.array(X_aug), np.array(y_aug)\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- Training --------------------\n",
    "acc_per_fold = []\n",
    "conf_matrices = []\n",
    "\n",
    "for fold_no, (train_val_idx, test_idx) in enumerate(fold_indices, start=1):\n",
    "    print(f\"\\nğŸ”¹ Fold {fold_no}\")\n",
    "\n",
    "    # Split into train/val/test\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y_encoded[train_val_idx], y_encoded[test_idx]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.1765, stratify=y_train_val, random_state=42\n",
    "    )\n",
    "\n",
    "    # ------------ APPLY DATA AUGMENTATION ------------\n",
    "    X_train, y_train = augment_batch(X_train, y_train)\n",
    "\n",
    "    print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "\n",
    "    # Build new model for each fold\n",
    "    model = build_cnn_lstm(X_train.shape[1])\n",
    "    model.summary()\n",
    "\n",
    "    # Handle class imbalance\n",
    "    cw = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = {0: cw[0], 1: cw[1]}\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val),\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    acc_per_fold.append(test_acc)\n",
    "    print(f\"Fold {fold_no} - Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # Save weights\n",
    "    weight_path = f\"results/cnn_lstm_fold{fold_no}.weights.h5\"\n",
    "    model.save_weights(weight_path)\n",
    "    print(f\"âœ… Weights saved to {weight_path}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\").flatten()\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrices.append(cm)\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt='d', cmap='Blues',\n",
    "        xticklabels=['Normal', 'Abnormal'], \n",
    "        yticklabels=['Normal', 'Abnormal']\n",
    "    )\n",
    "    plt.title(f\"Fold {fold_no} Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"results/cnn_lstm_conf_fold{fold_no}.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\nğŸ“Š Mean Accuracy:\", np.mean(acc_per_fold))\n",
    "\n",
    "# -------------------- Overall Confusion Matrix --------------------\n",
    "total_cm = np.sum(conf_matrices, axis=0)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(\n",
    "    total_cm, annot=True, fmt='d', cmap='Greens',\n",
    "    xticklabels=['Normal', 'Abnormal'], \n",
    "    yticklabels=['Normal', 'Abnormal']\n",
    ")\n",
    "plt.title(\"Overall Confusion Matrix (All Folds)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/cnn_lstm_conf_overall.png\")\n",
    "\n",
    "tn, fp, fn, tp = total_cm.ravel()\n",
    "\n",
    "overall_accuracy = (tp + tn) / np.sum(total_cm)\n",
    "overall_precision = tp / (tp + fp)\n",
    "overall_recall = tp / (tp + fn)\n",
    "overall_f1 = 2 * overall_precision * overall_recall / (overall_precision + overall_recall)\n",
    "\n",
    "print(\"\\nğŸ“Š Overall Metrics:\")\n",
    "print(f\"  Accuracy : {overall_accuracy:.4f}\")\n",
    "print(f\"  Precision: {overall_precision:.4f}\")\n",
    "print(f\"  Recall   : {overall_recall:.4f}\")\n",
    "print(f\"  F1-score : {overall_f1:.4f}\")\n",
    "\n",
    "print(\"âœ… CNN+LSTM Training Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5199e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
