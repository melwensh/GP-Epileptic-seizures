{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5b6d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (11000, 347, 1)\n",
      "Labels distribution: (array([0, 1]), array([2200, 8800]))\n",
      "ğŸ² Random state used for this run: 3690\n",
      "\n",
      "ğŸ”¹ Fold 1\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_24          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_25          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_26          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_24          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_24 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_25          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_25 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_26          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_26 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_34 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_16 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_17 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,793</span> (350.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,793\u001b[0m (350.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,345</span> (349.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,345\u001b[0m (349.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.4974 - loss: 0.3615 - val_accuracy: 0.7825 - val_loss: 0.3363\n",
      "Epoch 2/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 42ms/step - accuracy: 0.8067 - loss: 0.2388 - val_accuracy: 0.9556 - val_loss: 0.1140\n",
      "Epoch 3/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9308 - loss: 0.1187 - val_accuracy: 0.9646 - val_loss: 0.0779\n",
      "Epoch 4/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9451 - loss: 0.0992 - val_accuracy: 0.9691 - val_loss: 0.0594\n",
      "Epoch 5/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9518 - loss: 0.0841 - val_accuracy: 0.9640 - val_loss: 0.0642\n",
      "Epoch 6/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9617 - loss: 0.0708 - val_accuracy: 0.9788 - val_loss: 0.0436\n",
      "Epoch 7/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9636 - loss: 0.0688 - val_accuracy: 0.9685 - val_loss: 0.0524\n",
      "Epoch 8/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9652 - loss: 0.0631 - val_accuracy: 0.9736 - val_loss: 0.0435\n",
      "Epoch 9/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9682 - loss: 0.0607 - val_accuracy: 0.9717 - val_loss: 0.0495\n",
      "Epoch 10/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9698 - loss: 0.0568 - val_accuracy: 0.9826 - val_loss: 0.0357\n",
      "Epoch 11/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9693 - loss: 0.0508 - val_accuracy: 0.9813 - val_loss: 0.0354\n",
      "Epoch 12/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9712 - loss: 0.0520 - val_accuracy: 0.9820 - val_loss: 0.0345\n",
      "Epoch 13/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9732 - loss: 0.0493 - val_accuracy: 0.9820 - val_loss: 0.0328\n",
      "Epoch 14/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9759 - loss: 0.0436 - val_accuracy: 0.9794 - val_loss: 0.0341\n",
      "Epoch 15/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9738 - loss: 0.0441 - val_accuracy: 0.9820 - val_loss: 0.0320\n",
      "Epoch 16/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9776 - loss: 0.0391 - val_accuracy: 0.9852 - val_loss: 0.0327\n",
      "Epoch 17/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9770 - loss: 0.0405 - val_accuracy: 0.9826 - val_loss: 0.0288\n",
      "Epoch 18/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9781 - loss: 0.0357 - val_accuracy: 0.9871 - val_loss: 0.0273\n",
      "Epoch 19/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9818 - loss: 0.0339 - val_accuracy: 0.9858 - val_loss: 0.0269\n",
      "Epoch 20/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9819 - loss: 0.0325 - val_accuracy: 0.9839 - val_loss: 0.0294\n",
      "Epoch 21/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9811 - loss: 0.0319 - val_accuracy: 0.9858 - val_loss: 0.0243\n",
      "Epoch 22/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9823 - loss: 0.0333 - val_accuracy: 0.9820 - val_loss: 0.0303\n",
      "Epoch 23/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9825 - loss: 0.0286 - val_accuracy: 0.9794 - val_loss: 0.0299\n",
      "Epoch 24/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9848 - loss: 0.0284 - val_accuracy: 0.9871 - val_loss: 0.0247\n",
      "Epoch 25/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9846 - loss: 0.0247 - val_accuracy: 0.9858 - val_loss: 0.0242\n",
      "Epoch 26/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9847 - loss: 0.0243 - val_accuracy: 0.9852 - val_loss: 0.0223\n",
      "Epoch 27/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9854 - loss: 0.0243 - val_accuracy: 0.9826 - val_loss: 0.0250\n",
      "Epoch 28/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9850 - loss: 0.0263 - val_accuracy: 0.9852 - val_loss: 0.0235\n",
      "Epoch 29/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9868 - loss: 0.0222 - val_accuracy: 0.9852 - val_loss: 0.0242\n",
      "Epoch 30/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9854 - loss: 0.0218 - val_accuracy: 0.9807 - val_loss: 0.0286\n",
      "Epoch 31/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9883 - loss: 0.0201 - val_accuracy: 0.9884 - val_loss: 0.0234\n",
      "Epoch 32/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9878 - loss: 0.0211 - val_accuracy: 0.9826 - val_loss: 0.0257\n",
      "Epoch 33/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9887 - loss: 0.0175 - val_accuracy: 0.9833 - val_loss: 0.0269\n",
      "Epoch 34/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9890 - loss: 0.0190 - val_accuracy: 0.9858 - val_loss: 0.0222\n",
      "Epoch 35/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9890 - loss: 0.0188 - val_accuracy: 0.9897 - val_loss: 0.0221\n",
      "Epoch 36/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9892 - loss: 0.0185 - val_accuracy: 0.9865 - val_loss: 0.0228\n",
      "Epoch 37/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9895 - loss: 0.0169 - val_accuracy: 0.9858 - val_loss: 0.0261\n",
      "Epoch 38/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9888 - loss: 0.0159 - val_accuracy: 0.9865 - val_loss: 0.0205\n",
      "Epoch 39/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9908 - loss: 0.0152 - val_accuracy: 0.9884 - val_loss: 0.0169\n",
      "Epoch 40/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9912 - loss: 0.0144 - val_accuracy: 0.9916 - val_loss: 0.0168\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0117\n",
      "Fold 1 - Test Accuracy: 0.9945\n",
      "âœ… Weights saved to results/cnn_lstm_fold1.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "ğŸ”¹ Fold 2\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_27          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_28          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_29          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_27          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_27 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_28 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_28          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_28 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_37 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_29 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_29          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_29 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_38 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_18 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_39 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_19 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,793</span> (350.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,793\u001b[0m (350.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,345</span> (349.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,345\u001b[0m (349.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 22ms/step - accuracy: 0.5157 - loss: 0.3676 - val_accuracy: 0.7136 - val_loss: 0.3407\n",
      "Epoch 2/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7424 - loss: 0.2813 - val_accuracy: 0.9350 - val_loss: 0.1607\n",
      "Epoch 3/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9102 - loss: 0.1446 - val_accuracy: 0.9781 - val_loss: 0.0665\n",
      "Epoch 4/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9422 - loss: 0.1053 - val_accuracy: 0.9781 - val_loss: 0.0526\n",
      "Epoch 5/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9484 - loss: 0.0915 - val_accuracy: 0.9781 - val_loss: 0.0414\n",
      "Epoch 6/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9561 - loss: 0.0760 - val_accuracy: 0.9852 - val_loss: 0.0334\n",
      "Epoch 7/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9595 - loss: 0.0699 - val_accuracy: 0.9852 - val_loss: 0.0320\n",
      "Epoch 8/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9619 - loss: 0.0650 - val_accuracy: 0.9878 - val_loss: 0.0264\n",
      "Epoch 9/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9655 - loss: 0.0577 - val_accuracy: 0.9871 - val_loss: 0.0238\n",
      "Epoch 10/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9676 - loss: 0.0572 - val_accuracy: 0.9846 - val_loss: 0.0251\n",
      "Epoch 11/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9694 - loss: 0.0536 - val_accuracy: 0.9865 - val_loss: 0.0243\n",
      "Epoch 12/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9682 - loss: 0.0534 - val_accuracy: 0.9871 - val_loss: 0.0239\n",
      "Epoch 13/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9726 - loss: 0.0477 - val_accuracy: 0.9884 - val_loss: 0.0222\n",
      "Epoch 14/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9748 - loss: 0.0429 - val_accuracy: 0.9865 - val_loss: 0.0223\n",
      "Epoch 15/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9696 - loss: 0.0445 - val_accuracy: 0.9884 - val_loss: 0.0194\n",
      "Epoch 16/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9750 - loss: 0.0407 - val_accuracy: 0.9903 - val_loss: 0.0168\n",
      "Epoch 17/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9753 - loss: 0.0409 - val_accuracy: 0.9897 - val_loss: 0.0178\n",
      "Epoch 18/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9774 - loss: 0.0408 - val_accuracy: 0.9923 - val_loss: 0.0151\n",
      "Epoch 19/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9779 - loss: 0.0354 - val_accuracy: 0.9929 - val_loss: 0.0131\n",
      "Epoch 20/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9784 - loss: 0.0376 - val_accuracy: 0.9910 - val_loss: 0.0144\n",
      "Epoch 21/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9787 - loss: 0.0354 - val_accuracy: 0.9936 - val_loss: 0.0141\n",
      "Epoch 22/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9812 - loss: 0.0294 - val_accuracy: 0.9865 - val_loss: 0.0171\n",
      "Epoch 23/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9781 - loss: 0.0323 - val_accuracy: 0.9942 - val_loss: 0.0122\n",
      "Epoch 24/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 179ms/step - accuracy: 0.9839 - loss: 0.0291 - val_accuracy: 0.9936 - val_loss: 0.0115\n",
      "Epoch 25/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9821 - loss: 0.0279 - val_accuracy: 0.9891 - val_loss: 0.0170\n",
      "Epoch 26/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9832 - loss: 0.0262 - val_accuracy: 0.9942 - val_loss: 0.0108\n",
      "Epoch 27/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9843 - loss: 0.0274 - val_accuracy: 0.9923 - val_loss: 0.0115\n",
      "Epoch 28/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9843 - loss: 0.0238 - val_accuracy: 0.9936 - val_loss: 0.0105\n",
      "Epoch 29/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9839 - loss: 0.0246 - val_accuracy: 0.9942 - val_loss: 0.0106\n",
      "Epoch 30/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9854 - loss: 0.0216 - val_accuracy: 0.9942 - val_loss: 0.0109\n",
      "Epoch 31/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9839 - loss: 0.0275 - val_accuracy: 0.9878 - val_loss: 0.0197\n",
      "Epoch 32/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9861 - loss: 0.0219 - val_accuracy: 0.9974 - val_loss: 0.0062\n",
      "Epoch 33/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9892 - loss: 0.0189 - val_accuracy: 0.9923 - val_loss: 0.0112\n",
      "Epoch 34/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9876 - loss: 0.0182 - val_accuracy: 0.9929 - val_loss: 0.0121\n",
      "Epoch 35/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9860 - loss: 0.0226 - val_accuracy: 0.9936 - val_loss: 0.0086\n",
      "Epoch 36/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9892 - loss: 0.0181 - val_accuracy: 0.9916 - val_loss: 0.0128\n",
      "Epoch 37/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9874 - loss: 0.0205 - val_accuracy: 0.9903 - val_loss: 0.0130\n",
      "Epoch 38/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9892 - loss: 0.0165 - val_accuracy: 0.9923 - val_loss: 0.0124\n",
      "Epoch 39/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9911 - loss: 0.0145 - val_accuracy: 0.9955 - val_loss: 0.0079\n",
      "Epoch 40/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9888 - loss: 0.0185 - val_accuracy: 0.9942 - val_loss: 0.0084\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.0196\n",
      "Fold 2 - Test Accuracy: 0.9900\n",
      "âœ… Weights saved to results/cnn_lstm_fold2.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "ğŸ”¹ Fold 3\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_30          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_31          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_32          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_30 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_30          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_30 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_40 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_31 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_31          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_31 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_41 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_32 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_32          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_32 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_42 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_20 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_43 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_21 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,793</span> (350.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,793\u001b[0m (350.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,345</span> (349.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,345\u001b[0m (349.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 22ms/step - accuracy: 0.4892 - loss: 0.3663 - val_accuracy: 0.7748 - val_loss: 0.3291\n",
      "Epoch 2/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.7458 - loss: 0.2757 - val_accuracy: 0.9028 - val_loss: 0.1896\n",
      "Epoch 3/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9155 - loss: 0.1399 - val_accuracy: 0.9344 - val_loss: 0.1173\n",
      "Epoch 4/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9493 - loss: 0.0951 - val_accuracy: 0.9511 - val_loss: 0.0974\n",
      "Epoch 5/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9520 - loss: 0.0798 - val_accuracy: 0.9588 - val_loss: 0.0866\n",
      "Epoch 6/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9591 - loss: 0.0722 - val_accuracy: 0.9588 - val_loss: 0.0881\n",
      "Epoch 7/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9628 - loss: 0.0646 - val_accuracy: 0.9710 - val_loss: 0.0652\n",
      "Epoch 8/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9687 - loss: 0.0568 - val_accuracy: 0.9633 - val_loss: 0.0733\n",
      "Epoch 9/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9705 - loss: 0.0524 - val_accuracy: 0.9640 - val_loss: 0.0758\n",
      "Epoch 10/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9738 - loss: 0.0477 - val_accuracy: 0.9736 - val_loss: 0.0601\n",
      "Epoch 11/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9755 - loss: 0.0445 - val_accuracy: 0.9717 - val_loss: 0.0664\n",
      "Epoch 12/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9755 - loss: 0.0427 - val_accuracy: 0.9698 - val_loss: 0.0767\n",
      "Epoch 13/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9782 - loss: 0.0386 - val_accuracy: 0.9736 - val_loss: 0.0582\n",
      "Epoch 14/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9783 - loss: 0.0368 - val_accuracy: 0.9781 - val_loss: 0.0534\n",
      "Epoch 15/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9776 - loss: 0.0369 - val_accuracy: 0.9762 - val_loss: 0.0547\n",
      "Epoch 16/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9781 - loss: 0.0356 - val_accuracy: 0.9736 - val_loss: 0.0675\n",
      "Epoch 17/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9808 - loss: 0.0345 - val_accuracy: 0.9833 - val_loss: 0.0412\n",
      "Epoch 18/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9794 - loss: 0.0323 - val_accuracy: 0.9801 - val_loss: 0.0460\n",
      "Epoch 19/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9818 - loss: 0.0310 - val_accuracy: 0.9801 - val_loss: 0.0552\n",
      "Epoch 20/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9820 - loss: 0.0290 - val_accuracy: 0.9801 - val_loss: 0.0402\n",
      "Epoch 21/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9842 - loss: 0.0265 - val_accuracy: 0.9820 - val_loss: 0.0404\n",
      "Epoch 22/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9834 - loss: 0.0266 - val_accuracy: 0.9794 - val_loss: 0.0555\n",
      "Epoch 23/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9865 - loss: 0.0237 - val_accuracy: 0.9813 - val_loss: 0.0474\n",
      "Epoch 24/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9845 - loss: 0.0254 - val_accuracy: 0.9865 - val_loss: 0.0313\n",
      "Epoch 25/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9879 - loss: 0.0218 - val_accuracy: 0.9820 - val_loss: 0.0617\n",
      "Epoch 26/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9874 - loss: 0.0224 - val_accuracy: 0.9858 - val_loss: 0.0327\n",
      "Epoch 27/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9894 - loss: 0.0174 - val_accuracy: 0.9813 - val_loss: 0.0531\n",
      "Epoch 28/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9906 - loss: 0.0160 - val_accuracy: 0.9846 - val_loss: 0.0407\n",
      "Epoch 29/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9872 - loss: 0.0206 - val_accuracy: 0.9865 - val_loss: 0.0259\n",
      "Epoch 30/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9881 - loss: 0.0170 - val_accuracy: 0.9858 - val_loss: 0.0347\n",
      "Epoch 31/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9881 - loss: 0.0203 - val_accuracy: 0.9852 - val_loss: 0.0294\n",
      "Epoch 32/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9872 - loss: 0.0194 - val_accuracy: 0.9865 - val_loss: 0.0293\n",
      "Epoch 33/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9885 - loss: 0.0190 - val_accuracy: 0.9878 - val_loss: 0.0227\n",
      "Epoch 34/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9908 - loss: 0.0156 - val_accuracy: 0.9897 - val_loss: 0.0262\n",
      "Epoch 35/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9884 - loss: 0.0179 - val_accuracy: 0.9871 - val_loss: 0.0273\n",
      "Epoch 36/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9911 - loss: 0.0157 - val_accuracy: 0.9897 - val_loss: 0.0213\n",
      "Epoch 37/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9913 - loss: 0.0136 - val_accuracy: 0.9891 - val_loss: 0.0219\n",
      "Epoch 38/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9911 - loss: 0.0144 - val_accuracy: 0.9910 - val_loss: 0.0273\n",
      "Epoch 39/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9900 - loss: 0.0160 - val_accuracy: 0.9878 - val_loss: 0.0198\n",
      "Epoch 40/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9920 - loss: 0.0143 - val_accuracy: 0.9891 - val_loss: 0.0222\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0227\n",
      "Fold 3 - Test Accuracy: 0.9941\n",
      "âœ… Weights saved to results/cnn_lstm_fold3.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "ğŸ”¹ Fold 4\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_33          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_34          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_35          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_33 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_33          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_33 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_34 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_34          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_34 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_35 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_35          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_35 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_46 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_22 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_47 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_23 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,793</span> (350.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,793\u001b[0m (350.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,345</span> (349.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,345\u001b[0m (349.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 22ms/step - accuracy: 0.5842 - loss: 0.3701 - val_accuracy: 0.8018 - val_loss: 0.3029\n",
      "Epoch 2/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.7834 - loss: 0.2463 - val_accuracy: 0.9228 - val_loss: 0.1444\n",
      "Epoch 3/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9277 - loss: 0.1224 - val_accuracy: 0.9543 - val_loss: 0.0955\n",
      "Epoch 4/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9474 - loss: 0.0993 - val_accuracy: 0.9685 - val_loss: 0.0748\n",
      "Epoch 5/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9511 - loss: 0.0879 - val_accuracy: 0.9543 - val_loss: 0.0838\n",
      "Epoch 6/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9583 - loss: 0.0825 - val_accuracy: 0.9640 - val_loss: 0.0706\n",
      "Epoch 7/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 237ms/step - accuracy: 0.9573 - loss: 0.0728 - val_accuracy: 0.9646 - val_loss: 0.0717\n",
      "Epoch 8/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9643 - loss: 0.0677 - val_accuracy: 0.9717 - val_loss: 0.0588\n",
      "Epoch 9/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9689 - loss: 0.0611 - val_accuracy: 0.9781 - val_loss: 0.0521\n",
      "Epoch 10/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9702 - loss: 0.0565 - val_accuracy: 0.9743 - val_loss: 0.0522\n",
      "Epoch 11/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9710 - loss: 0.0520 - val_accuracy: 0.9820 - val_loss: 0.0342\n",
      "Epoch 12/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9721 - loss: 0.0506 - val_accuracy: 0.9813 - val_loss: 0.0387\n",
      "Epoch 13/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9727 - loss: 0.0469 - val_accuracy: 0.9833 - val_loss: 0.0330\n",
      "Epoch 14/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9731 - loss: 0.0453 - val_accuracy: 0.9794 - val_loss: 0.0382\n",
      "Epoch 15/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9756 - loss: 0.0437 - val_accuracy: 0.9846 - val_loss: 0.0321\n",
      "Epoch 16/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9781 - loss: 0.0384 - val_accuracy: 0.9846 - val_loss: 0.0325\n",
      "Epoch 17/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9786 - loss: 0.0362 - val_accuracy: 0.9794 - val_loss: 0.0399\n",
      "Epoch 18/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9793 - loss: 0.0330 - val_accuracy: 0.9865 - val_loss: 0.0281\n",
      "Epoch 19/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9811 - loss: 0.0330 - val_accuracy: 0.9820 - val_loss: 0.0271\n",
      "Epoch 20/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9814 - loss: 0.0319 - val_accuracy: 0.9891 - val_loss: 0.0201\n",
      "Epoch 21/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9818 - loss: 0.0301 - val_accuracy: 0.9897 - val_loss: 0.0171\n",
      "Epoch 22/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9833 - loss: 0.0276 - val_accuracy: 0.9891 - val_loss: 0.0169\n",
      "Epoch 23/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9832 - loss: 0.0295 - val_accuracy: 0.9910 - val_loss: 0.0148\n",
      "Epoch 24/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9848 - loss: 0.0256 - val_accuracy: 0.9903 - val_loss: 0.0171\n",
      "Epoch 25/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9832 - loss: 0.0271 - val_accuracy: 0.9903 - val_loss: 0.0149\n",
      "Epoch 26/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9848 - loss: 0.0240 - val_accuracy: 0.9916 - val_loss: 0.0153\n",
      "Epoch 27/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9858 - loss: 0.0227 - val_accuracy: 0.9903 - val_loss: 0.0162\n",
      "Epoch 28/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9864 - loss: 0.0241 - val_accuracy: 0.9936 - val_loss: 0.0137\n",
      "Epoch 29/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9848 - loss: 0.0233 - val_accuracy: 0.9916 - val_loss: 0.0134\n",
      "Epoch 30/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9881 - loss: 0.0198 - val_accuracy: 0.9865 - val_loss: 0.0256\n",
      "Epoch 31/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9898 - loss: 0.0179 - val_accuracy: 0.9910 - val_loss: 0.0161\n",
      "Epoch 32/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9858 - loss: 0.0205 - val_accuracy: 0.9910 - val_loss: 0.0168\n",
      "Epoch 33/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9859 - loss: 0.0236 - val_accuracy: 0.9891 - val_loss: 0.0224\n",
      "Epoch 34/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9903 - loss: 0.0177 - val_accuracy: 0.9923 - val_loss: 0.0112\n",
      "Epoch 35/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9875 - loss: 0.0217 - val_accuracy: 0.9929 - val_loss: 0.0131\n",
      "Epoch 36/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9907 - loss: 0.0154 - val_accuracy: 0.9936 - val_loss: 0.0141\n",
      "Epoch 37/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9863 - loss: 0.0206 - val_accuracy: 0.9936 - val_loss: 0.0125\n",
      "Epoch 38/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9897 - loss: 0.0171 - val_accuracy: 0.9891 - val_loss: 0.0197\n",
      "Epoch 39/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9908 - loss: 0.0144 - val_accuracy: 0.9942 - val_loss: 0.0148\n",
      "Epoch 40/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9888 - loss: 0.0170 - val_accuracy: 0.9936 - val_loss: 0.0089\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9895 - loss: 0.0177\n",
      "Fold 4 - Test Accuracy: 0.9895\n",
      "âœ… Weights saved to results/cnn_lstm_fold4.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "ğŸ”¹ Fold 5\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_36          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_37          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_38          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_36 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_36          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_36 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_48 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_37 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_37          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_37 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_49 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_38 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_38          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_38 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_50 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_24 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_25 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,793</span> (350.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,793\u001b[0m (350.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,345</span> (349.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,345\u001b[0m (349.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 22ms/step - accuracy: 0.5705 - loss: 0.3662 - val_accuracy: 0.8063 - val_loss: 0.2870\n",
      "Epoch 2/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7587 - loss: 0.2659 - val_accuracy: 0.9131 - val_loss: 0.1481\n",
      "Epoch 3/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9273 - loss: 0.1194 - val_accuracy: 0.9492 - val_loss: 0.0915\n",
      "Epoch 4/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9507 - loss: 0.0921 - val_accuracy: 0.9614 - val_loss: 0.0717\n",
      "Epoch 5/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9588 - loss: 0.0734 - val_accuracy: 0.9633 - val_loss: 0.0706\n",
      "Epoch 6/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9629 - loss: 0.0681 - val_accuracy: 0.9730 - val_loss: 0.0582\n",
      "Epoch 7/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9650 - loss: 0.0620 - val_accuracy: 0.9749 - val_loss: 0.0576\n",
      "Epoch 8/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9669 - loss: 0.0566 - val_accuracy: 0.9730 - val_loss: 0.0611\n",
      "Epoch 9/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9689 - loss: 0.0511 - val_accuracy: 0.9839 - val_loss: 0.0424\n",
      "Epoch 10/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9696 - loss: 0.0498 - val_accuracy: 0.9833 - val_loss: 0.0408\n",
      "Epoch 11/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9724 - loss: 0.0462 - val_accuracy: 0.9852 - val_loss: 0.0354\n",
      "Epoch 12/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9740 - loss: 0.0441 - val_accuracy: 0.9871 - val_loss: 0.0340\n",
      "Epoch 13/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9770 - loss: 0.0389 - val_accuracy: 0.9839 - val_loss: 0.0354\n",
      "Epoch 14/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9790 - loss: 0.0374 - val_accuracy: 0.9852 - val_loss: 0.0350\n",
      "Epoch 15/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9783 - loss: 0.0405 - val_accuracy: 0.9891 - val_loss: 0.0314\n",
      "Epoch 16/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9796 - loss: 0.0352 - val_accuracy: 0.9865 - val_loss: 0.0310\n",
      "Epoch 17/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9803 - loss: 0.0309 - val_accuracy: 0.9878 - val_loss: 0.0367\n",
      "Epoch 18/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9795 - loss: 0.0331 - val_accuracy: 0.9871 - val_loss: 0.0322\n",
      "Epoch 19/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9825 - loss: 0.0301 - val_accuracy: 0.9884 - val_loss: 0.0282\n",
      "Epoch 20/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9823 - loss: 0.0294 - val_accuracy: 0.9865 - val_loss: 0.0322\n",
      "Epoch 21/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9826 - loss: 0.0294 - val_accuracy: 0.9897 - val_loss: 0.0271\n",
      "Epoch 22/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9812 - loss: 0.0304 - val_accuracy: 0.9897 - val_loss: 0.0281\n",
      "Epoch 23/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9823 - loss: 0.0269 - val_accuracy: 0.9871 - val_loss: 0.0322\n",
      "Epoch 24/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9868 - loss: 0.0222 - val_accuracy: 0.9871 - val_loss: 0.0287\n",
      "Epoch 25/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9844 - loss: 0.0262 - val_accuracy: 0.9891 - val_loss: 0.0273\n",
      "Epoch 26/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9843 - loss: 0.0243 - val_accuracy: 0.9903 - val_loss: 0.0207\n",
      "Epoch 27/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9838 - loss: 0.0264 - val_accuracy: 0.9878 - val_loss: 0.0276\n",
      "Epoch 28/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9887 - loss: 0.0198 - val_accuracy: 0.9884 - val_loss: 0.0223\n",
      "Epoch 29/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9881 - loss: 0.0219 - val_accuracy: 0.9897 - val_loss: 0.0215\n",
      "Epoch 30/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9871 - loss: 0.0212 - val_accuracy: 0.9903 - val_loss: 0.0218\n",
      "Epoch 31/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9868 - loss: 0.0225 - val_accuracy: 0.9897 - val_loss: 0.0246\n",
      "Epoch 32/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 958ms/step - accuracy: 0.9894 - loss: 0.0177 - val_accuracy: 0.9903 - val_loss: 0.0175\n",
      "Epoch 33/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9889 - loss: 0.0175 - val_accuracy: 0.9910 - val_loss: 0.0200\n",
      "Epoch 34/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9896 - loss: 0.0148 - val_accuracy: 0.9916 - val_loss: 0.0187\n",
      "Epoch 35/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9890 - loss: 0.0172 - val_accuracy: 0.9910 - val_loss: 0.0212\n",
      "Epoch 36/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9909 - loss: 0.0153 - val_accuracy: 0.9897 - val_loss: 0.0219\n",
      "Epoch 37/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9903 - loss: 0.0160 - val_accuracy: 0.9929 - val_loss: 0.0138\n",
      "Epoch 38/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9923 - loss: 0.0126 - val_accuracy: 0.9897 - val_loss: 0.0170\n",
      "Epoch 39/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9904 - loss: 0.0153 - val_accuracy: 0.9891 - val_loss: 0.0175\n",
      "Epoch 40/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9908 - loss: 0.0162 - val_accuracy: 0.9916 - val_loss: 0.0145\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9950 - loss: 0.0168  \n",
      "Fold 5 - Test Accuracy: 0.9950\n",
      "âœ… Weights saved to results/cnn_lstm_fold5.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "ğŸ“Š Mean Accuracy: 0.9926363706588746\n",
      "\n",
      "ğŸ“Š Overall Metrics:\n",
      "  Accuracy : 0.9926\n",
      "  Precision: 0.9946\n",
      "  Recall   : 0.9962\n",
      "  F1-score : 0.9954\n",
      "âœ… CNN+LSTM Training Completed!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeIAAAGGCAYAAACnjILvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAATNtJREFUeJzt3Ql8DPf/P/C3IBcirgh134mzoiqKlsZ9FkX5om6KIq6m7qPuW4u2FHXU0aKOOlJn3UTdgjqrztZ9RcL+H6+P/+xvN9klm93Jxub17GO62ZnPzM7ujn3P+3PMpDAYDAYhIiIip3BzzssSERERMBATERE5EQMxERGREzEQExEROREDMRERkRMxEBMRETkRAzEREZETMRATERE5EQMxERGREzEQu6Bt27ZJihQp1KPm008/lTx58sibYMGCBVKkSBFJnTq1+Pr6Onz7Q4cOVZ8PvXTx4kX1ecybN8+hH8m4cePU9/jixYsErW/pmMV+4vtLip9NQv6NbdiwQdKmTSu3bt2yYy/pTcdAbMGJEyfkf//7n7z11lvi4eEh2bNnlxYtWqj5ycXKlSulZs2akjlzZnF3d1efQZMmTWTLli26vm5kZKT6QcufP798//338t1334krwY86pvbt21tcPmDAAGOZf//91+bt//bbb4kaqKy5f/++jB07Vvr37y9ubnF/Zu7evSuenp7qfZ46dUqX4GlpKleunCQlNWrUkAIFCsjo0aOdvSvkRKmc+eJJ0YoVK+STTz6RjBkzSrt27SRv3rzqH/acOXPk559/liVLlshHH30krgqXHm/btq3KAN5++20JDQ0Vf39/uXbtmgrOH374oezatUvKly+vy+sji0cGNXXqVPUDpYeBAwfKF198Ic6CAPTLL7/IjBkz1EmOqZ9++kktf/r0aYK2jUD8zTff2BSMc+fOLU+ePFE1EI7yww8/SExMjPq3ZMny5ctVYMSxtWjRIhk5cqQ4Gl67Vq1aZvOyZMkiSU2nTp2kT58+MmzYMEmXLp2zd4ecgIHYxLlz56Rly5aSL18+2bFjh9k/2h49ekjFihXV8qNHj6oyieXRo0eSJk2aRHmtiRMnqiDcs2dPmTRpklkVLrI1VBunSqXfYXPz5k31qEeVtAb7r+d7iE8WtHr1alm/fr3Ur1/fOH/37t1y4cIFadSokQrUekOgxEkPTgYQ/B1p7ty5Uq9ePavbXbhwoQqSOAlYvHixLoG4dOnSqmYrqcP33b17d3VygpNgSn5YNW1i/Pjx8vjxY1UdGvvMGVW03377rQqKaPsCZMgIVNu3b4/zwaIslh0/ftys2rVx48Yq28YPVJkyZdQPsikEQW2bn332mfj5+UmOHDnUskuXLql5hQsXFi8vL8mUKZN8/PHHKmN3BGRFqCJDu96ECRMstqPiRKRs2bLG5+fPn1f7gPfk7e2tqv7WrVtnsc162bJl8tVXX6n3g/eP7Pqvv/4ylkP72pAhQ9Tf+PxN2wOttQ1iHVRla6Kjo1VmUbBgQfUa+IwqVKgg4eHhr2wjRlAaMWKEqhJHcwS2++WXX0pUVFSc16tTp47s3LlTfQ54DZyU/fjjj/H+nNHkUalSJRWATCEzLF68uBQrVizOOn/88Yf6nHPlyqX2L2fOnNKrVy/1nWnwOSAb1j4vbTKtrsX3OmXKFOP7PHnyZJx2UJwM4fP/4IMPVA2JBt8VTgibNm36yveHkwmcrIaEhFhcfvnyZfV+mjVrpiaUx0lIYovPsWvNqlWr1PeE7x+PqC2yBDVoQUFBKtP18fFR3y9qe0zh33iJEiXk119/dcj7ojcPM2ITa9asUT+0yHwtwY8nlmv/WGvXrq06WiDAvP/++2Zlly5dKkWLFjX+qKJ9+b333lM/wqgWxQ8a1mvQoIHKfmJXdyPg4sdw8ODBKvjDgQMH1A8WfrwQzPADOnPmTPWDiR9U/JjYA8Hl9u3bKhtOmTLla8vfuHFDVVHj5OXzzz9XQW/+/PkqE8JJSuz3NGbMGNVeiGq4e/fuqRMatL3v27dPLUeAQEDDjxreFz5b/EDZAkEWJxNog0WgRFvlwYMH5dChQ1K1alWr66E89h0nSr1791b7hO2g/TL2jywCEsqh6aJ169aqGhZBED+4+M7jo3nz5qqW5eHDh+p94kQAGRGaAixVS2MZPucuXbqoz3n//v0yffp0uXLlilqmVXFevXpVnXSg5sJaportd+zYUQViBKHYnakQGPD5I0jhNfDdogzeIwIKqtRfRQuqyEgtQfU7jn+c0OCEEicFOAlxdHMHPq/Y7ezp06dXVfC2HrumNm3apLLYwMBAdYz8999/0qZNG+MJswbfA6rHccKJ9nLA8YSmHXz3pnDsILhTMoX7EZPBcPfuXZz6G+rXr//Kj6NevXqq3P3799XzTz75xODn52eIiYkxlrl27ZrBzc3NMHz4cOO8Dz/80FC8eHHD06dPjfNevHhhKF++vKFgwYLGeXPnzlXbr1Chgtk24fHjx3H2Z8+ePar8jz/+aJy3detWNQ+PmtatWxty5879yvc2depUtd7KlSvjdUj07NlTlf/jjz+M8x48eGDImzevIU+ePIbnz5+b7U9AQIAhKioqzusdO3bMOG/IkCFq3q1bt8xeC/OwLDa8J7w3TcmSJQ21a9d+5X5rr6E5fPiwet6+fXuzcn369FHzt2zZYvZ6mLdjxw7jvJs3bxo8PDwMvXv3fuXrau+ja9euhtu3bxvc3d0NCxYsUPPXrVtnSJEiheHixYsWPwNL3/3o0aPVOpcuXTLOw7Yt/bO+cOGCmu/j46P219IyHHumcGx7e3sbzpw5Yxg/frwqs2rVqte+x4EDB6qyOBYswb+DFi1aGJ9/+eWXhsyZMxuio6PNylk6Zq0dB5bej6VJ+zcR32PX0mdTqlQpQ7Zs2dRvhmbTpk2qnOn+9ujRQ33esf8dWzJq1Ci1/o0bN15bllwPq6b/vwcPHqjH13WW0JYj0wJU06Eqz3SoEM6okUFoVXjIMtHbGL2O8To4S8eEM+nq1avL2bNn5Z9//jF7nQ4dOsTJSpE9mFbBYn10aEJ7KjI+e2nvKb4dRtAxCFknqn41yO6QbSFbR5ZuClmDaeckreYBVYSOgs8CtQ/4TOML7wOQjZpCZgyxqyuRCZnWmqDmAs0FtryPDBkyqLZiZIeAampkaGgztcT0u0cNCY4flEds+vPPP+P9usjk4tth6euvv1YZJLL/QYMGqWYJ0zZta3Bcog0ex0JsqLI+duyYWScu/I33s3HjRnEkHIfISk2nkiVLJujY1aDT4uHDh1VNCD4bDWpbcFzEPhbxXZk2i7zqeICE9JSnNx8D8f+nBR8tIMc3YOPHFP8gURWtwd+lSpWSQoUKGasy8YOJHzP8CJpOWpuo1klJg97asaE9EFXVaB9EtSLarbENDAVBVa+90IYVn89AgzZrBKDYAgICjMtNoX3T0o/PnTt3xFGGDx+uPg989miP69u3r/rxfxXsJ6rMY/fSRo9e/Ji+7n1o78XW94HqafxIo80U1ZJ4bg3KoGoYVckIGPjeteYQW757S8eVNXitadOmqc8Pxzj+thc6aaFaGu3q+HeBCe2saPJB9bQjoZ8A2qlNJ+2Ys/XY1Wjzse3YYm8PzUs4DjEMENXW6IiFccOWaG3xHN+ePLGN+P/DD022bNle+6ON5Wjn1YIWAiLaedGOiLYztD2hDWjUqFHGdbQ2OLSNIgO2JHYQMM2ANOhZiTY+tOEGBwerfcY/XLQZJ/SiCabQSQuQseA9OZq1dmfTDkG2ev78eZx2fPR+R8cXtOXNnj1bJk+eLLNmzbI6dlcT3x9BR70PtEfi+EF2hU5hqDGx9h6RcaFmBeNy8T0hmKEWBcHZlu/e0nH1KlqWipMMtEfHpzc72lvR5o0TOtPaFXw+qAFAlhg7e9RORrU2c1eAtnZkz/gM0UMeE/79tmrVSrVHm9JO4nByTckPA7EJdB7BRSTQacm0ykqDnp6otkKnGFOogsY/rM2bN6vOGPjBMe1Zqg11QicRaz1J4wNV3vjRxhAjDTreIAN0BLxnZAz4sUSP4dd12EI16unTp+PMR+9wbbmjYL9iv89nz56pqkJLmRyqwTHhhx3BGZ24rAVi7CeCGaqztYwIcFKF13Tk+4gdFHHCgyxRu3iKJTgxOnPmjDrG8COusVTl6ciMCtkbTmT69eunslUce+jE9rqhX9oJHXpDm3a2w0gABHPUWph+zlogQrUwagYSY8hRQo9dbb6lpg9L20NTTN26ddWEYwxZMkZUoHbM9OQbn5VWw0XJD6umTaAaEz+OCLRo5zKFbKRz586qZzLKmUJwxY8/qqQxoe3JtAoQZ8bo2Yx/gJYCR3wvb4fAGDvrQq/W2FlhQuG9IePCyQQeLWV4CBrosQsYB4q/9+zZY1yObAfDv1DVaCnrSSj0rMXYblN4ndjvPfb3huwKP3ixhyGZ0i76gF7bpjCOWusdrxfUkqB5Aj/M1mgnRKbfB/6OPQwGtPHm9p6cYX2t5zlqdxCQ0Q/BtKbHGtTWAHqrW6qWxr8ftDubTugTgepeR1dPW5PQYxe1Zmh2wkmRaZMATopityvHPhbR/KGdmMQ+HiMiIoyfGyU/zIhN4IcA/8AwpAbti7GvrIWOFMgWERRMIdNt2LChGjOIf8wYqxkbxnci48R28aODLBkZF34IkCUcOXIkXhk7hqWgSho/FFj3999/V1WBjoIfSXR2Qta9detW9SOJttLr16+rbAU/XtrwFAzDwueBbA5DQHAygs8PZ/cYkmXp0oYJhaCAEyF0NkI1LT4vVPnFziLxueCkB8NBsD8IBqhJ6Natm9VtowMPsj38CCMAoe0V7xPvBRlr5cqVHfY+LL221oHoVRkmjjkEbVRHo1kEn6+lNmm8b8D3gWYQBHE0XdgKw2sQSHB8YRvoC4HvABfeQIetV+0zjm0M28O62gUqEHiwz/jurF3kA1X1OLlAFTVOXvVkz7GLIUs4OcO/Z7w/nKTjhBhD11ADo8HnhWVVqlRRbcRoX0Y5BHLTGgG8XzR5de3aVdf3TEmYs7ttJ0VHjx5VQzcwRCF16tQGf39/9dx0mE1s4eHhavgBhpP8/fffFsucO3fO0KpVK7U9bPett94y1KlTx/Dzzz/HGb504MCBOOvfuXPH0KZNGzXUI23atIbq1asbIiMj4wzhSejwJVPYp2rVqhkyZsxoSJUqlfosmjZtati2bVuc99S4cWODr6+vwdPT01C2bFnD2rVrzcpo+7N8+XKz+ZaGhlgbvoThJP3791fvHUNq8N7/+uuvOO995MiRah+wP15eXoYiRYoYvvrqK8OzZ8/ivIYpDJ0ZNmyYGr6C7yZnzpyGsLAws+FmgNezNDzq/fffV1N8hy+9iqXP4OTJk4aQkBD1veMz6NChg+HIkSNxPj8MlenevbshS5Ys6ljU3qf2WWMYUmyxv4dff/1VPZ84caJZOQzZw/vHEDHTz9OSSZMmqX3Vhl398ssvaptz5syxug6OLZTBsDZHDF+y9F5tPXatDe3C+8FwPAxbCwwMNKxYsSLO/mr/hjC8EUPVcuXKZejUqZMa3mhq5syZ6pjWhkRS8pMC/3P2yQARuRZU2yIzxkVbULNE1uGa7qjFQadCSp4YiIlIF7iaFHoJo+3Ukc0UrgQd4tD8gzHoelfHU9LFQExEROREPE0lIiJyIgZiIiIiJ2IgJiIiciIGYiIiIidiICYiInKiJHNlrf23/nD2LhDZpUTGl1e1InqTeab01mW7KarmsGt9Q/gVcVXMiImIiJwoyWTERETkwhx4ZzBXw0BMRET6Y/2rVQzERESkP2bEVjEQExGR/lgzbRUrC4iIiJyIGTEREemPVdNWMRATEZH+WP9qFQMxERHpjxmxVQzERESkP3bWsoqVBURERE7EjJiIiPTnxpTYGgZiIiLSH+OwVQzERESkP3bWsoptxERERE7EjJiIiPTHqmmrGIiJiEh/7KxlFQMxERHpjxmxVQzERESkP3bWsoqdtYiIiJyIGTEREemPbcRWMRATEZH+2EZsFQMxERHpj23EVrGNmIiIEicjtmeywfPnz2XQoEGSN29e8fLykvz588uIESPEYDAYy+DvwYMHS7Zs2VSZkJAQOXv2rNl2bt++LS1atBAfHx/x9fWVdu3aycOHD83KHD16VCpWrCienp6SM2dOGTdunNiKgZiIiFzK2LFjZebMmfL111/LqVOn1HMEyOnTpxvL4Pm0adNk1qxZsm/fPkmTJo1Ur15dnj59aiyDIHzixAkJDw+XtWvXyo4dO6Rjx47G5ffv35dq1apJ7ty5JSIiQsaPHy9Dhw6V7777zqb9TWEwPUVwov23/nD2LhDZpUTGIH6C9MbzTOmty3ZTtC5s1/qG+afjXbZOnTqSNWtWmTNnjnFeo0aNVOa7cOFClQ1nz55devfuLX369FHL7927p9aZN2+eNGvWTAXwwMBAOXDggJQpU0aV2bBhg9SqVUuuXLmi1kewHzBggFy/fl3c3d1VmS+++EJWrVolkZGR8d5fZsRERORSVdPly5eXzZs3y5kzZ9TzI0eOyM6dO6VmzZrq+YULF1TwRHW0Jn369PLuu+/Knj171HM8ojpaC8KA8m5ubiqD1spUqlTJGIQBWfXp06flzp078d5fdtYiIqIk31krKipKTaY8PDzUFBuyUlQbFylSRFKmTKnajL/66itV1QwIwoAM2BSea8vw6OfnZ7Y8VapUkjFjRrMyaIeOvQ1tWYYMGeL13pgRExGR/tzsm0aPHq2yVtMJ8yxZtmyZLFq0SBYvXiyHDh2S+fPny4QJE9RjUsSMmIiIkrywsDAJDQ01m2cpG4a+ffuqrBhtvVC8eHG5dOmSCtytW7cWf39/Nf/GjRuq17QGz0uVKqX+RpmbN2+abTcmJkb1pNbWxyPWMaU918rEBzNiIiJKnKppOyYPDw81jMh0shaIHz9+rNpyTaGK+sWLF+pvVCcjUKIdWYOqbLT9BgcHq+d4vHv3ruoNrdmyZYvaBtqStTLoSR0dHW0sgx7WhQsXjne1NDAQExGRS3XWqlu3rmoTXrdunVy8eFFWrlwpkyZNko8++ujlrqRIIT179pSRI0fK6tWr5dixY9KqVSvVE7pBgwaqTEBAgNSoUUM6dOgg+/fvl127dkm3bt1Ulo1y0Lx5c9VRC+OLMcxp6dKlMnXq1DiZ++uwapqIiFzqylrTp09XF/T47LPPVPUyAmenTp3UBTw0/fr1k0ePHqlxwch8K1SooIYn4cIcGrQzI/h++OGHKsPGECiMPdagnXrTpk3StWtXCQoKksyZM6vXMB1rHB8cR0zkIBxHTK5At3HEnQPtWt8w66S4KlZNExERORGrpomISH+86YNVDMRERKQ/3gbRKgZiIiLSnxsjsTVsIyYiInIiZsRERKQ/thFbxUBMRET6Y820VQzERESkO1zNiixjICYiIt0xEFvHzlpEREROxIyYiIh0x5pp6xiIiYhId26MxFYxEBMRke7YRmwdAzEREemOgdg6dtYiIiJyImbERESkO2bE1jEQExGR7thXyzoGYiIi0h0zYusYiImISHcMxNaxsxYREZETMSMmIiLdpeDtl6xiICYiIt2xato6BmIiItIde01bxzZiIiIiJ2JGTEREuuNNHxwQiO/fvx/fouLj4xPvskRE5PrYRuyAqmlfX1/JkCHDKyetDBERUexAbM9kizx58ljcRteuXdXyp0+fqr8zZcokadOmlUaNGsmNGzfMtnH58mWpXbu2eHt7i5+fn/Tt21diYmLMymzbtk1Kly4tHh4eUqBAAZk3b57omhFv3bo1QS9ARESUmJ21Dhw4IM+fPzc+P378uFStWlU+/vhj9bxXr16ybt06Wb58uaRPn166desmDRs2lF27dqnlWBdB2N/fX3bv3i3Xrl2TVq1aSerUqWXUqFGqzIULF1SZzp07y6JFi2Tz5s3Svn17yZYtm1SvXt2m/U1hMBgMkgTsv/WHs3eByC4lMgbxE6Q3nmdKb122m3lwebvW/3f47gSv27NnT1m7dq2cPXtWNbNmyZJFFi9eLI0bN1bLIyMjJSAgQPbs2SPlypWT9evXS506deTq1auSNWtWVWbWrFnSv39/uXXrlri7u6u/EcwR5DXNmjWTu3fvyoYNGxKv1/Tjx4/VGzh69KjZRERE5KyqaVPPnj2ThQsXStu2bdV2IiIiJDo6WkJCQoxlihQpIrly5VKBGPBYvHhxYxAGZLkI4idOnDCWMd2GVkbbhu69pnFG0KZNG3XWYIlplQAREZG9nbWioqLUZApts5heZdWqVSpL/fTTT9Xz69evq4wWfZpMIehimVbGNAhry7VlryqDYP3kyRPx8vLSNyNGmo83tm/fPvViSMPnz58vBQsWlNWrVydkk0RE5MLszYhHjx6t2nNNJ8x7nTlz5kjNmjUle/bsklQlKCPesmWL/Prrr1KmTBlxc3OT3Llzq4ZwDFvCB4MGbCIiIkdlxGFfhEloaKjZvNdlw5cuXZLff/9dVqxYYZyHDliorkYyaZoVo9c0lmll9u/fb7YtrVe1aZnYPa3xHHHQlmw4wRnxo0ePVHduwHAlVFUD6tQPHTqUkE0SERFZhaCLIGc6vS4Qz507V8Uq0+QwKChI9X5GL2fN6dOn1XCl4OBg9RyPx44dk5s3bxrLhIeHq9cMDAw0ljHdhlZG24bugbhw4cJqx6FkyZLy7bffyj///KN6laHrNhERkSkkxPZMtnrx4oUKxK1bt5ZUqf6v8hdV2u3atVPZNYblovMW+jwhgKLHNFSrVk0F3JYtW8qRI0dk48aNMnDgQDX2WAv+GLZ0/vx56devn+q0PGPGDFm2bJkaGpUoVdM9evRQ46pgyJAhUqNGDTWOCg3gCR3QTEREriuxr6z1+++/qywXvaVjmzx5smpWxYU80AEMvZ0RSDUpU6ZUw526dOmiAnSaNGlUQB8+fLixTN68edXwJQTeqVOnSo4cOWT27Nk2jyF22DhibRgTun9nzpw5QdvgOGJ603EcMbkCvcYRv/XVB3at/8+AbeKqHHLTB1wCDJf5IiIisoQ3fXBwIEYS/fPPP6v6dTRmoy7elGkPNSIiInJwIMY4YnTQqly5shrAzLtqEBHRqyRyE7HrB+IFCxaorLdWrVqO3yOyaPWC3+Tg9kNy7dI1Se3hLgWL55dmXRpLtlwvx7TBll+3y57wfXLxzGV5+vipzFo/TdKkM2/v6dW4v/x7/T+zeU06NZS6LV9+l6cORcqGZb/LuVMX5MmjJ+KfI6vUal5d3qv2sjchUWKa8/0PMm3ydGnRsrn0C+ur5v1761+ZNGGK7N29Vx49fqTutNOhUzsJqWZ+uUFKWpiwOTgQo/t3vnz5ErIqJVDkn6clpGFlyVckjzx//kKWf7dCxvaaJGMWjhBPr5fd6Z9FPZMS7xZT07JvrTcPNGpfXz6oW8n43NPb0/j32ePnJGf+HFK7RQ1Jn9FHDu86Kt+OnCPeabzk7fdK8vujRHP82An5edkvUqhwQbP5A8IGyYMHD2TqN1MkQwZf+W3deukb2l8WL1skAYFF+A0lUSmEKbFDxxEPHTpUhg0bpq6nSYmj36ReUqnWe5Ij31uSu2BO6fhlW/nvxm25ePqSsUyNJlVVZlug6KtPkhB4fTOlN05aIId6rWpL4w4NpFDxApL1LT+p3iREBXZk40SJ5fGjxxLW70sZMmyQuoiCqSN/HpFPWjST4iWKSY6cOaRj5w6SLl06OXXyJL8gSj6BuEmTJnLnzh11xRJcTQs9pk0n0t+TR4/VYxqfNDavu3bheulSq4cMbDNM1i3eIM9jXn2TjicPnyTodYgSatTI0VLp/YpSrnzcJpGSb5eUjes3yb2791RH0fW/bZCoZ1FS5p0y/MCTMGfdfcllq6YxsBlXI/nf//7HzlpOgB+fhdOWqqw1Z763bFq3WuMPJU+hXCqwohp62awVcve/e9Kie1OL5fdtPiDnIy9Km74tHbT3RK+GwHrqZKQsXrbQ4vLxk8ZJv979pVL5D9QVkzw9PWXytEmSK3cufrRJmKsH00QPxLiaCC75VaFCBYfdzgrtm+4e7gnaXnIzf9IiuXL+Hxk0o7/N69ZsVs34d64COdUP2dzxC1SHrdTuqc3KnjwUKd+Nnivt+rVSVeJEert+7bqMGz1evp090+p1hL+Z9o08uP9AvpszS3wz+MrWzdukX2g/mbvgBylYyLw9mZIOxmEHV03nzJkzTruNLSzdzmr+VMtnvxQ3CB/efVTCpvWRjH4Z7f548gfmVfePjt2T+tSfp2VS/+kqU65Qszy/BkoUJ0+cktv/3ZZmjZtL6eJl1HTwQIQsXviT+vvvy3/LksVLZdjIofJu8LtSuEhh6dy1kwQWDVTzKeli1bSDM+KJEyeqC13jJg8YOmCrsLC4t7M6ev9AQnYl2cBFVH6cvFgidvwpX07vK37Zszhku5f++ltSuKUQH990xnkYwjSx/3Rp2rmRVKn/vkNehyg+3g0uKz//utxs3pABQyRP3rzSpv2n8vTpUzXPzc28mtMtZUr1b4Qo2QRitA3j+tL58+dXl7fELaVM3b59+5Xro8opdrWTexSrpV9l/sRFsuf3fdJzdDfV6xntuuCd1stYpY95927fkxv/vLx115XzV1TZTFkzSlqftKpN+NzJ8xLwdhHx8vaUsyfOyaJpS9UYYa0zFqqjJ/abJtU/DpF3Pggyvk6q1CnVNoj0hIvrFyxYwGwe7u3q65tezY+OjpZcuXLKiKEjJbRvqJq/ZfNWNaZ4+oyp/HKSMLYROzgQT5kyJSGrkR02r3p5wfNR3cebze/wZRs1rAm2rNomK+euMS4b2XWcWZnUqVPJ3t8PyMofVkv0sxjJkj2z1GhaVWo2rWpc54/1u+XZ02eyZsFvatIUKVVIBnzdj98hORVO+r+eNV2mTp4mn3ftoRICFZhHD5eK71fkt5OEMRA78O5LOCPt1KmTDBo0SN0GylF49yV60/HuS+QK9Lr7UuHJNexa/3SvDeKq3BJyRvrLL7/oszdEROSS2FnLwb2mGzRoIKtWrUrIqkRERGRvG3HBggVl+PDhsmvXLgkKClIdLEx9/vnnCdksERG5KLYRO7CNGF7VNowP+/z587Zukm3E9MZjGzG5Ar3aiAOn1bZr/ZOfrxNXlaCM+MKFC47fEyIiclm8spaDA7EpLaFmtQMREVnDGOHgzlrw448/qjsvYbA9phIlSsiCBQsSujkiIqJkKUEZ8aRJk9Q44m7dusl77728mMTOnTulc+fO8u+//0qvXr0cvZ9ERPQGY0bs4EA8ffp0mTlzprRq1co4r169elK0aFEZOnQoAzEREZlhIHZwIL527ZqULx/3jjyYh2VERESm2FnLwW3EBQoUkGXLlsWZv3TpUjXGmIiIiHTMiIcNGyZNmzaVHTt2GNuIcXGPzZs3WwzQRESUvLFq2sEZcaNGjWTfvn2SKVMmdalLTJkzZ5b9+/fLRx99lJBNEhGRq9dN2zPZ6J9//lG37EWcwsgejPI5ePCg2dDbwYMHS7Zs2dTykJAQOXv2bJxb+rZo0UJ8fHzE19dX2rVrJw8fPjQrc/ToUalYsaJ4enpKzpw5Zdy4l3e9S5RxxLi05aJFixK6OhERJSOJmRHfuXNH1dZWrlxZ1q9fL1myZFFBNkOGDMYyCJjTpk2T+fPnq6tFYiRQ9erV5eTJkyqoAoIw+j2Fh4erOw+2adNGOnbsKIsXL1bL79+/L9WqVVNBfNasWXLs2DFp27atCtoop8slLt3c3F77YWJ5TEyM2Iq3QaQ3HS9xSa5Ar0tclv7evtrSQx1WxrvsF198oZpL//jjD4vLEfayZ88uvXv3lj59+qh59+7dk6xZs8q8efOkWbNmcurUKQkMDJQDBw5ImTJlVJkNGzZIrVq15MqVK2p9jB4aMGCAXL9+Xdzd3Y2vjVriyMhIfTLilSutfxB79uxRZxcvXrywZZNEREQOtXr1apXdfvzxx7J9+3Z566235LPPPpMOHToYL9OM4IlMVpM+fXp59913VSxDIMYjMlstCAPKIyFF0yyaYVGmUqVKxiAMeN2xY8eqrNw0A3dYIK5fv36ceadPn1ZnAGvWrFFpPO7KRERE5Miq6aioKDWZ8vDwUFNsuPEQstXQ0FD58ssvVVaLuwIiYLZu3VoFYUAGbArPtWV49PPzM1ueKlUqyZgxo1mZ2DdB0raJZfENxAm+xOXVq1fV2QUawFEVffjwYVXXnjt37oRukoiIXBQCsT3T6NGjVdZqOmGeJaiZLV26tIwaNUrefvtt1V6LeIV23KTI5kCMevT+/furscQnTpxQQ5aQDRcrVkyfPSQiIknugTgsLEzFH9MJ8yxBT2i075oKCAiQy5cvq7/9/f3V440bN8zK4Lm2DI83b940W46kEz2pTctY2obpazg8EKOXWb58+WTt2rXy008/ye7du1W3bSIiIj1HL3l4eKhhRKaTpWppQI9pNJuaOnPmjLHGFtXJCJRIJDXoAY223+DgYPUcj3fv3pWIiAhjmS1btqhsG23JWhlcTwM9qjXoYV24cOF4V0snqNe0Nt4qZcqUVsutWLFCbMVe0/SmY69pcgV69ZouO7exXevvb/NzvMuiTRiXXMbFp5o0aaKucYGq6e+++071ZQJ0qBozZozZ8CWMCTYdvlSzZk2V4aJKWxu+hM5b2vAlZOUIuhjChJri48ePq+FLkydPtmn4kk2dtXCTB14dhYiIbJWYseOdd95Ro3xQdY0OxAi0U6ZMMQZh6Nevnzx69EgFTGS+FSpUUMOTtCAMuFYG7jL44YcfqkQUF7PC6CAN2qk3bdokXbt2VdfWwIWtcJEQW4KwzRmxnpgR05uOGTG5Ar0y4nLzm9i1/t7Wrnv55ARfWYuIiCi+WJtqHQMxERHpjoFYh3HEREREZD9mxEREpLtE7Kv1xmEgJiIi3bFq2joGYiIi0h0DsXUMxEREpDsGYuvYWYuIiMiJmBETEZHu2FnLOgZiIiLSHaumrWMgJiIi/TEltoptxERERE7EjJiIiHTHqmnrGIiJiEh3bryyllUMxEREpDtmxNYxEBMRke7c2FnLKnbWIiIiciJmxEREpDtWTVvHQExERLpj9at1DMRERKQ7thFbx0BMRES6Y9W0dawtICIiciJmxEREpDtWTVvHQExERLpj1bR1DMRERKQ7toNax0BMRES6Y9W0dTxJISIiciIGYiIiSpQ2YnsmWwwdOjTO+kWKFDEuf/r0qXTt2lUyZcokadOmlUaNGsmNGzfMtnH58mWpXbu2eHt7i5+fn/Tt21diYmLMymzbtk1Kly4tHh4eUqBAAZk3b54kBAMxERElStW0PZOtihYtKteuXTNOO3fuNC7r1auXrFmzRpYvXy7bt2+Xq1evSsOGDY3Lnz9/roLws2fPZPfu3TJ//nwVZAcPHmwsc+HCBVWmcuXKcvjwYenZs6e0b99eNm7caPO+so2YiIh0l9i3I06VKpX4+/vHmX/v3j2ZM2eOLF68WKpUqaLmzZ07VwICAmTv3r1Srlw52bRpk5w8eVJ+//13yZo1q5QqVUpGjBgh/fv3V9m2u7u7zJo1S/LmzSsTJ05U28D6CPaTJ0+W6tWr27SvzIiJiCjJi4qKkvv375tNmGfN2bNnJXv27JIvXz5p0aKFqmqGiIgIiY6OlpCQEGNZVFvnypVL9uzZo57jsXjx4ioIaxBc8ZonTpwwljHdhlZG24YtGIiJiCjJV02PHj1a0qdPbzZhniXvvvuuqkresGGDzJw5U1UjV6xYUR48eCDXr19XGa2vr6/ZOgi6WAZ4NA3C2nJt2avKIFg/efLEps+GVdNERJTkhy+FhYVJaGio2Tx0krKkZs2axr9LlCihAnPu3Lll2bJl4uXlJUkNM2IiIkryvaY9PDzEx8fHbLIWiGND9luoUCH566+/VLsxOmHdvXvXrAx6TWttyniM3Ytae/66MtgvW4M9AzEREblcr2lTDx8+lHPnzkm2bNkkKChIUqdOLZs3bzYuP336tGpDDg4OVs/xeOzYMbl586axTHh4uAqygYGBxjKm29DKaNuwBQMxERG5lD59+qhhSRcvXlTDjz766CNJmTKlfPLJJ6ptuV27dqqae+vWrarzVps2bVQARY9pqFatmgq4LVu2lCNHjqghSQMHDlRjj7UsvHPnznL+/Hnp16+fREZGyowZM1TVN4ZG2YptxERE5FLDl65cuaKC7n///SdZsmSRChUqqKFJ+BswxMjNzU1dyAM9r9HbGYFUg6C9du1a6dKliwrQadKkkdatW8vw4cONZTB0ad26dSrwTp06VXLkyCGzZ8+2eegSpDAYDAZJAvbf+sPZu0BklxIZg/gJ0hvPM6W3LtttE97drvXnVp0urooZMRER6Y43fbCOgZiIiHTH+xFbx85aRERETsSMmIiIdMeqaesYiImIyOVu+vAmYSAmIiLdMSO2joGYiIh0x0BsHTtrEREROREzYiIi0h2HL1nHQExERLpj9at1DMRERKQ7ZsTW8SSFiIjIiZgRExGR7thr2joGYiIi0h0DsXUMxEREpDu2Eb8BgZj3cqU3nVeNQs7eBSK7GcKv6PIpuvEil1axsxYREZETJZmMmIiIXBerpq1jICYiIt2xs5Z1DMRERKS7FGwjtoqBmIiIdMeqaevYWYuIiMiJmBETEZHu2EZsHQMxERHpLgUrYK1iICYiIt0xI7aOgZiIiHTHzlrWsbMWERG5tDFjxqgTgZ49exrnPX36VLp27SqZMmWStGnTSqNGjeTGjRtm612+fFlq164t3t7e4ufnJ3379pWYmBizMtu2bZPSpUuLh4eHFChQQObNm2fz/jEQExFRoowjtue/hDpw4IB8++23UqJECbP5vXr1kjVr1sjy5ctl+/btcvXqVWnYsKFx+fPnz1UQfvbsmezevVvmz5+vguzgwYONZS5cuKDKVK5cWQ4fPqwCffv27WXjxo027SMDMRERJUobsT1TQjx8+FBatGgh33//vWTIkME4/969ezJnzhyZNGmSVKlSRYKCgmTu3Lkq4O7du1eV2bRpk5w8eVIWLlwopUqVkpo1a8qIESPkm2++UcEZZs2aJXnz5pWJEydKQECAdOvWTRo3biyTJ0+2aT8ZiImISHeoGrZnioqKkvv375tNmPcqqHpGxhoSEmI2PyIiQqKjo83mFylSRHLlyiV79uxRz/FYvHhxyZo1q7FM9erV1eueOHHCWCb2tlFG20Z8MRATEZHu3Oz8b/To0ZI+fXqzCfOsWbJkiRw6dMhimevXr4u7u7v4+vqazUfQxTKtjGkQ1pZry15VBsH6yZMn8f5s2GuaiIiSvLCwMAkNDTWbhw5Slvz999/So0cPCQ8PF09PT0nqmBETEVGSr5r28PAQHx8fs8laIEbV882bN1Vv5lSpUqkJHbKmTZum/kbWinbeu3fvmq2HXtP+/v7qbzzG7kWtPX9dGeybl5dXvD8bBmIiIkrygdgWH374oRw7dkz1ZNamMmXKqI5b2t+pU6eWzZs3G9c5ffq0Gq4UHBysnuMR20BA1yDDRpANDAw0ljHdhlZG20Z8sWqaiIh055aIt0FMly6dFCtWzGxemjRp1JhhbX67du1UVXfGjBlVcO3evbsKoOXKlVPLq1WrpgJuy5YtZdy4cao9eODAgaoDmJaJd+7cWb7++mvp16+ftG3bVrZs2SLLli2TdevW2bS/DMRERJTsTJ48Wdzc3NSFPND7Gr2dZ8yYYVyeMmVKWbt2rXTp0kUFaATy1q1by/Dhw41lMHQJQRdjkqdOnSo5cuSQ2bNnq23ZIoXBYDBIEvD0+WNn7wKRXbxqFOInSG88Q/gVXbY74fA4u9bvU6qfuCpmxEREpDve9ME6BmIiItKdPZepdHUMxEREpDu3FBykYw0/GSIiIidiRkxERLrj/YitYyAmIiLdsY3YOgZiIiLSHXtNW8dATEREumNGbB07axERETkRM2IiItIdq6atYyAmIiLdpeA4YqsYiImISHdsI7aOgZiIiHTHqmnr2FmLiIjIiZgRExGR7nhlLesYiImISHduvPuSVQzERESkO2bE1rGNmIiIyImYERMRke44jtg6BmIiItId24itYyAmIiLdsY3YOgZiIiLSHa+sZR07axERETkRM2IiItIdq6atYyAmIiLdsbOWdQzERESkOw5fso5txERElCidtez5zxYzZ86UEiVKiI+Pj5qCg4Nl/fr1xuVPnz6Vrl27SqZMmSRt2rTSqFEjuXHjhtk2Ll++LLVr1xZvb2/x8/OTvn37SkxMjFmZbdu2SenSpcXDw0MKFCgg8+bNk4RgICYiIpeSI0cOGTNmjERERMjBgwelSpUqUr9+fTlx4oRa3qtXL1mzZo0sX75ctm/fLlevXpWGDRsa13/+/LkKws+ePZPdu3fL/PnzVZAdPHiwscyFCxdUmcqVK8vhw4elZ8+e0r59e9m4caPN+5vCYDAYJAl4+vyxs3eByC5eNQrxE6Q3niH8ii7bXX5+kV3rf5yvhV3rZ8yYUcaPHy+NGzeWLFmyyOLFi9XfEBkZKQEBAbJnzx4pV66cyp7r1KmjAnTWrFlVmVmzZkn//v3l1q1b4u7urv5et26dHD9+3PgazZo1k7t378qGDRsc30b89ttvx7vH26FDh2zaASIicn32jiOOiopSkylUCWN6FWS3yHwfPXqkqqiRJUdHR0tISIixTJEiRSRXrlzGQIzH4sWLG4MwVK9eXbp06aKyasRElDHdhlYGmbGt4hWIGzRoYPOGiYiIHDV8afTo0TJs2DCzeUOGDJGhQ4daLH/s2DEVeNEejHbglStXSmBgoKpGRkbr6+trVh5B9/r16+pvPJoGYW25tuxVZe7fvy9PnjwRLy8vxwZivFkiIiJnDV8KCwuT0NBQs3mvyoYLFy6sgu69e/fk559/ltatW6v24KSIw5eIiCjJ84hHNbQpZL3oyQxBQUFy4MABmTp1qjRt2lR1wkJbrmlWjF7T/v7+6m887t+/32x7Wq9q0zKxe1rjOXpp25INJ6jXNOrbJ0yYIGXLllU7ggZw04mIiMhS1bQ9k71evHih2pgRlFOnTi2bN282Ljt9+rQaroSqbMAjqrZv3rxpLBMeHq6CLKq3tTKm29DKaNvQNRCjjn7SpEnqrAIpP6oK0O3bzc3Nal09ERElbylU5XTCJ1ursXfs2CEXL15UARXPMea3RYsWkj59emnXrp2KXVu3blWdt9q0aaMCKDpqQbVq1VTAbdmypRw5ckQNSRo4cKAae6xl5Z07d5bz589Lv379VK/rGTNmyLJly9TQKN2rphctWiTff/+9Gj+FwPvJJ59I/vz51eDpvXv3yueff27zThARkWtLzGtN37x5U1q1aiXXrl1TgRfxCcG0atWqavnkyZNV8ogLeSBLRm9nBFJNypQpZe3ataqXNAJ0mjRpVBvz8OHDjWXy5s2rhi8h8KLKG2OXZ8+erbal+zhi7NCpU6dUV+9s2bKpHcGVRXBmgC7dyJITguOI6U3HccTkCvQaR7z60s92rV8v98sxv67I5qppRH2cZQAy4U2bNqm/0RBuS0M6ERElH4l5iUuXD8QfffSRsYG6e/fuMmjQIClYsKCqBmjbtq0e+0hERG84txQp7Jpcmc1txLh+pwYdtrSrkSAY161b19H7R0RELsDVs1qnjiNGQ3ZCumsTEVHykZidtZJFIMaFsHfu3Kl6pmFslin2miYiItIxEONWUJ06dVJXLcG9HE3PcvA3AzEREcVm61jg5MTmQIzOWbgnIwZIYxwWERHR67Bq2oGB+PHjx+qeiwzCRESUWDd9cGU2p7S4NBju7UhERPSmXGvapTJi3BOyTp06smHDBnXjZFw82xSuQ01EREQ6BmJcsxP3eoTYnbWIiIhi4zhiBwbiiRMnyg8//CCffvqprasSEVEyxUTNgYEY15N+7733bF2NiIiSMQ5fcmBnrR49esj06dNtXY2IiJIxXmvagRnx/v37ZcuWLepejUWLFo3TWWvFihW2bpKIiCjZsjkQ+/r6SsOGDfXZGyIicknsrOWgQBwTEyOVK1eWatWqib+/vy2rUiJYtmSZLFvys1z956p6nr9APunUpaNUqFRBPR8+ZKTs27tPbt28Jd7eXlKyVEnp2buH5M2Xl98PJQpcCGhoy1D534cNxT+jn1z977rM27RcRi6a+tob0/f9bqRMWD7L+LxW2Soy+H+9pES+AHn67KlsP7pXPhraXi1rXe1jmdd3ssXt+H1cUm7d/c/h741ejZ21HBSIU6VKJZ07d5ZTp07ZsholEr+sWaVHr+6SK3cuMYjImlVrpEe3XrL0lyVSoGB+CSwaILXr1hT/bNnk/r17MvObWdK5/WfyW/haSZkyJb8n0l3/pp9Jl7qtpPW4nnLi0hkpU6ikzO0zUe49eiDTV/2gyvg3edtsnZplK8uc0Anyyx+/Gec1rFBLvu81Tr6cO0a2/LlLUqVMJcXyvBxSCUu3rZENB7aZbQeB2dPdg0HYSZgRO7BqumzZsvLnn39K7ty5bV2VdPZB5ffNnnfv2U2WLVkuR48eVYG4cZNGxmVvvZVdun3eVT7+qKnKoHPmysnvh3RXPrCM/Lp7k/y2f4t6funGFfmkcn0pW7iUscyNO7fM1qkfXE22HtktF65fVs9TuqWUqZ8Nk77fj5QfNiwxljt1+azxb2TImDSZ02eUKqXKS7tJfXV9f2QdM2IHBuLPPvtMevfuLVeuXJGgoCBJkyaN2fISJUrYuknSwfPnz2XTxnB58uSJlCwZ9zt5/PiJ/LpytbyV4y02M1Ci2X3yoHSs1UIKvpVXzv5zQVUrVyj2joTOGm6xvJ9vZqn97ofSelwv47zSBYtLjizZ5IXhhRyauUH8M2SRw+dOqsB84uJpi9tpVbWxPI56Ij/vWKfbeyNKtECMGz6A6e0OcaZjMBjUIwIAOc/ZM2el5Set5dmzZ6odePK0iZK/QH7j8qU/LZPJE6aoAJ0nbx75dvZMSe1u3vOdSC9jlnwjPt7pJPKH7fL8xXOV3Q6YO1YWb1lpsTzaeh88fiQrdq43zsuXLZd6RFszAvjFG39L78adZNuE5VKoTSW58+BunO20q9FMFm9ZZZYlU+Jy420QHReIL1y4IPaKiopSkylDqufqYiFknzx58siyFUvk4cOHEr7xdxn05WCZM3+2MRjXqlNTygW/K//++6/Mn/uj9A3tL/MXzeVnT4miyft1pUWVj6T56G5y4uIZKVWgqEzpMlSu/ndDfgz/OU75ttWbyqItKyUq+v9+L9xSvLz8wVeLp8uKnS/bjdtMCJUriw/Ix5Vqy3frFplto1xAaQnMXUhaju2h+/sj61g17cBA7Ii2YVyvetiwYWbzBgz6UgYOGWD3tpM7ZLforAWBRQPlxPETsmjBTzJ42EA1L126dGrKnSe3akaoEFxJtvy+RWrWrunkPafkYHyHgTJm6TeydNtq9fz4xUjJ7feWhDXrFicQVyhWVorkKiBNv+piNv/a7Zvq8eSlM8Z5z6KfyflrlyWX31txXrN9zeby51/H5dDZYzq9K4oPdtZyYCCGc+fOyZQpU4y9pwMDA9UVt/Ln/78q0FcJCwuT0NDQOBkxOd4Lg0Gio59ZXGZA32qDyLNn0fzoKVF4e3rJixcvzOahitrS/c3b1WwmB88ckaPnzUdpRJw9qqqYC+fML7tOHFDz0Gs6j38OuXTjH7OyaTy9pcn7dSTshzG6vB8ipwRi3HmpXr16UqpUKeM1p3ft2qWusrVmzRqpWrXqa7eBKujY1dBPnz+2dVcolqmTpkmFSu+p4UmPHz2S39aul4P7D8rM72fIlb+vyMb1GyX4vWDJkCGD3LhxQ36Y/bJKWhtnTKS3NXvDZUDzz+XyzX/U8KW3CxST0EYd5YeNS83KpfNOKx9XrCO9v4vbievB44cya+1CGdaqt/x966rqed23ycusefmOtWZlm35QTwXphb/zin/OxqppBwbiL774Qnr16iVjxoyJM79///7xCsSkj9u3b8vALwbJrVv/Stp0aaVQoYIqCAeXLyc3b96UQxF/ysIFi+X+vfuSKXMmCQoqLT8unieZMmXkV0KJovvXg2TEp31lxuejVI9oXNDj23ULZfjCKWblmn1QX/1w/7TlV6sX94h5HiML+k8VL3dP2Rf5p1Tp21TuPrwXp5MWOnrde3Rf1/dFr8eqaetSGNDd2Qaenp5y7NgxKViwoNn8M2fOqDbHp08T1iuRGTG96bxqFHL2LhDZzdqVzex18NYuu9Yvk+U9m/oh4b4HkZGR4uXlJeXLl5exY8dK4cL/d9EXxCoMxV2yZInqPFy9enWZMWOGZM2a1Vjm8uXL0qVLF9m6daukTZtWWrdurbaNi1tptm3bpppaT5w4ITlz5pSBAwfafJtgm+++lCVLFjl8+HCc+Zjn5+dn6+aIiCg5SJHCvskG27dvl65du8revXslPDxcoqOj1aWZHz16ZCyDml00py5fvlyVv3r1qtl9FDAUt3bt2moo6O7du2X+/Pkyb948GTx4sNkoIpTBpZ8RA3v27Cnt27dXTbi6ZsTDhw+XyZMnq6ponGVobcQ428BZwaBBgyQhmBHTm44ZMbkC3TLif3fbtX6ZzC/jTULcunVLJYoIuJUqVZJ79+6ppHLx4sXSuHFjVQbZc0BAgOzZs0fKlSsn69evlzp16qgArWXJs2bNUk2w2J67u7v6e926dXL8+HGza23cvXtXNmzYoF8bMQIthr9MnDhR9X6G7Nmzy9ChQ80u8kFEROSoNuIoC9efsNTx1xIEXsiY8WV/mIiICJUlh4SEGMsUKVJEcuXKZQzEeCxevLhZVTWqr1FVjWrot99+W5Ux3YZWBpmxrlXT6ECBlB6XuMSbw4S/MXyJveKIiMha7LBnGj16tKRPn95swrzXwXA5BEaM8ilWrJiad/36dZXR4ra+phB0sUwrYxqEteXasleVuX//vrp6oa7jiDXIjImIiPTOiMMsXH8iPtkw2opRdbxz505JqmzOiDH+tGXLlqo6Gj3HcPs804mIiMhSILbnPw8PD/Hx8TGbXheIu3XrJmvXrlW9nnPkyGGc7+/vrzphoS03dnzDMq0Mnsderi17VRnsG3pr65YRo1s2unSjrThbtmysjiYioiTFYDBI9+7dZeXKlWp4Ud68ec2W486BqVOnls2bN0ujRi9vD3v69GkV24KDg9VzPH711VfqGgzaiCD0wEaQxdUktTK//fZ/98nWymjb0K3XNKqj//jjD3VlLUdir2l607HXNLkCvXpNH7n98nKkCVUy4zs23a4XPaJ//fVXs7HDaFfWMlV0ukIQxZAkBFcEbsBQJW34EuIcan/HjRun2oNRG4zhSaNGjTIOX0K7M6q/27ZtK1u2bFGdltGTGp22dMuIMWDZxthNRETJXGJeWWvmzJnq8YMPPjCbP3fuXOPFNjAMF9c4R0ZsekEPDZpaUa2NgI0MN02aNOqCHhjCq0GmjaCLDsxTp05V1d+zZ8+2KQgnKCPetGmTGrr07bffqlvuOQozYnrTMSMmV6BXRnzsdoRd6xfPGCSuyuaMuGnTpvL48WN1pyVvb29Vzx77esdERESmOLzVgYEYtz8kIiIiJwVi1JETERHZgndfcvAFPdCbDN3CT516ecNudOWuX7++2R0piIiINKyats7myIlrbNarV0915da6heOGD7iANu5koV1CjIiISMOM2IFX1sIYqqJFi6rrSx86dEhNf//9t7oXcceOHW3dHBERUbJmc0aMey4ePHhQMmTIYJyHv3EFknfeif+AayIiSj6YETswIy5UqFCca2sCLgNWoEABWzdHRETJgL13X5LknhHjlk4a3HYKl/DC/Ydxz0bYu3evutoI2oqJiIhiY0Zs55W1cBkw0zMSbRVtnulz9KhOCF5Zi950vLIWuQK9rqx19t4Ju9YvmL6oJOuMGLeQio9jx47Zuz9ERETJis3Xmo7twYMH8tNPP6kLXUdERDAjpmSLGTG5Ar0y4r/un7Rr/QI+L2896Ips7qyl2bFjh7rKFu5JPGHCBKlSpYpqKyYiIoorhZ2T67Jp+BIu4oF7N86ZM0d14GrSpIm6fdSqVauMN0omIiKKzdV7PidKRly3bl11Ja2jR4+qGz9cvXpVpk+fbteLExFR8uk1bc9/rizeGfH69evVsCXcJLlgwYL67hUREVEyEe+MeOfOnapjVlBQkLz77rvy9ddfy7///qvv3hERkUtgRuyAQIyLd3z//fdy7do16dSpkyxZskSyZ88uL168kPDwcBWkiYiILOGVtXQavnT69GnVcWvBggVy9+5dqVq1qqxevTpB2+IFPehNx+FL5Ar0Gr506eFfdq2fO63rXkI5wcOXAJ23xo0bp+7EhLHERERElrBqWscLejgKM2J60zEjJlegV0Z8+eE5u9bPlTa/uCqbb4NIRERkK44jto6BmIiIdOfqY4HtwUBMRES6Y0asU2ctIiIisg8zYiIi0h2rpq1jRkxERC5396UdO3aoeyTgwlOoFsfNiUxhwNDgwYPVHQS9vLwkJCREzp49a1bm9u3b0qJFC/Hx8RFfX19p166dPHz40KwM7r9QsWJF8fT0lJw5c6ohvbZiICYiIpe7CeKjR4+kZMmS8s0331hcjoA5bdo0mTVrluzbt0/SpEkj1atXl6dPnxrLIAifOHFCXT1y7dq1Krh37NjRuBx3IaxWrZrkzp1bIiIiZPz48TJ06FD57rvvbPtsOI6YyDE4jphcgV7jiK8/+duu9f29ciZ4XWTEK1eulAYNGhizYWTKvXv3lj59+qh59+7dk6xZs6pb/TZr1kxOnTqlbu974MABKVOmjCqzYcMGqVWrlrqIFdafOXOmDBgwQN0i2N3dXZX54osvVPYdGRkZ7/1jRkxEREleVFSUykBNJ8xLiAsXLqjgiepoTfr06dUNjfbs2aOe4xHV0VoQBpR3c3NTGbRWplKlSsYgDMiqcfnnO3fuxHt/GIiJiCjJV06PHj1aBUvTCfMSAkEYkAGbwnNtGR79/PzMlqdKlUoyZsxoVsbSNkxfIz7Ya5qIiHRn7+U8wsLCJDQ01Gyeh4eHuAIGYiIiSvKh2MPDw2GB19/fXz3euHFD9ZrW4HmpUqWMZW7evGm2XkxMjOpJra2PR6xjSnuulYkPVk0TEVGyuh9x3rx5VaDcvHmzcR7anNH2GxwcrJ7jEbf3RW9ozZYtW+TFixeqLVkrg57U0dHRxjLoYY07E2bIkCHe+8NATERELufhw4dy+PBhNWkdtPD35cuXVWDv2bOnjBw5UlavXi3Hjh2TVq1aqZ7QWs/qgIAAqVGjhnTo0EH2798vu3btkm7duqke1SgHzZs3Vx21ML4Yw5yWLl0qU6dOjVOF/jocvkTkIBy+RK5Ar+FLN59etWt9P8+XwS++tm3bJpUrV44zv3Xr1mqIEoYwDRkyRI35ReZboUIFmTFjhhQqVMhYFtXQCL5r1qxRvaUbNWqkxh6nTZvW7IIeXbt2VcOcMmfOLN27d5f+/fvbtK8MxEQOwkBMrkCvQHzr6TW71s/i+X9tua6GnbWIiEh3vNa0dWwjJiIiciIGYiIiIidi1TQREenO0UOQXAkzYiIiIidiRkxERLpjZy3rmBETERE5ETNiIiJKBGwjtoaBmIiIdMcwbB0DMRER6Y69pq1jICYiokTAnNgadtYiIiJyImbERESkO+bD1jEQExFRImAotoaBmIiIdMfOWtaxjZiIiMiJGIiJiIiciFXTRESkO15r2joGYiIiSgTsrGUNAzEREemOYdg6BmIiItIde01bx85aRERETsSMmIiIEgErp61hICYiIt0xDFvHQExERImAodgaBmIiItIdO2tZx85aRERETsRATERE5ESsmiYiIt3xEpfWpTAYDIZXLCcXERUVJaNHj5awsDDx8PBw9u4Q2YzHMLkqBuJk4v79+5I+fXq5d++e+Pj4OHt3iGzGY5hcFduIiYiInIiBmIiIyIkYiImIiJyIgTiZQAetIUOGsKMWvbF4DJOrYmctIiIiJ2JGTERE5EQMxERERE7EQExEROREDMRkl23btqm7qty9e5efJLns8TB06FApVaqUs3eDXBQDcRLy6aefqh+xMWPGmM1ftWoVbyFGScqePXskZcqUUrt2bWfvCtEbj4E4ifH09JSxY8fKnTt3HLbNZ8+eOWxbRDBnzhzp3r277NixQ65evZokPpTo6Ghn7wJRgjAQJzEhISHi7++vbtBgzS+//CJFixZV4yrz5MkjEydONFuOeSNGjJBWrVqp60p37NhR5s2bJ76+vrJ27VopXLiweHt7S+PGjeXx48cyf/58tU6GDBnk888/l+fPnxu3tWDBAilTpoykS5dO7Vfz5s3l5s2bun4GlLQ9fPhQli5dKl26dFEZMY6t2Hbt2iUlSpRQJ5blypWT48ePG5dpx+LGjRslICBA0qZNKzVq1JBr164Zy7x48UKGDx8uOXLkUMc5qoU3bNhgXH7x4kVVS4T9eP/999XrLFq0SNUqNWjQQEaNGiVZs2ZVr4PtxMTESN++fSVjxoxqm3PnzjXb3/79+0uhQoXUv4t8+fLJoEGDGNgp8eDuS5Q0tG7d2lC/fn3DihUrDJ6enoa///5bzV+5ciXukKX+PnjwoMHNzc0wfPhww+nTpw1z5841eHl5qUdN7ty5DT4+PoYJEyYY/vrrLzVheerUqQ1Vq1Y1HDp0yLB9+3ZDpkyZDNWqVTM0adLEcOLECcOaNWsM7u7uhiVLlhi3NWfOHMNvv/1mOHfunGHPnj2G4OBgQ82aNY3Lt27dqvbtzp07ifpZkfPgmChTpoz6G8dM/vz5DS9evDA7HgICAgybNm0yHD161FCnTh1Dnjx5DM+ePVNltGMxJCTEcODAAUNERIQq37x5c+NrTJo0SR3DP/30kyEyMtLQr18/tc6ZM2fU8gsXLqjXwXZ/+eUXw/nz5w1Xr15V/4bSpUtn6Nq1q1oP+4py1atXN3z11Vdq/REjRqhtaf++APN27dqltrt69WpD1qxZDWPHjjUuHzJkiKFkyZKJ9hlT8sJAnAQDMZQrV87Qtm3bOIEYP1YIpqb69u1rCAwMNAvEDRo0MCuDHz9sA0FZ06lTJ4O3t7fhwYMHxnn4wcJ8a/DDie1o6zAQJz/ly5c3TJkyRf0dHR1tyJw5szoOTI8H05O5//77T50sLl261Oqx+M0336jgp8mePbsKnKbeeecdw2effWYWiLX9MP03hOP/+fPnxnmFCxc2VKxY0fg8JibGkCZNGhXkrRk/frwhKCjI+JyBmPTEqukkCu3EqDI+deqU2Xw8f++998zm4fnZs2fNqpRRnRwbqt3y589vfI6qO1RJo2rQdJ5p1XNERITUrVtXcuXKpaqnUQ0Ily9fdtA7pTfJ6dOnZf/+/fLJJ5+o56lSpZKmTZuqNmNTwcHBxr9RHYzmENNjOfaxmC1bNuNxh9sdot3Z0nEe+9+DpeMczTZubm5mx3Tx4sWNz9HJLFOmTGbHOaq4sX00v+Dfw8CBA3mMU6JhIE6iKlWqJNWrV5ewsLAErZ8mTZo481KnTm32HG1sluahfQ4ePXqk9gHtzGh/O3DggKxcuVItYwew5AkBF+2t2bNnV0EY08yZM1W/BdzrOr4sHXeooXPGcY4e4C1atJBatWqpPhR//vmnDBgwgMc4JZpUifdSZCsMY0InFWQTGnRuQUcYU3iOjiY403ekyMhI+e+//9R+5MyZU807ePCgQ1+D3hwIwD/++KPqHFitWjWzZegg9dNPP0mRIkXU871796paFMAIgDNnzqhjNz5w4odAj+Naq4EBPC9btqw42u7duyV37twq+GouXbrk8NchsoaBOAlDdRrO1KdNm2ac17t3b3nnnXdUr2hUCeJs/uuvv5YZM2Y4/PXxQ+ru7i7Tp0+Xzp07q56veF1KnpAtIqi2a9dO0qdPb7asUaNGKlseP368eo6eyqj+RbUwAlzmzJlVsI4v9HDG3cJQfY2TUfRyPnz4sKqZcbSCBQuqauglS5aof1vr1q0z1vwQJQZWTSdx+EHTqtCgdOnSsmzZMvWjUaxYMRk8eLAqg2EbjpYlSxY11GT58uUSGBioMuMJEyY4/HXozYBAi+F1sYOwFohRW3L06FH1HMdKjx49JCgoSK5fvy5r1qxRJ3XxhWF0oaGh6sQTJ6QYurR69WoVNB2tXr160qtXL+nWrZsK+siQMXyJKLHwNohEREROxIyYiIjIiRiIiYiInIiBmIiIyIkYiImIiJyIgZiIiMiJGIiJiIiciIGYiIjIiRiIiYiInIiBmIiIyIkYiImIiJyIgZiIiMiJGIiJiIjEef4fOv/ZxNpcOp0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D, MaxPooling1D, LSTM, Dense, Dropout,\n",
    "    LayerNormalization, Add, Bidirectional,\n",
    "    GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- Load Data --------------------\n",
    "X = np.load(r\"preprocessed\\ALL_X.npy\")\n",
    "y = np.load(r\"preprocessed\\ALL_y.npy\")\n",
    "\n",
    "# Convert to binary: ICTAL = 0, ALL OTHERS = 1\n",
    "y_encoded = np.where(y == 'ICTAL', 0, 1)\n",
    "\n",
    "# Reshape for CNN input\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Labels distribution:\", np.unique(y_encoded, return_counts=True))\n",
    "\n",
    "# -------------------- Prepare Cross Validation --------------------\n",
    "random_state = np.random.randint(0, 10000)\n",
    "print(f\"ğŸ² Random state used for this run: {random_state}\")\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "fold_indices = [(train_idx, test_idx) for train_idx, test_idx in kfold.split(X, y_encoded)]\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "np.save(\"results/fold_indices.npy\", np.array(fold_indices, dtype=object), allow_pickle=True)\n",
    "\n",
    "def hybrid_focal_loss(alpha=0.25, gamma=2.0, bce_weight=0.5):\n",
    "    \"\"\"\n",
    "    Hybrid = BCE * bce_weight + FocalLoss * (1 - bce_weight)\n",
    "    \"\"\"\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        # --- Binary Cross Entropy ---\n",
    "        bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "        # --- Focal Loss ---\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        focal = -alpha * (1 - y_pred) ** gamma * y_true * K.log(y_pred) \\\n",
    "                - (1 - alpha) * y_pred ** gamma * (1 - y_true) * K.log(1 - y_pred)\n",
    "\n",
    "        focal = K.mean(focal, axis=-1)\n",
    "\n",
    "        # --- Combine Both ---\n",
    "        return bce_weight * bce + (1 - bce_weight) * focal\n",
    "\n",
    "    return loss\n",
    "\n",
    "# -------------------- CNN + LSTM Model --------------------\n",
    "def build_cnn_lstm(input_length):\n",
    "    model = Sequential([\n",
    "        # --- CNN Layers ---\n",
    "        Conv1D(32, kernel_size=7, activation='relu', input_shape=(input_length, 1)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Conv1D(64, kernel_size=5, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Conv1D(128, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.4),\n",
    "\n",
    "         # --- NEW Conv1D Layer ---\n",
    "        # Conv1D(256, kernel_size=3, activation='relu'),\n",
    "        # BatchNormalization(),\n",
    "        # MaxPooling1D(2),\n",
    "        # Dropout(0.4),\n",
    "\n",
    "        \n",
    "        # --- LSTM ---\n",
    "        LSTM(64, return_sequences=False),\n",
    "\n",
    "        # --- Dense Layers ---\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=hybrid_focal_loss(alpha=0.25, gamma=2.0, bce_weight=0.5),\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# -------------------- Residual Block --------------------\n",
    "# def residual_block(x, filters, kernel_size):\n",
    "#     shortcut = x\n",
    "\n",
    "#     out = Conv1D(filters, kernel_size, padding=\"same\", activation='relu')(x)\n",
    "#     out = LayerNormalization()(out)\n",
    "\n",
    "#     out = Conv1D(filters, kernel_size, padding=\"same\")(out)\n",
    "#     out = LayerNormalization()(out)\n",
    "\n",
    "#     out = Add()([shortcut, out])   # residual connection\n",
    "#     out = Dropout(0.2)(out)\n",
    "\n",
    "#     return out\n",
    "\n",
    "\n",
    "# -------------------- Attention Layer --------------------\n",
    "# def attention_block(inputs):\n",
    "#     \"\"\"\n",
    "#     inputs: (batch_size, timesteps, features)\n",
    "#     returns: (batch_size, features)\n",
    "#     \"\"\"\n",
    "#     score = Dense(128, activation='tanh')(inputs)\n",
    "#     score = Dense(1)(score)\n",
    "#     attention_weights = tf.nn.softmax(score, axis=1)\n",
    "#     context_vector = attention_weights * inputs\n",
    "#     context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "#     return context_vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- Data Augmentation for 1D EEG (Optimized Version) --------------------\n",
    "def augment_signal(signal):\n",
    "    # 1) Very Light Noise\n",
    "    noise = np.random.normal(0, 0.005, signal.shape)\n",
    "    signal_noisy = signal + noise\n",
    "\n",
    "    # 2) Small Time Shift\n",
    "    shift = np.random.randint(-5, 5)\n",
    "    signal_shifted = np.roll(signal_noisy, shift)\n",
    "\n",
    "    # 3) Gentle Scaling\n",
    "    scale = np.random.uniform(0.97, 1.03)\n",
    "    signal_scaled = signal_shifted * scale\n",
    "\n",
    "    return signal_scaled\n",
    "\n",
    "\n",
    "\n",
    "def augment_batch(X, y):\n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        X_aug.append(X[i])\n",
    "        y_aug.append(y[i])\n",
    "\n",
    "        # Generate **1 weakly augmented version**\n",
    "        X_aug.append(augment_signal(X[i]))\n",
    "        y_aug.append(y[i])\n",
    "\n",
    "    return np.array(X_aug), np.array(y_aug)\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- Training --------------------\n",
    "acc_per_fold = []\n",
    "conf_matrices = []\n",
    "\n",
    "for fold_no, (train_val_idx, test_idx) in enumerate(fold_indices, start=1):\n",
    "    print(f\"\\nğŸ”¹ Fold {fold_no}\")\n",
    "\n",
    "    # Split into train/val/test\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y_encoded[train_val_idx], y_encoded[test_idx]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.1765, stratify=y_train_val, random_state=42\n",
    "    )\n",
    "\n",
    "    # ------------ APPLY DATA AUGMENTATION ------------\n",
    "    X_train, y_train = augment_batch(X_train, y_train)\n",
    "\n",
    "    print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "\n",
    "    # Build new model for each fold\n",
    "    model = build_cnn_lstm(X_train.shape[1])\n",
    "    model.summary()\n",
    "\n",
    "    # Handle class imbalance\n",
    "    cw = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = {0: cw[0], 1: cw[1]}\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=40,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val),\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    acc_per_fold.append(test_acc)\n",
    "    print(f\"Fold {fold_no} - Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # Save weights\n",
    "    weight_path = f\"results/cnn_lstm_fold{fold_no}.weights.h5\"\n",
    "    model.save_weights(weight_path)\n",
    "    print(f\"âœ… Weights saved to {weight_path}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\").flatten()\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrices.append(cm)\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt='d', cmap='Blues',\n",
    "        xticklabels=['Normal', 'Abnormal'], \n",
    "        yticklabels=['Normal', 'Abnormal']\n",
    "    )\n",
    "    plt.title(f\"Fold {fold_no} Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"results/cnn_lstm_conf_fold{fold_no}.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\nğŸ“Š Mean Accuracy:\", np.mean(acc_per_fold))\n",
    "\n",
    "# -------------------- Overall Confusion Matrix --------------------\n",
    "total_cm = np.sum(conf_matrices, axis=0)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(\n",
    "    total_cm, annot=True, fmt='d', cmap='Greens',\n",
    "    xticklabels=['Normal', 'Abnormal'], \n",
    "    yticklabels=['Normal', 'Abnormal']\n",
    ")\n",
    "plt.title(\"Overall Confusion Matrix (All Folds)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/cnn_lstm_conf_overall.png\")\n",
    "\n",
    "tn, fp, fn, tp = total_cm.ravel()\n",
    "\n",
    "overall_accuracy = (tp + tn) / np.sum(total_cm)\n",
    "overall_precision = tp / (tp + fp)\n",
    "overall_recall = tp / (tp + fn)\n",
    "overall_f1 = 2 * overall_precision * overall_recall / (overall_precision + overall_recall)\n",
    "\n",
    "print(\"\\nğŸ“Š Overall Metrics:\")\n",
    "print(f\"  Accuracy : {overall_accuracy:.4f}\")\n",
    "print(f\"  Precision: {overall_precision:.4f}\")\n",
    "print(f\"  Recall   : {overall_recall:.4f}\")\n",
    "print(f\"  F1-score : {overall_f1:.4f}\")\n",
    "\n",
    "print(\"âœ… CNN+LSTM Training Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5199e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
