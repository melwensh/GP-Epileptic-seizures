{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b6d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (11000, 347, 1)\n",
      "Labels distribution: (array([0, 1, 2]), array([4400, 2200, 4400]))\n",
      "ğŸ² Random state used for this run: 8003\n",
      "\n",
      "ğŸ”¹ Fold 1\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚           \u001b[38;5;34m195\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,923</span> (351.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,923\u001b[0m (351.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,475</span> (349.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,475\u001b[0m (349.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: np.float64(0.8334483551874856), 1: np.float64(1.6668967103749712), 2: np.float64(0.8331608600666897)}\n",
      "Epoch 1/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.6048 - loss: 0.8919 - val_accuracy: 0.5997 - val_loss: 0.8783\n",
      "Epoch 2/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.8152 - loss: 0.5243 - val_accuracy: 0.8366 - val_loss: 0.4393\n",
      "Epoch 3/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.8905 - loss: 0.3278 - val_accuracy: 0.8874 - val_loss: 0.3242\n",
      "Epoch 4/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9026 - loss: 0.2881 - val_accuracy: 0.9009 - val_loss: 0.2723\n",
      "Epoch 5/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9140 - loss: 0.2481 - val_accuracy: 0.9125 - val_loss: 0.2474\n",
      "Epoch 6/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9173 - loss: 0.2378 - val_accuracy: 0.9260 - val_loss: 0.2214\n",
      "Epoch 7/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9224 - loss: 0.2225 - val_accuracy: 0.9286 - val_loss: 0.2032\n",
      "Epoch 8/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9253 - loss: 0.2085 - val_accuracy: 0.9356 - val_loss: 0.1751\n",
      "Epoch 9/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9263 - loss: 0.2069 - val_accuracy: 0.9305 - val_loss: 0.1850\n",
      "Epoch 10/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9276 - loss: 0.1922 - val_accuracy: 0.9286 - val_loss: 0.1989\n",
      "Epoch 11/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9324 - loss: 0.1838 - val_accuracy: 0.9324 - val_loss: 0.1767\n",
      "Epoch 12/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9327 - loss: 0.1781 - val_accuracy: 0.9369 - val_loss: 0.1724\n",
      "Epoch 13/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9346 - loss: 0.1770 - val_accuracy: 0.9453 - val_loss: 0.1483\n",
      "Epoch 14/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9342 - loss: 0.1764 - val_accuracy: 0.9453 - val_loss: 0.1413\n",
      "Epoch 15/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9361 - loss: 0.1660 - val_accuracy: 0.9414 - val_loss: 0.1562\n",
      "Epoch 16/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9396 - loss: 0.1584 - val_accuracy: 0.9414 - val_loss: 0.1601\n",
      "Epoch 17/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9392 - loss: 0.1550 - val_accuracy: 0.9492 - val_loss: 0.1399\n",
      "Epoch 18/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9426 - loss: 0.1504 - val_accuracy: 0.9517 - val_loss: 0.1374\n",
      "Epoch 19/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9436 - loss: 0.1451 - val_accuracy: 0.9492 - val_loss: 0.1314\n",
      "Epoch 20/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9430 - loss: 0.1441 - val_accuracy: 0.9492 - val_loss: 0.1264\n",
      "Epoch 21/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9442 - loss: 0.1402 - val_accuracy: 0.9550 - val_loss: 0.1183\n",
      "Epoch 22/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9465 - loss: 0.1325 - val_accuracy: 0.9530 - val_loss: 0.1238\n",
      "Epoch 23/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9457 - loss: 0.1368 - val_accuracy: 0.9524 - val_loss: 0.1344\n",
      "Epoch 24/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9496 - loss: 0.1276 - val_accuracy: 0.9588 - val_loss: 0.1096\n",
      "Epoch 25/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9483 - loss: 0.1285 - val_accuracy: 0.9575 - val_loss: 0.1172\n",
      "Epoch 26/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9489 - loss: 0.1264 - val_accuracy: 0.9569 - val_loss: 0.1050\n",
      "Epoch 27/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9518 - loss: 0.1145 - val_accuracy: 0.9569 - val_loss: 0.1185\n",
      "Epoch 28/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9538 - loss: 0.1174 - val_accuracy: 0.9582 - val_loss: 0.1112\n",
      "Epoch 29/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9509 - loss: 0.1181 - val_accuracy: 0.9582 - val_loss: 0.1098\n",
      "Epoch 30/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9521 - loss: 0.1125 - val_accuracy: 0.9588 - val_loss: 0.1072\n",
      "Epoch 31/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9537 - loss: 0.1111 - val_accuracy: 0.9595 - val_loss: 0.1075\n",
      "Epoch 32/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9538 - loss: 0.1117 - val_accuracy: 0.9607 - val_loss: 0.1096\n",
      "Epoch 33/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9556 - loss: 0.1039 - val_accuracy: 0.9633 - val_loss: 0.0925\n",
      "Epoch 34/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9523 - loss: 0.1126 - val_accuracy: 0.9595 - val_loss: 0.0944\n",
      "Epoch 35/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9550 - loss: 0.1057 - val_accuracy: 0.9653 - val_loss: 0.0899\n",
      "Epoch 36/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9572 - loss: 0.1013 - val_accuracy: 0.9601 - val_loss: 0.0988\n",
      "Epoch 37/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9593 - loss: 0.0987 - val_accuracy: 0.9614 - val_loss: 0.0942\n",
      "Epoch 38/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9559 - loss: 0.1036 - val_accuracy: 0.9633 - val_loss: 0.0981\n",
      "Epoch 39/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9583 - loss: 0.1015 - val_accuracy: 0.9627 - val_loss: 0.0951\n",
      "Epoch 40/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9575 - loss: 0.0984 - val_accuracy: 0.9595 - val_loss: 0.0969\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9641 - loss: 0.1090\n",
      "Fold 1 - Test Accuracy: 0.9641\n",
      "âœ… Weights saved to results/cnn_lstm_fold1.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "ğŸ”¹ Fold 2\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_4           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_5           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_4           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_5           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚           \u001b[38;5;34m195\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,923</span> (351.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,923\u001b[0m (351.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,475</span> (349.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,475\u001b[0m (349.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: np.float64(0.8334483551874856), 1: np.float64(1.6668967103749712), 2: np.float64(0.8331608600666897)}\n",
      "Epoch 1/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.6256 - loss: 0.8771 - val_accuracy: 0.4376 - val_loss: 1.1595\n",
      "Epoch 2/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.8137 - loss: 0.5556 - val_accuracy: 0.8623 - val_loss: 0.3845\n",
      "Epoch 3/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.8867 - loss: 0.3426 - val_accuracy: 0.9151 - val_loss: 0.2516\n",
      "Epoch 4/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9073 - loss: 0.2752 - val_accuracy: 0.9292 - val_loss: 0.2128\n",
      "Epoch 5/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9154 - loss: 0.2435 - val_accuracy: 0.9350 - val_loss: 0.1946\n",
      "Epoch 6/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9189 - loss: 0.2301 - val_accuracy: 0.9395 - val_loss: 0.1828\n",
      "Epoch 7/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9258 - loss: 0.2127 - val_accuracy: 0.9408 - val_loss: 0.1731\n",
      "Epoch 8/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9269 - loss: 0.2034 - val_accuracy: 0.9440 - val_loss: 0.1671\n",
      "Epoch 9/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9320 - loss: 0.1918 - val_accuracy: 0.9453 - val_loss: 0.1610\n",
      "Epoch 10/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9322 - loss: 0.1834 - val_accuracy: 0.9479 - val_loss: 0.1578\n",
      "Epoch 11/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9367 - loss: 0.1779 - val_accuracy: 0.9479 - val_loss: 0.1666\n",
      "Epoch 12/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9363 - loss: 0.1750 - val_accuracy: 0.9505 - val_loss: 0.1508\n",
      "Epoch 13/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9377 - loss: 0.1644 - val_accuracy: 0.9524 - val_loss: 0.1431\n",
      "Epoch 14/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9390 - loss: 0.1625 - val_accuracy: 0.9537 - val_loss: 0.1366\n",
      "Epoch 15/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9399 - loss: 0.1554 - val_accuracy: 0.9517 - val_loss: 0.1391\n",
      "Epoch 16/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9422 - loss: 0.1500 - val_accuracy: 0.9524 - val_loss: 0.1389\n",
      "Epoch 17/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9431 - loss: 0.1444 - val_accuracy: 0.9595 - val_loss: 0.1325\n",
      "Epoch 18/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9460 - loss: 0.1377 - val_accuracy: 0.9550 - val_loss: 0.1453\n",
      "Epoch 19/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9459 - loss: 0.1399 - val_accuracy: 0.9569 - val_loss: 0.1397\n",
      "Epoch 20/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9487 - loss: 0.1315 - val_accuracy: 0.9595 - val_loss: 0.1240\n",
      "Epoch 21/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9491 - loss: 0.1320 - val_accuracy: 0.9569 - val_loss: 0.1317\n",
      "Epoch 22/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9462 - loss: 0.1300 - val_accuracy: 0.9607 - val_loss: 0.1239\n",
      "Epoch 23/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9508 - loss: 0.1213 - val_accuracy: 0.9575 - val_loss: 0.1212\n",
      "Epoch 24/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9510 - loss: 0.1224 - val_accuracy: 0.9588 - val_loss: 0.1265\n",
      "Epoch 25/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9538 - loss: 0.1162 - val_accuracy: 0.9620 - val_loss: 0.1149\n",
      "Epoch 26/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9516 - loss: 0.1146 - val_accuracy: 0.9640 - val_loss: 0.1115\n",
      "Epoch 27/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9548 - loss: 0.1144 - val_accuracy: 0.9569 - val_loss: 0.1158\n",
      "Epoch 28/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9558 - loss: 0.1121 - val_accuracy: 0.9556 - val_loss: 0.1333\n",
      "Epoch 29/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9551 - loss: 0.1123 - val_accuracy: 0.9627 - val_loss: 0.1127\n",
      "Epoch 30/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9548 - loss: 0.1082 - val_accuracy: 0.9588 - val_loss: 0.1132\n",
      "Epoch 31/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9577 - loss: 0.1056 - val_accuracy: 0.9588 - val_loss: 0.1174\n",
      "Epoch 32/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9559 - loss: 0.1068 - val_accuracy: 0.9562 - val_loss: 0.1345\n",
      "Epoch 33/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9565 - loss: 0.1064 - val_accuracy: 0.9595 - val_loss: 0.1230\n",
      "Epoch 34/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9586 - loss: 0.1009 - val_accuracy: 0.9588 - val_loss: 0.1191\n",
      "Epoch 35/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9590 - loss: 0.0989 - val_accuracy: 0.9633 - val_loss: 0.1152\n",
      "Epoch 36/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9601 - loss: 0.0990 - val_accuracy: 0.9653 - val_loss: 0.1086\n",
      "Epoch 37/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9626 - loss: 0.0920 - val_accuracy: 0.9640 - val_loss: 0.1108\n",
      "Epoch 38/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9589 - loss: 0.0977 - val_accuracy: 0.9633 - val_loss: 0.1089\n",
      "Epoch 39/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9629 - loss: 0.0890 - val_accuracy: 0.9595 - val_loss: 0.1139\n",
      "Epoch 40/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9606 - loss: 0.0936 - val_accuracy: 0.9659 - val_loss: 0.1056\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9486 - loss: 0.1333\n",
      "Fold 2 - Test Accuracy: 0.9486\n",
      "âœ… Weights saved to results/cnn_lstm_fold2.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "ğŸ”¹ Fold 3\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_6           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_7           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_8           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_6           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_7           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_8           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚           \u001b[38;5;34m195\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,923</span> (351.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,923\u001b[0m (351.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,475</span> (349.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,475\u001b[0m (349.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: np.float64(0.8334483551874856), 1: np.float64(1.6668967103749712), 2: np.float64(0.8331608600666897)}\n",
      "Epoch 1/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.5901 - loss: 0.8955 - val_accuracy: 0.4575 - val_loss: 1.0683\n",
      "Epoch 2/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.8132 - loss: 0.5241 - val_accuracy: 0.8443 - val_loss: 0.4231\n",
      "Epoch 3/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.8955 - loss: 0.3100 - val_accuracy: 0.8887 - val_loss: 0.3240\n",
      "Epoch 4/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9062 - loss: 0.2727 - val_accuracy: 0.8932 - val_loss: 0.3039\n",
      "Epoch 5/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9160 - loss: 0.2357 - val_accuracy: 0.9035 - val_loss: 0.2858\n",
      "Epoch 6/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9202 - loss: 0.2187 - val_accuracy: 0.9054 - val_loss: 0.2626\n",
      "Epoch 7/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9249 - loss: 0.2131 - val_accuracy: 0.9215 - val_loss: 0.2322\n",
      "Epoch 8/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9264 - loss: 0.2079 - val_accuracy: 0.9176 - val_loss: 0.2272\n",
      "Epoch 9/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9278 - loss: 0.1963 - val_accuracy: 0.9176 - val_loss: 0.2249\n",
      "Epoch 10/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9294 - loss: 0.1904 - val_accuracy: 0.9292 - val_loss: 0.2000\n",
      "Epoch 11/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9310 - loss: 0.1795 - val_accuracy: 0.9241 - val_loss: 0.2237\n",
      "Epoch 12/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9373 - loss: 0.1696 - val_accuracy: 0.9311 - val_loss: 0.1969\n",
      "Epoch 13/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9354 - loss: 0.1759 - val_accuracy: 0.9292 - val_loss: 0.2102\n",
      "Epoch 14/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9351 - loss: 0.1648 - val_accuracy: 0.9363 - val_loss: 0.1741\n",
      "Epoch 15/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9366 - loss: 0.1622 - val_accuracy: 0.9376 - val_loss: 0.1794\n",
      "Epoch 16/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9370 - loss: 0.1578 - val_accuracy: 0.9376 - val_loss: 0.1836\n",
      "Epoch 17/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9425 - loss: 0.1486 - val_accuracy: 0.9382 - val_loss: 0.1790\n",
      "Epoch 18/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9413 - loss: 0.1501 - val_accuracy: 0.9382 - val_loss: 0.1830\n",
      "Epoch 19/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9449 - loss: 0.1437 - val_accuracy: 0.9459 - val_loss: 0.1683\n",
      "Epoch 20/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9459 - loss: 0.1344 - val_accuracy: 0.9427 - val_loss: 0.1598\n",
      "Epoch 21/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9436 - loss: 0.1456 - val_accuracy: 0.9402 - val_loss: 0.1792\n",
      "Epoch 22/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9476 - loss: 0.1328 - val_accuracy: 0.9440 - val_loss: 0.1680\n",
      "Epoch 23/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9464 - loss: 0.1335 - val_accuracy: 0.9447 - val_loss: 0.1688\n",
      "Epoch 24/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9489 - loss: 0.1280 - val_accuracy: 0.9472 - val_loss: 0.1528\n",
      "Epoch 25/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9505 - loss: 0.1249 - val_accuracy: 0.9472 - val_loss: 0.1546\n",
      "Epoch 26/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9503 - loss: 0.1224 - val_accuracy: 0.9427 - val_loss: 0.1632\n",
      "Epoch 27/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9490 - loss: 0.1218 - val_accuracy: 0.9511 - val_loss: 0.1492\n",
      "Epoch 28/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9516 - loss: 0.1174 - val_accuracy: 0.9498 - val_loss: 0.1599\n",
      "Epoch 29/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9533 - loss: 0.1138 - val_accuracy: 0.9498 - val_loss: 0.1472\n",
      "Epoch 30/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9537 - loss: 0.1102 - val_accuracy: 0.9537 - val_loss: 0.1410\n",
      "Epoch 31/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9535 - loss: 0.1110 - val_accuracy: 0.9479 - val_loss: 0.1459\n",
      "Epoch 32/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9548 - loss: 0.1081 - val_accuracy: 0.9588 - val_loss: 0.1311\n",
      "Epoch 33/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9523 - loss: 0.1160 - val_accuracy: 0.9562 - val_loss: 0.1399\n",
      "Epoch 34/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9591 - loss: 0.0995 - val_accuracy: 0.9537 - val_loss: 0.1389\n",
      "Epoch 35/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9563 - loss: 0.1069 - val_accuracy: 0.9575 - val_loss: 0.1376\n",
      "Epoch 36/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9576 - loss: 0.0992 - val_accuracy: 0.9582 - val_loss: 0.1308\n",
      "Epoch 37/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9594 - loss: 0.0994 - val_accuracy: 0.9569 - val_loss: 0.1421\n",
      "Epoch 38/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9574 - loss: 0.0974 - val_accuracy: 0.9505 - val_loss: 0.1609\n",
      "Epoch 39/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9583 - loss: 0.1012 - val_accuracy: 0.9556 - val_loss: 0.1430\n",
      "Epoch 40/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9603 - loss: 0.0926 - val_accuracy: 0.9588 - val_loss: 0.1335\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9682 - loss: 0.0936\n",
      "Fold 3 - Test Accuracy: 0.9682\n",
      "âœ… Weights saved to results/cnn_lstm_fold3.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\n",
      "ğŸ”¹ Fold 4\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_9           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_10          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_11          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_9           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_10          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_10 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_11          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚           \u001b[38;5;34m195\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,923</span> (351.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,923\u001b[0m (351.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,475</span> (349.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,475\u001b[0m (349.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: np.float64(0.8334483551874856), 1: np.float64(1.6668967103749712), 2: np.float64(0.8331608600666897)}\n",
      "Epoch 1/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - accuracy: 0.6177 - loss: 0.8842 - val_accuracy: 0.5373 - val_loss: 0.9562\n",
      "Epoch 2/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.8144 - loss: 0.5323 - val_accuracy: 0.8713 - val_loss: 0.3800\n",
      "Epoch 3/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.8871 - loss: 0.3428 - val_accuracy: 0.8990 - val_loss: 0.2988\n",
      "Epoch 4/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.8999 - loss: 0.2894 - val_accuracy: 0.9086 - val_loss: 0.2673\n",
      "Epoch 5/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9124 - loss: 0.2519 - val_accuracy: 0.9202 - val_loss: 0.2279\n",
      "Epoch 6/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9182 - loss: 0.2330 - val_accuracy: 0.9299 - val_loss: 0.2067\n",
      "Epoch 7/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.9190 - loss: 0.2258 - val_accuracy: 0.9260 - val_loss: 0.2053\n",
      "Epoch 8/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.9222 - loss: 0.2132 - val_accuracy: 0.9337 - val_loss: 0.1847\n",
      "Epoch 9/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9233 - loss: 0.2028 - val_accuracy: 0.9344 - val_loss: 0.1800\n",
      "Epoch 10/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9283 - loss: 0.1968 - val_accuracy: 0.9363 - val_loss: 0.1799\n",
      "Epoch 11/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.9303 - loss: 0.1885 - val_accuracy: 0.9344 - val_loss: 0.1779\n",
      "Epoch 12/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.9313 - loss: 0.1821 - val_accuracy: 0.9421 - val_loss: 0.1594\n",
      "Epoch 13/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9342 - loss: 0.1739 - val_accuracy: 0.9459 - val_loss: 0.1545\n",
      "Epoch 14/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.9327 - loss: 0.1698 - val_accuracy: 0.9440 - val_loss: 0.1563\n",
      "Epoch 15/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9327 - loss: 0.1704 - val_accuracy: 0.9466 - val_loss: 0.1405\n",
      "Epoch 16/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9360 - loss: 0.1660 - val_accuracy: 0.9479 - val_loss: 0.1372\n",
      "Epoch 17/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.9377 - loss: 0.1615 - val_accuracy: 0.9498 - val_loss: 0.1378\n",
      "Epoch 18/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9401 - loss: 0.1515 - val_accuracy: 0.9511 - val_loss: 0.1329\n",
      "Epoch 19/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9418 - loss: 0.1518 - val_accuracy: 0.9466 - val_loss: 0.1403\n",
      "Epoch 20/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.9411 - loss: 0.1463 - val_accuracy: 0.9562 - val_loss: 0.1220\n",
      "Epoch 21/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9434 - loss: 0.1455 - val_accuracy: 0.9530 - val_loss: 0.1285\n",
      "Epoch 22/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.9436 - loss: 0.1410 - val_accuracy: 0.9524 - val_loss: 0.1354\n",
      "Epoch 23/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.9455 - loss: 0.1326 - val_accuracy: 0.9524 - val_loss: 0.1340\n",
      "Epoch 24/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9484 - loss: 0.1290 - val_accuracy: 0.9569 - val_loss: 0.1240\n",
      "Epoch 25/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9460 - loss: 0.1332 - val_accuracy: 0.9524 - val_loss: 0.1340\n",
      "Epoch 26/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.9477 - loss: 0.1303 - val_accuracy: 0.9569 - val_loss: 0.1210\n",
      "Epoch 27/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9489 - loss: 0.1280 - val_accuracy: 0.9556 - val_loss: 0.1143\n",
      "Epoch 28/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9487 - loss: 0.1221 - val_accuracy: 0.9556 - val_loss: 0.1202\n",
      "Epoch 29/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9511 - loss: 0.1201 - val_accuracy: 0.9537 - val_loss: 0.1237\n",
      "Epoch 30/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9540 - loss: 0.1158 - val_accuracy: 0.9582 - val_loss: 0.1132\n",
      "Epoch 31/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9513 - loss: 0.1160 - val_accuracy: 0.9582 - val_loss: 0.1197\n",
      "Epoch 32/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9550 - loss: 0.1152 - val_accuracy: 0.9595 - val_loss: 0.1116\n",
      "Epoch 33/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.9531 - loss: 0.1150 - val_accuracy: 0.9640 - val_loss: 0.1085\n",
      "Epoch 34/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9552 - loss: 0.1082 - val_accuracy: 0.9569 - val_loss: 0.1148\n",
      "Epoch 35/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.9530 - loss: 0.1125 - val_accuracy: 0.9575 - val_loss: 0.1130\n",
      "Epoch 36/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9565 - loss: 0.1035 - val_accuracy: 0.9582 - val_loss: 0.1148\n",
      "Epoch 37/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9596 - loss: 0.1012 - val_accuracy: 0.9633 - val_loss: 0.1122\n",
      "Epoch 38/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9553 - loss: 0.1042 - val_accuracy: 0.9633 - val_loss: 0.1142\n",
      "Epoch 39/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9556 - loss: 0.1058 - val_accuracy: 0.9588 - val_loss: 0.1107\n",
      "Epoch 40/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9600 - loss: 0.1006 - val_accuracy: 0.9614 - val_loss: 0.1068\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9600 - loss: 0.1223\n",
      "Fold 4 - Test Accuracy: 0.9600\n",
      "âœ… Weights saved to results/cnn_lstm_fold4.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "\n",
      "ğŸ”¹ Fold 5\n",
      "Train: 14492, Val: 1554, Test: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_12          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_13          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_14          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_12          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_12 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_13          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_13 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_14          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_14 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m49,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚           \u001b[38;5;34m195\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,923</span> (351.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,923\u001b[0m (351.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,475</span> (349.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,475\u001b[0m (349.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: np.float64(0.8334483551874856), 1: np.float64(1.6668967103749712), 2: np.float64(0.8331608600666897)}\n",
      "Epoch 1/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - accuracy: 0.6337 - loss: 0.8513 - val_accuracy: 0.5837 - val_loss: 0.8690\n",
      "Epoch 2/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.8332 - loss: 0.4884 - val_accuracy: 0.8900 - val_loss: 0.3247\n",
      "Epoch 3/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.8885 - loss: 0.3272 - val_accuracy: 0.8951 - val_loss: 0.2885\n",
      "Epoch 4/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9062 - loss: 0.2785 - val_accuracy: 0.9080 - val_loss: 0.2655\n",
      "Epoch 5/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.9101 - loss: 0.2512 - val_accuracy: 0.9189 - val_loss: 0.2434\n",
      "Epoch 6/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9166 - loss: 0.2357 - val_accuracy: 0.9266 - val_loss: 0.2143\n",
      "Epoch 7/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9197 - loss: 0.2161 - val_accuracy: 0.9311 - val_loss: 0.2068\n",
      "Epoch 8/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.9229 - loss: 0.2090 - val_accuracy: 0.9337 - val_loss: 0.1989\n",
      "Epoch 9/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.9269 - loss: 0.1968 - val_accuracy: 0.9421 - val_loss: 0.1845\n",
      "Epoch 10/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9285 - loss: 0.1912 - val_accuracy: 0.9408 - val_loss: 0.1899\n",
      "Epoch 11/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9291 - loss: 0.1815 - val_accuracy: 0.9485 - val_loss: 0.1759\n",
      "Epoch 12/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.9371 - loss: 0.1711 - val_accuracy: 0.9498 - val_loss: 0.1727\n",
      "Epoch 13/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9346 - loss: 0.1776 - val_accuracy: 0.9453 - val_loss: 0.1705\n",
      "Epoch 14/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.9356 - loss: 0.1681 - val_accuracy: 0.9524 - val_loss: 0.1653\n",
      "Epoch 15/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9396 - loss: 0.1565 - val_accuracy: 0.9498 - val_loss: 0.1656\n",
      "Epoch 16/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9378 - loss: 0.1574 - val_accuracy: 0.9524 - val_loss: 0.1619\n",
      "Epoch 17/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.9368 - loss: 0.1553 - val_accuracy: 0.9517 - val_loss: 0.1610\n",
      "Epoch 18/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.9410 - loss: 0.1458 - val_accuracy: 0.9492 - val_loss: 0.1646\n",
      "Epoch 19/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.9415 - loss: 0.1437 - val_accuracy: 0.9466 - val_loss: 0.1597\n",
      "Epoch 20/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9425 - loss: 0.1430 - val_accuracy: 0.9530 - val_loss: 0.1609\n",
      "Epoch 21/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.9429 - loss: 0.1415 - val_accuracy: 0.9524 - val_loss: 0.1571\n",
      "Epoch 22/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.9462 - loss: 0.1334 - val_accuracy: 0.9543 - val_loss: 0.1540\n",
      "Epoch 23/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9471 - loss: 0.1285 - val_accuracy: 0.9511 - val_loss: 0.1569\n",
      "Epoch 24/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9477 - loss: 0.1249 - val_accuracy: 0.9569 - val_loss: 0.1570\n",
      "Epoch 25/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9488 - loss: 0.1313 - val_accuracy: 0.9492 - val_loss: 0.1668\n",
      "Epoch 26/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.9479 - loss: 0.1240 - val_accuracy: 0.9517 - val_loss: 0.1439\n",
      "Epoch 27/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.9502 - loss: 0.1186 - val_accuracy: 0.9537 - val_loss: 0.1473\n",
      "Epoch 28/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9480 - loss: 0.1251 - val_accuracy: 0.9524 - val_loss: 0.1505\n",
      "Epoch 29/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9524 - loss: 0.1190 - val_accuracy: 0.9492 - val_loss: 0.1489\n",
      "Epoch 30/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9509 - loss: 0.1165 - val_accuracy: 0.9537 - val_loss: 0.1489\n",
      "Epoch 31/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9500 - loss: 0.1184 - val_accuracy: 0.9537 - val_loss: 0.1447\n",
      "Epoch 32/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.9516 - loss: 0.1137 - val_accuracy: 0.9517 - val_loss: 0.1608\n",
      "Epoch 33/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9541 - loss: 0.1105 - val_accuracy: 0.9575 - val_loss: 0.1392\n",
      "Epoch 34/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.9547 - loss: 0.1093 - val_accuracy: 0.9575 - val_loss: 0.1388\n",
      "Epoch 35/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.9530 - loss: 0.1067 - val_accuracy: 0.9556 - val_loss: 0.1405\n",
      "Epoch 36/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9567 - loss: 0.1034 - val_accuracy: 0.9537 - val_loss: 0.1518\n",
      "Epoch 37/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9579 - loss: 0.1007 - val_accuracy: 0.9517 - val_loss: 0.1536\n",
      "Epoch 38/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9558 - loss: 0.1005 - val_accuracy: 0.9562 - val_loss: 0.1467\n",
      "Epoch 39/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9559 - loss: 0.1031 - val_accuracy: 0.9556 - val_loss: 0.1477\n",
      "Epoch 40/40\n",
      "\u001b[1m453/453\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.9581 - loss: 0.0968 - val_accuracy: 0.9569 - val_loss: 0.1319\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9659 - loss: 0.0954\n",
      "Fold 5 - Test Accuracy: 0.9659\n",
      "âœ… Weights saved to results/cnn_lstm_fold5.weights.h5\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "\n",
      "ğŸ“Š Mean Accuracy: 0.9613636136054993\n",
      "\n",
      "ğŸ“Š Overall 3-Class Metrics\n",
      "Accuracy : 0.9614\n",
      "Rows = True labels | Columns = Predicted labels\n",
      "[[4214    7  179]\n",
      " [  19 2123   58]\n",
      " [ 147   15 4238]]\n",
      "âœ… CNN+LSTM 3-Class Training Completed!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# -------------------- Load Data --------------------\n",
    "X = np.load(r\"preprocessed\\ALL_X.npy\")\n",
    "y = np.load(r\"preprocessed\\ALL_y.npy\")\n",
    "\n",
    "# ---------- Convert to 3 classes: NORMAL, ICTAL, INTERICTAL ----------\n",
    "label_map = {\n",
    "    'NORMAL': 0,\n",
    "    'ICTAL': 1,\n",
    "    'INTERICTAL': 2\n",
    "}\n",
    "y_encoded = np.array([label_map[label] for label in y])\n",
    "\n",
    "# Reshape for CNN input\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Labels distribution:\", np.unique(y_encoded, return_counts=True))\n",
    "\n",
    "# -------------------- Prepare Cross Validation --------------------\n",
    "random_state = np.random.randint(0, 10000)\n",
    "print(f\"ğŸ² Random state used for this run: {random_state}\")\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "fold_indices = [(train_idx, test_idx) for train_idx, test_idx in kfold.split(X, y_encoded)]\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "np.save(\"results/fold_indices.npy\", np.array(fold_indices, dtype=object), allow_pickle=True)\n",
    "\n",
    "\n",
    "# -------------------- CNN + LSTM Model --------------------\n",
    "def build_cnn_lstm(input_length):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=7, activation='relu', input_shape=(input_length, 1)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Conv1D(64, kernel_size=5, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Conv1D(128, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        LSTM(64, return_sequences=False),\n",
    "\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        Dense(3, activation='softmax')   # ğŸ”¥ 3 classes\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(1e-4),\n",
    "        loss='sparse_categorical_crossentropy',  # ğŸ”¥ multi-class\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# -------------------- Data Augmentation (light) --------------------\n",
    "def augment_signal(signal):\n",
    "    noise = np.random.normal(0, 0.005, signal.shape)\n",
    "    signal_noisy = signal + noise\n",
    "\n",
    "    shift = np.random.randint(-5, 5)\n",
    "    signal_shifted = np.roll(signal_noisy, shift)\n",
    "\n",
    "    scale = np.random.uniform(0.97, 1.03)\n",
    "    signal_scaled = signal_shifted * scale\n",
    "\n",
    "    return signal_scaled\n",
    "\n",
    "\n",
    "def augment_batch(X, y):\n",
    "    X_aug, y_aug = [], []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        X_aug.append(X[i])\n",
    "        y_aug.append(y[i])\n",
    "\n",
    "        X_aug.append(augment_signal(X[i]))\n",
    "        y_aug.append(y[i])\n",
    "\n",
    "    return np.array(X_aug), np.array(y_aug)\n",
    "\n",
    "\n",
    "# -------------------- Training --------------------\n",
    "acc_per_fold = []\n",
    "conf_matrices = []\n",
    "\n",
    "for fold_no, (train_val_idx, test_idx) in enumerate(fold_indices, start=1):\n",
    "    print(f\"\\nğŸ”¹ Fold {fold_no}\")\n",
    "\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y_encoded[train_val_idx], y_encoded[test_idx]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.1765, stratify=y_train_val, random_state=42\n",
    "    )\n",
    "\n",
    "    # ------------ APPLY DATA AUGMENTATION ------------\n",
    "    X_train, y_train = augment_batch(X_train, y_train)\n",
    "\n",
    "    print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "\n",
    "    # Build new model for each fold\n",
    "    model = build_cnn_lstm(X_train.shape[1])\n",
    "    model.summary()\n",
    "\n",
    "    # ------------ CLASS IMBALANCE (3 classes) ------------\n",
    "    cw = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    class_weights = {i: cw[i] for i in range(3)}\n",
    "    print(\"Class Weights:\", class_weights)\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=40,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val),\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    acc_per_fold.append(test_acc)\n",
    "    print(f\"Fold {fold_no} - Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # Save weights\n",
    "    weight_path = f\"results/cnn_lstm_fold{fold_no}.weights.h5\"\n",
    "    model.save_weights(weight_path)\n",
    "    print(f\"âœ… Weights saved to {weight_path}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "    conf_matrices.append(cm)\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt='d', cmap='Blues',\n",
    "        xticklabels=['Normal', 'Ictal', 'Interictal'],\n",
    "        yticklabels=['Normal', 'Ictal', 'Interictal']\n",
    "    )\n",
    "    plt.title(f\"Fold {fold_no} Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"results/cnn_lstm_conf_fold{fold_no}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“Š Mean Accuracy:\", np.mean(acc_per_fold))\n",
    "\n",
    "# -------------------- Overall Confusion Matrix --------------------\n",
    "total_cm = np.sum(conf_matrices, axis=0)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(\n",
    "    total_cm, annot=True, fmt='d', cmap='Greens',\n",
    "    xticklabels=['Normal', 'Ictal', 'Interictal'],\n",
    "    yticklabels=['Normal', 'Ictal', 'Interictal']\n",
    ")\n",
    "plt.title(\"Overall Confusion Matrix (All Folds)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/cnn_lstm_conf_overall.png\")\n",
    "\n",
    "tn_normal, fp_normal, _ = total_cm[0]\n",
    "tn_ictal, fp_ictal, _ = total_cm[1]\n",
    "\n",
    "print(\"\\nğŸ“Š Overall 3-Class Metrics\")\n",
    "\n",
    "total = np.sum(total_cm)\n",
    "accuracy = np.trace(total_cm) / total\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "\n",
    "print(\"Rows = True labels | Columns = Predicted labels\")\n",
    "print(total_cm)\n",
    "\n",
    "print(\"âœ… CNN+LSTM 3-Class Training Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5199e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
