{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4718b6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found, using CPU\n",
      "\n",
      "===== Fold 1/5 =====\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\M.Elwensh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.6353 - loss: 0.6359 - val_accuracy: 0.4000 - val_loss: 0.8991 - learning_rate: 1.0000e-04\n",
      "Epoch 2/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.7515 - loss: 0.4415 - val_accuracy: 0.5083 - val_loss: 0.6033 - learning_rate: 1.0000e-04\n",
      "Epoch 3/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.8062 - loss: 0.3735 - val_accuracy: 0.8292 - val_loss: 0.2880 - learning_rate: 1.0000e-04\n",
      "Epoch 4/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8390 - loss: 0.3350 - val_accuracy: 0.9208 - val_loss: 0.1811 - learning_rate: 1.0000e-04\n",
      "Epoch 5/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8669 - loss: 0.3066 - val_accuracy: 0.9125 - val_loss: 0.1637 - learning_rate: 1.0000e-04\n",
      "Epoch 6/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8651 - loss: 0.2850 - val_accuracy: 0.9333 - val_loss: 0.1623 - learning_rate: 1.0000e-04\n",
      "Epoch 7/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8743 - loss: 0.2896 - val_accuracy: 0.9146 - val_loss: 0.1793 - learning_rate: 1.0000e-04\n",
      "Epoch 8/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8721 - loss: 0.2657 - val_accuracy: 0.9271 - val_loss: 0.1460 - learning_rate: 1.0000e-04\n",
      "Epoch 9/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8816 - loss: 0.2602 - val_accuracy: 0.9479 - val_loss: 0.1161 - learning_rate: 1.0000e-04\n",
      "Epoch 10/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8897 - loss: 0.2400 - val_accuracy: 0.8917 - val_loss: 0.2092 - learning_rate: 1.0000e-04\n",
      "Epoch 11/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8746 - loss: 0.2630 - val_accuracy: 0.9208 - val_loss: 0.1639 - learning_rate: 1.0000e-04\n",
      "Epoch 12/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8960 - loss: 0.2316 - val_accuracy: 0.9500 - val_loss: 0.0969 - learning_rate: 1.0000e-04\n",
      "Epoch 13/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8868 - loss: 0.2581 - val_accuracy: 0.9438 - val_loss: 0.1120 - learning_rate: 1.0000e-04\n",
      "Epoch 14/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8798 - loss: 0.2364 - val_accuracy: 0.9563 - val_loss: 0.0935 - learning_rate: 1.0000e-04\n",
      "Epoch 15/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8985 - loss: 0.2187 - val_accuracy: 0.9521 - val_loss: 0.0959 - learning_rate: 1.0000e-04\n",
      "Epoch 16/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8978 - loss: 0.2354 - val_accuracy: 0.9396 - val_loss: 0.1115 - learning_rate: 1.0000e-04\n",
      "Epoch 17/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9055 - loss: 0.2121 - val_accuracy: 0.9563 - val_loss: 0.0823 - learning_rate: 1.0000e-04\n",
      "Epoch 18/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.9210 - loss: 0.1981 - val_accuracy: 0.9333 - val_loss: 0.1348 - learning_rate: 1.0000e-04\n",
      "Epoch 19/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.9099 - loss: 0.2170 - val_accuracy: 0.9521 - val_loss: 0.0941 - learning_rate: 1.0000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.9000 - loss: 0.2153 - val_accuracy: 0.9583 - val_loss: 0.0827 - learning_rate: 1.0000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8985 - loss: 0.2232 - val_accuracy: 0.9563 - val_loss: 0.0794 - learning_rate: 1.0000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9022 - loss: 0.2137 - val_accuracy: 0.9500 - val_loss: 0.1006 - learning_rate: 1.0000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.9136 - loss: 0.1968 - val_accuracy: 0.9688 - val_loss: 0.0717 - learning_rate: 1.0000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9077 - loss: 0.2165 - val_accuracy: 0.9583 - val_loss: 0.0705 - learning_rate: 1.0000e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9114 - loss: 0.2014 - val_accuracy: 0.9542 - val_loss: 0.0801 - learning_rate: 1.0000e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9099 - loss: 0.2026 - val_accuracy: 0.9479 - val_loss: 0.1016 - learning_rate: 1.0000e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.9081 - loss: 0.1978 - val_accuracy: 0.9625 - val_loss: 0.0781 - learning_rate: 1.0000e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9074 - loss: 0.2000 - val_accuracy: 0.9583 - val_loss: 0.0807 - learning_rate: 1.0000e-04\n",
      "Epoch 29/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9092 - loss: 0.2087 - val_accuracy: 0.9688 - val_loss: 0.0738 - learning_rate: 1.0000e-04\n",
      "Epoch 30/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9158 - loss: 0.2029 - val_accuracy: 0.9521 - val_loss: 0.0913 - learning_rate: 1.0000e-04\n",
      "Epoch 31/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9088 - loss: 0.1905 - val_accuracy: 0.9729 - val_loss: 0.0563 - learning_rate: 1.0000e-04\n",
      "Epoch 32/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9118 - loss: 0.2061 - val_accuracy: 0.9521 - val_loss: 0.0804 - learning_rate: 1.0000e-04\n",
      "Epoch 33/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.9103 - loss: 0.2012 - val_accuracy: 0.9563 - val_loss: 0.0759 - learning_rate: 1.0000e-04\n",
      "Epoch 34/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.9246 - loss: 0.1817 - val_accuracy: 0.9729 - val_loss: 0.0590 - learning_rate: 1.0000e-04\n",
      "Epoch 35/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.9037 - loss: 0.2013 - val_accuracy: 0.9667 - val_loss: 0.0637 - learning_rate: 1.0000e-04\n",
      "Epoch 36/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9180 - loss: 0.1943 - val_accuracy: 0.9500 - val_loss: 0.0954 - learning_rate: 1.0000e-04\n",
      "Epoch 37/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9180 - loss: 0.1970 - val_accuracy: 0.9646 - val_loss: 0.0677 - learning_rate: 1.0000e-04\n",
      "Epoch 38/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9224 - loss: 0.1833 - val_accuracy: 0.9625 - val_loss: 0.0748 - learning_rate: 1.0000e-04\n",
      "Epoch 39/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.9228 - loss: 0.1793 - val_accuracy: 0.9667 - val_loss: 0.0615 - learning_rate: 1.0000e-04\n",
      "Epoch 40/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.9195 - loss: 0.1847 - val_accuracy: 0.9667 - val_loss: 0.0681 - learning_rate: 6.0000e-05\n",
      "Epoch 41/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9254 - loss: 0.1784 - val_accuracy: 0.9688 - val_loss: 0.0541 - learning_rate: 6.0000e-05\n",
      "Epoch 42/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9180 - loss: 0.1803 - val_accuracy: 0.9646 - val_loss: 0.0709 - learning_rate: 6.0000e-05\n",
      "Epoch 43/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9276 - loss: 0.1742 - val_accuracy: 0.9667 - val_loss: 0.0725 - learning_rate: 6.0000e-05\n",
      "Epoch 44/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.9217 - loss: 0.1802 - val_accuracy: 0.9646 - val_loss: 0.0703 - learning_rate: 6.0000e-05\n",
      "Epoch 45/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.9217 - loss: 0.1887 - val_accuracy: 0.9688 - val_loss: 0.0609 - learning_rate: 6.0000e-05\n",
      "Epoch 46/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.9210 - loss: 0.1783 - val_accuracy: 0.9542 - val_loss: 0.0831 - learning_rate: 6.0000e-05\n",
      "Epoch 47/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9316 - loss: 0.1760 - val_accuracy: 0.9604 - val_loss: 0.0666 - learning_rate: 6.0000e-05\n",
      "Epoch 48/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9239 - loss: 0.1950 - val_accuracy: 0.9708 - val_loss: 0.0560 - learning_rate: 6.0000e-05\n",
      "Epoch 49/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9199 - loss: 0.1838 - val_accuracy: 0.9708 - val_loss: 0.0597 - learning_rate: 6.0000e-05\n",
      "Epoch 50/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9243 - loss: 0.1811 - val_accuracy: 0.9729 - val_loss: 0.0533 - learning_rate: 3.6000e-05\n",
      "Epoch 51/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.9309 - loss: 0.1730 - val_accuracy: 0.9667 - val_loss: 0.0628 - learning_rate: 3.6000e-05\n",
      "Epoch 52/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9353 - loss: 0.1712 - val_accuracy: 0.9646 - val_loss: 0.0646 - learning_rate: 3.6000e-05\n",
      "Epoch 53/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9346 - loss: 0.1644 - val_accuracy: 0.9729 - val_loss: 0.0535 - learning_rate: 3.6000e-05\n",
      "Epoch 54/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.9268 - loss: 0.1808 - val_accuracy: 0.9667 - val_loss: 0.0596 - learning_rate: 3.6000e-05\n",
      "Epoch 55/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.9221 - loss: 0.1718 - val_accuracy: 0.9688 - val_loss: 0.0567 - learning_rate: 3.6000e-05\n",
      "Epoch 56/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.9243 - loss: 0.1931 - val_accuracy: 0.9729 - val_loss: 0.0528 - learning_rate: 3.6000e-05\n",
      "Epoch 57/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.9221 - loss: 0.1730 - val_accuracy: 0.9729 - val_loss: 0.0536 - learning_rate: 3.6000e-05\n",
      "Epoch 58/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9272 - loss: 0.1714 - val_accuracy: 0.9729 - val_loss: 0.0494 - learning_rate: 3.6000e-05\n",
      "Epoch 59/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.9368 - loss: 0.1680 - val_accuracy: 0.9667 - val_loss: 0.0621 - learning_rate: 3.6000e-05\n",
      "Epoch 60/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 66ms/step - accuracy: 0.9294 - loss: 0.1742 - val_accuracy: 0.9750 - val_loss: 0.0457 - learning_rate: 3.6000e-05\n",
      "Epoch 61/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9268 - loss: 0.1765 - val_accuracy: 0.9708 - val_loss: 0.0531 - learning_rate: 3.6000e-05\n",
      "Epoch 62/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9305 - loss: 0.1691 - val_accuracy: 0.9750 - val_loss: 0.0516 - learning_rate: 3.6000e-05\n",
      "Epoch 63/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9312 - loss: 0.1680 - val_accuracy: 0.9729 - val_loss: 0.0528 - learning_rate: 3.6000e-05\n",
      "Epoch 64/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9217 - loss: 0.1787 - val_accuracy: 0.9729 - val_loss: 0.0591 - learning_rate: 3.6000e-05\n",
      "Epoch 65/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.9298 - loss: 0.1762 - val_accuracy: 0.9646 - val_loss: 0.0634 - learning_rate: 3.6000e-05\n",
      "Epoch 66/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9312 - loss: 0.1777 - val_accuracy: 0.9708 - val_loss: 0.0599 - learning_rate: 3.6000e-05\n",
      "Epoch 67/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.9243 - loss: 0.1759 - val_accuracy: 0.9708 - val_loss: 0.0561 - learning_rate: 3.6000e-05\n",
      "Epoch 68/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9265 - loss: 0.1677 - val_accuracy: 0.9729 - val_loss: 0.0540 - learning_rate: 3.6000e-05\n",
      "Epoch 69/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9324 - loss: 0.1710 - val_accuracy: 0.9708 - val_loss: 0.0554 - learning_rate: 2.1600e-05\n",
      "Epoch 70/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9335 - loss: 0.1747 - val_accuracy: 0.9708 - val_loss: 0.0519 - learning_rate: 2.1600e-05\n",
      "Epoch 71/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9364 - loss: 0.1594 - val_accuracy: 0.9688 - val_loss: 0.0607 - learning_rate: 2.1600e-05\n",
      "Epoch 72/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 0.9279 - loss: 0.1845 - val_accuracy: 0.9688 - val_loss: 0.0604 - learning_rate: 2.1600e-05\n",
      "Epoch 73/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 75ms/step - accuracy: 0.9320 - loss: 0.1673 - val_accuracy: 0.9708 - val_loss: 0.0546 - learning_rate: 2.1600e-05\n",
      "Epoch 74/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.9254 - loss: 0.1682 - val_accuracy: 0.9708 - val_loss: 0.0554 - learning_rate: 2.1600e-05\n",
      "Epoch 75/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9268 - loss: 0.1781 - val_accuracy: 0.9729 - val_loss: 0.0524 - learning_rate: 2.1600e-05\n",
      "Epoch 76/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9353 - loss: 0.1619 - val_accuracy: 0.9729 - val_loss: 0.0528 - learning_rate: 2.1600e-05\n",
      "Epoch 77/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9338 - loss: 0.1697 - val_accuracy: 0.9729 - val_loss: 0.0513 - learning_rate: 1.2960e-05\n",
      "Epoch 78/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9294 - loss: 0.1821 - val_accuracy: 0.9708 - val_loss: 0.0583 - learning_rate: 1.2960e-05\n",
      "Epoch 79/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9331 - loss: 0.1712 - val_accuracy: 0.9708 - val_loss: 0.0540 - learning_rate: 1.2960e-05\n",
      "Epoch 80/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9298 - loss: 0.1645 - val_accuracy: 0.9729 - val_loss: 0.0541 - learning_rate: 1.2960e-05\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "\n",
      "===== Fold 2/5 =====\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\M.Elwensh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.6246 - loss: 0.6091 - val_accuracy: 0.4000 - val_loss: 0.9704 - learning_rate: 1.0000e-04\n",
      "Epoch 2/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.7688 - loss: 0.4456 - val_accuracy: 0.5771 - val_loss: 0.5608 - learning_rate: 1.0000e-04\n",
      "Epoch 3/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.8099 - loss: 0.3819 - val_accuracy: 0.9167 - val_loss: 0.2352 - learning_rate: 1.0000e-04\n",
      "Epoch 4/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.8338 - loss: 0.3342 - val_accuracy: 0.8938 - val_loss: 0.1959 - learning_rate: 1.0000e-04\n",
      "Epoch 5/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - accuracy: 0.8511 - loss: 0.3149 - val_accuracy: 0.9083 - val_loss: 0.1908 - learning_rate: 1.0000e-04\n",
      "Epoch 6/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8636 - loss: 0.2936 - val_accuracy: 0.9000 - val_loss: 0.1971 - learning_rate: 1.0000e-04\n",
      "Epoch 7/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.8651 - loss: 0.2835 - val_accuracy: 0.8979 - val_loss: 0.2032 - learning_rate: 1.0000e-04\n",
      "Epoch 8/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.8618 - loss: 0.2907 - val_accuracy: 0.9354 - val_loss: 0.1309 - learning_rate: 1.0000e-04\n",
      "Epoch 9/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - accuracy: 0.8897 - loss: 0.2491 - val_accuracy: 0.9292 - val_loss: 0.1343 - learning_rate: 1.0000e-04\n",
      "Epoch 10/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8827 - loss: 0.2591 - val_accuracy: 0.9042 - val_loss: 0.1643 - learning_rate: 1.0000e-04\n",
      "Epoch 11/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8776 - loss: 0.2476 - val_accuracy: 0.9396 - val_loss: 0.1203 - learning_rate: 1.0000e-04\n",
      "Epoch 12/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.8739 - loss: 0.2542 - val_accuracy: 0.9375 - val_loss: 0.1269 - learning_rate: 1.0000e-04\n",
      "Epoch 13/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8831 - loss: 0.2402 - val_accuracy: 0.9354 - val_loss: 0.1271 - learning_rate: 1.0000e-04\n",
      "Epoch 14/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8974 - loss: 0.2336 - val_accuracy: 0.9500 - val_loss: 0.1000 - learning_rate: 1.0000e-04\n",
      "Epoch 15/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.8879 - loss: 0.2362 - val_accuracy: 0.9146 - val_loss: 0.1532 - learning_rate: 1.0000e-04\n",
      "Epoch 16/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8904 - loss: 0.2452 - val_accuracy: 0.9292 - val_loss: 0.1230 - learning_rate: 1.0000e-04\n",
      "Epoch 17/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8982 - loss: 0.2318 - val_accuracy: 0.9500 - val_loss: 0.0952 - learning_rate: 1.0000e-04\n",
      "Epoch 18/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9096 - loss: 0.2041 - val_accuracy: 0.9563 - val_loss: 0.0948 - learning_rate: 1.0000e-04\n",
      "Epoch 19/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9132 - loss: 0.1949 - val_accuracy: 0.9583 - val_loss: 0.0795 - learning_rate: 1.0000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9000 - loss: 0.2106 - val_accuracy: 0.9646 - val_loss: 0.0800 - learning_rate: 1.0000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9051 - loss: 0.2122 - val_accuracy: 0.9438 - val_loss: 0.1056 - learning_rate: 1.0000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9066 - loss: 0.1951 - val_accuracy: 0.9583 - val_loss: 0.0861 - learning_rate: 1.0000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.9048 - loss: 0.2108 - val_accuracy: 0.9354 - val_loss: 0.1002 - learning_rate: 1.0000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.8978 - loss: 0.2198 - val_accuracy: 0.9625 - val_loss: 0.0795 - learning_rate: 1.0000e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.9048 - loss: 0.2144 - val_accuracy: 0.9625 - val_loss: 0.0797 - learning_rate: 1.0000e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9158 - loss: 0.2000 - val_accuracy: 0.9729 - val_loss: 0.0642 - learning_rate: 1.0000e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9099 - loss: 0.2088 - val_accuracy: 0.9583 - val_loss: 0.0704 - learning_rate: 1.0000e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9254 - loss: 0.1915 - val_accuracy: 0.9625 - val_loss: 0.0681 - learning_rate: 1.0000e-04\n",
      "Epoch 29/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.9103 - loss: 0.1986 - val_accuracy: 0.9375 - val_loss: 0.1182 - learning_rate: 1.0000e-04\n",
      "Epoch 30/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9169 - loss: 0.2131 - val_accuracy: 0.9458 - val_loss: 0.0844 - learning_rate: 1.0000e-04\n",
      "Epoch 31/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9180 - loss: 0.2003 - val_accuracy: 0.9667 - val_loss: 0.0602 - learning_rate: 1.0000e-04\n",
      "Epoch 32/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.9210 - loss: 0.1988 - val_accuracy: 0.9688 - val_loss: 0.0737 - learning_rate: 1.0000e-04\n",
      "Epoch 33/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9202 - loss: 0.1905 - val_accuracy: 0.9729 - val_loss: 0.0652 - learning_rate: 1.0000e-04\n",
      "Epoch 34/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.9191 - loss: 0.1918 - val_accuracy: 0.9771 - val_loss: 0.0523 - learning_rate: 1.0000e-04\n",
      "Epoch 35/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.9162 - loss: 0.1873 - val_accuracy: 0.9521 - val_loss: 0.0880 - learning_rate: 1.0000e-04\n",
      "Epoch 36/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9217 - loss: 0.1937 - val_accuracy: 0.9521 - val_loss: 0.0964 - learning_rate: 1.0000e-04\n",
      "Epoch 37/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.8974 - loss: 0.2177 - val_accuracy: 0.9667 - val_loss: 0.0705 - learning_rate: 1.0000e-04\n",
      "Epoch 38/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9151 - loss: 0.1911 - val_accuracy: 0.9729 - val_loss: 0.0557 - learning_rate: 1.0000e-04\n",
      "Epoch 39/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9187 - loss: 0.1817 - val_accuracy: 0.9625 - val_loss: 0.0728 - learning_rate: 1.0000e-04\n",
      "Epoch 40/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9276 - loss: 0.1720 - val_accuracy: 0.9646 - val_loss: 0.0666 - learning_rate: 1.0000e-04\n",
      "Epoch 41/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9195 - loss: 0.1939 - val_accuracy: 0.9646 - val_loss: 0.0817 - learning_rate: 1.0000e-04\n",
      "Epoch 42/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9213 - loss: 0.1806 - val_accuracy: 0.9625 - val_loss: 0.0754 - learning_rate: 1.0000e-04\n",
      "Epoch 43/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.9301 - loss: 0.1811 - val_accuracy: 0.9563 - val_loss: 0.0795 - learning_rate: 6.0000e-05\n",
      "Epoch 44/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9294 - loss: 0.1790 - val_accuracy: 0.9563 - val_loss: 0.0839 - learning_rate: 6.0000e-05\n",
      "Epoch 45/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9279 - loss: 0.1902 - val_accuracy: 0.9604 - val_loss: 0.0716 - learning_rate: 6.0000e-05\n",
      "Epoch 46/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.9287 - loss: 0.1745 - val_accuracy: 0.9563 - val_loss: 0.0668 - learning_rate: 6.0000e-05\n",
      "Epoch 47/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.9246 - loss: 0.1860 - val_accuracy: 0.9688 - val_loss: 0.0669 - learning_rate: 6.0000e-05\n",
      "Epoch 48/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.9195 - loss: 0.1801 - val_accuracy: 0.9583 - val_loss: 0.0682 - learning_rate: 6.0000e-05\n",
      "Epoch 49/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9301 - loss: 0.1790 - val_accuracy: 0.9583 - val_loss: 0.0721 - learning_rate: 6.0000e-05\n",
      "Epoch 50/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9287 - loss: 0.1849 - val_accuracy: 0.9438 - val_loss: 0.0941 - learning_rate: 6.0000e-05\n",
      "Epoch 51/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9338 - loss: 0.1756 - val_accuracy: 0.9604 - val_loss: 0.0713 - learning_rate: 3.6000e-05\n",
      "Epoch 52/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9213 - loss: 0.1936 - val_accuracy: 0.9625 - val_loss: 0.0656 - learning_rate: 3.6000e-05\n",
      "Epoch 53/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9250 - loss: 0.1670 - val_accuracy: 0.9563 - val_loss: 0.0730 - learning_rate: 3.6000e-05\n",
      "Epoch 54/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9265 - loss: 0.1691 - val_accuracy: 0.9625 - val_loss: 0.0648 - learning_rate: 3.6000e-05\n",
      "Epoch 55/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.9320 - loss: 0.1666 - val_accuracy: 0.9583 - val_loss: 0.0723 - learning_rate: 3.6000e-05\n",
      "Epoch 56/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9305 - loss: 0.1773 - val_accuracy: 0.9583 - val_loss: 0.0705 - learning_rate: 3.6000e-05\n",
      "Epoch 57/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9312 - loss: 0.1805 - val_accuracy: 0.9625 - val_loss: 0.0664 - learning_rate: 3.6000e-05\n",
      "Epoch 58/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9349 - loss: 0.1675 - val_accuracy: 0.9604 - val_loss: 0.0635 - learning_rate: 3.6000e-05\n",
      "Epoch 59/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9213 - loss: 0.1743 - val_accuracy: 0.9625 - val_loss: 0.0615 - learning_rate: 2.1600e-05\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "\n",
      "===== Fold 3/5 =====\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\M.Elwensh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - accuracy: 0.6250 - loss: 0.6332 - val_accuracy: 0.4000 - val_loss: 1.1439 - learning_rate: 1.0000e-04\n",
      "Epoch 2/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.7482 - loss: 0.4645 - val_accuracy: 0.4250 - val_loss: 0.8897 - learning_rate: 1.0000e-04\n",
      "Epoch 3/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.8026 - loss: 0.3840 - val_accuracy: 0.8313 - val_loss: 0.3256 - learning_rate: 1.0000e-04\n",
      "Epoch 4/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.8379 - loss: 0.3517 - val_accuracy: 0.9333 - val_loss: 0.1767 - learning_rate: 1.0000e-04\n",
      "Epoch 5/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.8533 - loss: 0.3298 - val_accuracy: 0.9417 - val_loss: 0.1673 - learning_rate: 1.0000e-04\n",
      "Epoch 6/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.8640 - loss: 0.2979 - val_accuracy: 0.9417 - val_loss: 0.1390 - learning_rate: 1.0000e-04\n",
      "Epoch 7/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.8651 - loss: 0.2979 - val_accuracy: 0.9333 - val_loss: 0.1356 - learning_rate: 1.0000e-04\n",
      "Epoch 8/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.8647 - loss: 0.2844 - val_accuracy: 0.9354 - val_loss: 0.1542 - learning_rate: 1.0000e-04\n",
      "Epoch 9/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.8699 - loss: 0.2785 - val_accuracy: 0.9312 - val_loss: 0.1292 - learning_rate: 1.0000e-04\n",
      "Epoch 10/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.8879 - loss: 0.2520 - val_accuracy: 0.9604 - val_loss: 0.0976 - learning_rate: 1.0000e-04\n",
      "Epoch 11/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.8915 - loss: 0.2572 - val_accuracy: 0.9500 - val_loss: 0.0989 - learning_rate: 1.0000e-04\n",
      "Epoch 12/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9007 - loss: 0.2324 - val_accuracy: 0.9708 - val_loss: 0.0852 - learning_rate: 1.0000e-04\n",
      "Epoch 13/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.8963 - loss: 0.2512 - val_accuracy: 0.9708 - val_loss: 0.0814 - learning_rate: 1.0000e-04\n",
      "Epoch 14/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9018 - loss: 0.2214 - val_accuracy: 0.9646 - val_loss: 0.0774 - learning_rate: 1.0000e-04\n",
      "Epoch 15/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9007 - loss: 0.2189 - val_accuracy: 0.9583 - val_loss: 0.0837 - learning_rate: 1.0000e-04\n",
      "Epoch 16/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.8967 - loss: 0.2330 - val_accuracy: 0.9563 - val_loss: 0.0694 - learning_rate: 1.0000e-04\n",
      "Epoch 17/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9051 - loss: 0.2229 - val_accuracy: 0.9500 - val_loss: 0.1164 - learning_rate: 1.0000e-04\n",
      "Epoch 18/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8890 - loss: 0.2269 - val_accuracy: 0.9688 - val_loss: 0.0649 - learning_rate: 1.0000e-04\n",
      "Epoch 19/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.9107 - loss: 0.2051 - val_accuracy: 0.9646 - val_loss: 0.0620 - learning_rate: 1.0000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.9000 - loss: 0.2207 - val_accuracy: 0.9646 - val_loss: 0.0581 - learning_rate: 1.0000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9224 - loss: 0.1939 - val_accuracy: 0.9688 - val_loss: 0.0607 - learning_rate: 1.0000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9059 - loss: 0.2211 - val_accuracy: 0.9667 - val_loss: 0.0647 - learning_rate: 1.0000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9206 - loss: 0.1955 - val_accuracy: 0.9646 - val_loss: 0.0626 - learning_rate: 1.0000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9136 - loss: 0.1920 - val_accuracy: 0.9688 - val_loss: 0.0538 - learning_rate: 1.0000e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.9136 - loss: 0.1981 - val_accuracy: 0.9375 - val_loss: 0.1013 - learning_rate: 1.0000e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.9206 - loss: 0.1935 - val_accuracy: 0.9646 - val_loss: 0.0587 - learning_rate: 1.0000e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9210 - loss: 0.2008 - val_accuracy: 0.9667 - val_loss: 0.0624 - learning_rate: 1.0000e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.9239 - loss: 0.1986 - val_accuracy: 0.9625 - val_loss: 0.0677 - learning_rate: 1.0000e-04\n",
      "Epoch 29/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9301 - loss: 0.1966 - val_accuracy: 0.9625 - val_loss: 0.0678 - learning_rate: 1.0000e-04\n",
      "Epoch 30/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9265 - loss: 0.1869 - val_accuracy: 0.9708 - val_loss: 0.0493 - learning_rate: 1.0000e-04\n",
      "Epoch 31/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9154 - loss: 0.1975 - val_accuracy: 0.9646 - val_loss: 0.0552 - learning_rate: 1.0000e-04\n",
      "Epoch 32/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9176 - loss: 0.1995 - val_accuracy: 0.9708 - val_loss: 0.0518 - learning_rate: 1.0000e-04\n",
      "Epoch 33/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9228 - loss: 0.1968 - val_accuracy: 0.9646 - val_loss: 0.0610 - learning_rate: 1.0000e-04\n",
      "Epoch 34/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9246 - loss: 0.1887 - val_accuracy: 0.9688 - val_loss: 0.0520 - learning_rate: 1.0000e-04\n",
      "Epoch 35/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.9232 - loss: 0.1941 - val_accuracy: 0.9625 - val_loss: 0.0571 - learning_rate: 1.0000e-04\n",
      "Epoch 36/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.9268 - loss: 0.1785 - val_accuracy: 0.9812 - val_loss: 0.0444 - learning_rate: 1.0000e-04\n",
      "Epoch 37/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9283 - loss: 0.1708 - val_accuracy: 0.9625 - val_loss: 0.0610 - learning_rate: 1.0000e-04\n",
      "Epoch 38/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.9210 - loss: 0.1928 - val_accuracy: 0.9771 - val_loss: 0.0461 - learning_rate: 1.0000e-04\n",
      "Epoch 39/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9257 - loss: 0.1699 - val_accuracy: 0.9688 - val_loss: 0.0510 - learning_rate: 1.0000e-04\n",
      "Epoch 40/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9283 - loss: 0.1750 - val_accuracy: 0.9750 - val_loss: 0.0462 - learning_rate: 1.0000e-04\n",
      "Epoch 41/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.9224 - loss: 0.1873 - val_accuracy: 0.9542 - val_loss: 0.0669 - learning_rate: 1.0000e-04\n",
      "Epoch 42/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9276 - loss: 0.1894 - val_accuracy: 0.9542 - val_loss: 0.0873 - learning_rate: 1.0000e-04\n",
      "Epoch 43/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9199 - loss: 0.1865 - val_accuracy: 0.9667 - val_loss: 0.0609 - learning_rate: 1.0000e-04\n",
      "Epoch 44/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9232 - loss: 0.1848 - val_accuracy: 0.9625 - val_loss: 0.0698 - learning_rate: 1.0000e-04\n",
      "Epoch 45/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9301 - loss: 0.1844 - val_accuracy: 0.9625 - val_loss: 0.0622 - learning_rate: 6.0000e-05\n",
      "Epoch 46/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.9364 - loss: 0.1664 - val_accuracy: 0.9688 - val_loss: 0.0517 - learning_rate: 6.0000e-05\n",
      "Epoch 47/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9324 - loss: 0.1754 - val_accuracy: 0.9708 - val_loss: 0.0509 - learning_rate: 6.0000e-05\n",
      "Epoch 48/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9206 - loss: 0.1864 - val_accuracy: 0.9708 - val_loss: 0.0478 - learning_rate: 6.0000e-05\n",
      "Epoch 49/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9239 - loss: 0.1799 - val_accuracy: 0.9667 - val_loss: 0.0504 - learning_rate: 6.0000e-05\n",
      "Epoch 50/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9338 - loss: 0.1653 - val_accuracy: 0.9708 - val_loss: 0.0452 - learning_rate: 6.0000e-05\n",
      "Epoch 51/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.9158 - loss: 0.1956 - val_accuracy: 0.9792 - val_loss: 0.0458 - learning_rate: 6.0000e-05\n",
      "Epoch 52/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9353 - loss: 0.1789 - val_accuracy: 0.9729 - val_loss: 0.0469 - learning_rate: 6.0000e-05\n",
      "Epoch 53/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9360 - loss: 0.1691 - val_accuracy: 0.9729 - val_loss: 0.0454 - learning_rate: 3.6000e-05\n",
      "Epoch 54/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.9342 - loss: 0.1723 - val_accuracy: 0.9729 - val_loss: 0.0472 - learning_rate: 3.6000e-05\n",
      "Epoch 55/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9364 - loss: 0.1661 - val_accuracy: 0.9646 - val_loss: 0.0513 - learning_rate: 3.6000e-05\n",
      "Epoch 56/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9346 - loss: 0.1701 - val_accuracy: 0.9688 - val_loss: 0.0494 - learning_rate: 3.6000e-05\n",
      "Epoch 57/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - accuracy: 0.9254 - loss: 0.1825 - val_accuracy: 0.9688 - val_loss: 0.0490 - learning_rate: 3.6000e-05\n",
      "Epoch 58/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9364 - loss: 0.1724 - val_accuracy: 0.9688 - val_loss: 0.0518 - learning_rate: 3.6000e-05\n",
      "Epoch 59/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9368 - loss: 0.1707 - val_accuracy: 0.9688 - val_loss: 0.0497 - learning_rate: 3.6000e-05\n",
      "Epoch 60/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9210 - loss: 0.1830 - val_accuracy: 0.9625 - val_loss: 0.0524 - learning_rate: 3.6000e-05\n",
      "Epoch 61/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.9419 - loss: 0.1609 - val_accuracy: 0.9625 - val_loss: 0.0520 - learning_rate: 2.1600e-05\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\n",
      "===== Fold 4/5 =====\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\M.Elwensh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 64ms/step - accuracy: 0.5813 - loss: 0.6952 - val_accuracy: 0.4000 - val_loss: 0.9744 - learning_rate: 1.0000e-04\n",
      "Epoch 2/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.7640 - loss: 0.4394 - val_accuracy: 0.4750 - val_loss: 0.6496 - learning_rate: 1.0000e-04\n",
      "Epoch 3/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.8000 - loss: 0.3879 - val_accuracy: 0.8396 - val_loss: 0.2977 - learning_rate: 1.0000e-04\n",
      "Epoch 4/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.8390 - loss: 0.3322 - val_accuracy: 0.9167 - val_loss: 0.1979 - learning_rate: 1.0000e-04\n",
      "Epoch 5/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.8412 - loss: 0.3234 - val_accuracy: 0.9146 - val_loss: 0.1751 - learning_rate: 1.0000e-04\n",
      "Epoch 6/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.8640 - loss: 0.3002 - val_accuracy: 0.8708 - val_loss: 0.2089 - learning_rate: 1.0000e-04\n",
      "Epoch 7/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.8570 - loss: 0.2983 - val_accuracy: 0.9021 - val_loss: 0.1823 - learning_rate: 1.0000e-04\n",
      "Epoch 8/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.8754 - loss: 0.2745 - val_accuracy: 0.9000 - val_loss: 0.1818 - learning_rate: 1.0000e-04\n",
      "Epoch 9/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.8691 - loss: 0.2844 - val_accuracy: 0.9187 - val_loss: 0.1545 - learning_rate: 1.0000e-04\n",
      "Epoch 10/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.8879 - loss: 0.2459 - val_accuracy: 0.9208 - val_loss: 0.1449 - learning_rate: 1.0000e-04\n",
      "Epoch 11/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.8915 - loss: 0.2463 - val_accuracy: 0.9125 - val_loss: 0.1545 - learning_rate: 1.0000e-04\n",
      "Epoch 12/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9015 - loss: 0.2430 - val_accuracy: 0.9292 - val_loss: 0.1295 - learning_rate: 1.0000e-04\n",
      "Epoch 13/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8978 - loss: 0.2371 - val_accuracy: 0.9292 - val_loss: 0.1375 - learning_rate: 1.0000e-04\n",
      "Epoch 14/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.8923 - loss: 0.2324 - val_accuracy: 0.9479 - val_loss: 0.1031 - learning_rate: 1.0000e-04\n",
      "Epoch 15/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.9066 - loss: 0.2158 - val_accuracy: 0.9042 - val_loss: 0.1637 - learning_rate: 1.0000e-04\n",
      "Epoch 16/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.8967 - loss: 0.2387 - val_accuracy: 0.9083 - val_loss: 0.1715 - learning_rate: 1.0000e-04\n",
      "Epoch 17/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.8985 - loss: 0.2328 - val_accuracy: 0.9500 - val_loss: 0.1065 - learning_rate: 1.0000e-04\n",
      "Epoch 18/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.9110 - loss: 0.2228 - val_accuracy: 0.9292 - val_loss: 0.1318 - learning_rate: 1.0000e-04\n",
      "Epoch 19/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9004 - loss: 0.2262 - val_accuracy: 0.9479 - val_loss: 0.1011 - learning_rate: 1.0000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.9059 - loss: 0.2102 - val_accuracy: 0.9312 - val_loss: 0.1245 - learning_rate: 1.0000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.9154 - loss: 0.2078 - val_accuracy: 0.9479 - val_loss: 0.1015 - learning_rate: 1.0000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.9077 - loss: 0.2109 - val_accuracy: 0.9417 - val_loss: 0.1154 - learning_rate: 1.0000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8989 - loss: 0.2257 - val_accuracy: 0.9604 - val_loss: 0.0832 - learning_rate: 1.0000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9107 - loss: 0.2005 - val_accuracy: 0.9417 - val_loss: 0.1032 - learning_rate: 1.0000e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9107 - loss: 0.2091 - val_accuracy: 0.9667 - val_loss: 0.0831 - learning_rate: 1.0000e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9092 - loss: 0.2172 - val_accuracy: 0.9417 - val_loss: 0.1049 - learning_rate: 1.0000e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9140 - loss: 0.1990 - val_accuracy: 0.9500 - val_loss: 0.0957 - learning_rate: 1.0000e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9015 - loss: 0.2003 - val_accuracy: 0.9542 - val_loss: 0.0819 - learning_rate: 1.0000e-04\n",
      "Epoch 29/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9254 - loss: 0.1906 - val_accuracy: 0.9458 - val_loss: 0.1006 - learning_rate: 1.0000e-04\n",
      "Epoch 30/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9158 - loss: 0.1979 - val_accuracy: 0.9458 - val_loss: 0.1020 - learning_rate: 1.0000e-04\n",
      "Epoch 31/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9213 - loss: 0.1887 - val_accuracy: 0.9500 - val_loss: 0.0907 - learning_rate: 1.0000e-04\n",
      "Epoch 32/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9298 - loss: 0.1844 - val_accuracy: 0.9583 - val_loss: 0.0705 - learning_rate: 1.0000e-04\n",
      "Epoch 33/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9125 - loss: 0.1934 - val_accuracy: 0.9458 - val_loss: 0.1040 - learning_rate: 1.0000e-04\n",
      "Epoch 34/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9055 - loss: 0.2034 - val_accuracy: 0.9458 - val_loss: 0.0819 - learning_rate: 1.0000e-04\n",
      "Epoch 35/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9088 - loss: 0.2051 - val_accuracy: 0.9583 - val_loss: 0.0684 - learning_rate: 1.0000e-04\n",
      "Epoch 36/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9210 - loss: 0.1806 - val_accuracy: 0.9583 - val_loss: 0.0640 - learning_rate: 1.0000e-04\n",
      "Epoch 37/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9154 - loss: 0.1886 - val_accuracy: 0.9563 - val_loss: 0.0746 - learning_rate: 1.0000e-04\n",
      "Epoch 38/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9070 - loss: 0.1980 - val_accuracy: 0.9604 - val_loss: 0.0768 - learning_rate: 1.0000e-04\n",
      "Epoch 39/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9210 - loss: 0.1865 - val_accuracy: 0.9625 - val_loss: 0.0656 - learning_rate: 1.0000e-04\n",
      "Epoch 40/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9202 - loss: 0.1883 - val_accuracy: 0.9542 - val_loss: 0.0672 - learning_rate: 1.0000e-04\n",
      "Epoch 41/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9235 - loss: 0.1870 - val_accuracy: 0.9542 - val_loss: 0.0756 - learning_rate: 1.0000e-04\n",
      "Epoch 42/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.9235 - loss: 0.1781 - val_accuracy: 0.9583 - val_loss: 0.0772 - learning_rate: 1.0000e-04\n",
      "Epoch 43/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9279 - loss: 0.1744 - val_accuracy: 0.9604 - val_loss: 0.0595 - learning_rate: 1.0000e-04\n",
      "Epoch 44/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9316 - loss: 0.1746 - val_accuracy: 0.9521 - val_loss: 0.0640 - learning_rate: 1.0000e-04\n",
      "Epoch 45/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9173 - loss: 0.1935 - val_accuracy: 0.9583 - val_loss: 0.0674 - learning_rate: 1.0000e-04\n",
      "Epoch 46/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.9143 - loss: 0.1896 - val_accuracy: 0.9563 - val_loss: 0.0681 - learning_rate: 1.0000e-04\n",
      "Epoch 47/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9257 - loss: 0.1811 - val_accuracy: 0.9542 - val_loss: 0.0651 - learning_rate: 1.0000e-04\n",
      "Epoch 48/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9187 - loss: 0.1916 - val_accuracy: 0.9625 - val_loss: 0.0587 - learning_rate: 1.0000e-04\n",
      "Epoch 49/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9184 - loss: 0.1879 - val_accuracy: 0.9500 - val_loss: 0.0862 - learning_rate: 1.0000e-04\n",
      "Epoch 50/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.9217 - loss: 0.1844 - val_accuracy: 0.9563 - val_loss: 0.0708 - learning_rate: 1.0000e-04\n",
      "Epoch 51/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9261 - loss: 0.1758 - val_accuracy: 0.9500 - val_loss: 0.0972 - learning_rate: 1.0000e-04\n",
      "Epoch 52/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9199 - loss: 0.1859 - val_accuracy: 0.9625 - val_loss: 0.0593 - learning_rate: 1.0000e-04\n",
      "Epoch 53/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9176 - loss: 0.1840 - val_accuracy: 0.9583 - val_loss: 0.0766 - learning_rate: 1.0000e-04\n",
      "Epoch 54/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9199 - loss: 0.1787 - val_accuracy: 0.9604 - val_loss: 0.0584 - learning_rate: 1.0000e-04\n",
      "Epoch 55/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9254 - loss: 0.1709 - val_accuracy: 0.9604 - val_loss: 0.0626 - learning_rate: 1.0000e-04\n",
      "Epoch 56/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.9268 - loss: 0.1758 - val_accuracy: 0.9625 - val_loss: 0.0583 - learning_rate: 1.0000e-04\n",
      "Epoch 57/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.9283 - loss: 0.1721 - val_accuracy: 0.9479 - val_loss: 0.0765 - learning_rate: 1.0000e-04\n",
      "Epoch 58/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.9243 - loss: 0.1836 - val_accuracy: 0.9625 - val_loss: 0.0693 - learning_rate: 1.0000e-04\n",
      "Epoch 59/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9265 - loss: 0.1722 - val_accuracy: 0.9667 - val_loss: 0.0651 - learning_rate: 1.0000e-04\n",
      "Epoch 60/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9312 - loss: 0.1725 - val_accuracy: 0.9667 - val_loss: 0.0530 - learning_rate: 1.0000e-04\n",
      "Epoch 61/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9243 - loss: 0.1776 - val_accuracy: 0.9583 - val_loss: 0.0597 - learning_rate: 1.0000e-04\n",
      "Epoch 62/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9272 - loss: 0.1813 - val_accuracy: 0.9563 - val_loss: 0.0609 - learning_rate: 1.0000e-04\n",
      "Epoch 63/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9338 - loss: 0.1714 - val_accuracy: 0.9583 - val_loss: 0.0595 - learning_rate: 1.0000e-04\n",
      "Epoch 64/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9357 - loss: 0.1628 - val_accuracy: 0.9542 - val_loss: 0.0606 - learning_rate: 1.0000e-04\n",
      "Epoch 65/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9290 - loss: 0.1763 - val_accuracy: 0.9646 - val_loss: 0.0631 - learning_rate: 1.0000e-04\n",
      "Epoch 66/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9353 - loss: 0.1611 - val_accuracy: 0.9667 - val_loss: 0.0622 - learning_rate: 1.0000e-04\n",
      "Epoch 67/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9368 - loss: 0.1625 - val_accuracy: 0.9542 - val_loss: 0.0614 - learning_rate: 1.0000e-04\n",
      "Epoch 68/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9320 - loss: 0.1723 - val_accuracy: 0.9563 - val_loss: 0.0725 - learning_rate: 1.0000e-04\n",
      "Epoch 69/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9382 - loss: 0.1625 - val_accuracy: 0.9667 - val_loss: 0.0600 - learning_rate: 6.0000e-05\n",
      "Epoch 70/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9412 - loss: 0.1639 - val_accuracy: 0.9625 - val_loss: 0.0497 - learning_rate: 6.0000e-05\n",
      "Epoch 71/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9342 - loss: 0.1690 - val_accuracy: 0.9646 - val_loss: 0.0518 - learning_rate: 6.0000e-05\n",
      "Epoch 72/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9438 - loss: 0.1622 - val_accuracy: 0.9604 - val_loss: 0.0524 - learning_rate: 6.0000e-05\n",
      "Epoch 73/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9298 - loss: 0.1847 - val_accuracy: 0.9563 - val_loss: 0.0630 - learning_rate: 6.0000e-05\n",
      "Epoch 74/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9342 - loss: 0.1704 - val_accuracy: 0.9708 - val_loss: 0.0551 - learning_rate: 6.0000e-05\n",
      "Epoch 75/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9375 - loss: 0.1678 - val_accuracy: 0.9646 - val_loss: 0.0509 - learning_rate: 6.0000e-05\n",
      "Epoch 76/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9364 - loss: 0.1612 - val_accuracy: 0.9583 - val_loss: 0.0549 - learning_rate: 6.0000e-05\n",
      "Epoch 77/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9357 - loss: 0.1719 - val_accuracy: 0.9646 - val_loss: 0.0491 - learning_rate: 6.0000e-05\n",
      "Epoch 78/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9393 - loss: 0.1665 - val_accuracy: 0.9583 - val_loss: 0.0563 - learning_rate: 6.0000e-05\n",
      "Epoch 79/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9305 - loss: 0.1698 - val_accuracy: 0.9604 - val_loss: 0.0551 - learning_rate: 6.0000e-05\n",
      "Epoch 80/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9327 - loss: 0.1698 - val_accuracy: 0.9729 - val_loss: 0.0522 - learning_rate: 6.0000e-05\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\n",
      "===== Fold 5/5 =====\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\M.Elwensh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.6397 - loss: 0.5882 - val_accuracy: 0.4000 - val_loss: 1.1407 - learning_rate: 1.0000e-04\n",
      "Epoch 2/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.7540 - loss: 0.4557 - val_accuracy: 0.4417 - val_loss: 0.8897 - learning_rate: 1.0000e-04\n",
      "Epoch 3/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.7985 - loss: 0.3857 - val_accuracy: 0.8333 - val_loss: 0.2924 - learning_rate: 1.0000e-04\n",
      "Epoch 4/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8430 - loss: 0.3362 - val_accuracy: 0.9229 - val_loss: 0.1831 - learning_rate: 1.0000e-04\n",
      "Epoch 5/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8614 - loss: 0.3114 - val_accuracy: 0.9250 - val_loss: 0.1653 - learning_rate: 1.0000e-04\n",
      "Epoch 6/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8713 - loss: 0.2794 - val_accuracy: 0.9375 - val_loss: 0.1270 - learning_rate: 1.0000e-04\n",
      "Epoch 7/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8768 - loss: 0.2699 - val_accuracy: 0.9250 - val_loss: 0.1506 - learning_rate: 1.0000e-04\n",
      "Epoch 8/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8846 - loss: 0.2478 - val_accuracy: 0.9458 - val_loss: 0.1117 - learning_rate: 1.0000e-04\n",
      "Epoch 9/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8982 - loss: 0.2435 - val_accuracy: 0.9417 - val_loss: 0.1154 - learning_rate: 1.0000e-04\n",
      "Epoch 10/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8963 - loss: 0.2413 - val_accuracy: 0.9417 - val_loss: 0.1170 - learning_rate: 1.0000e-04\n",
      "Epoch 11/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8930 - loss: 0.2362 - val_accuracy: 0.9396 - val_loss: 0.1149 - learning_rate: 1.0000e-04\n",
      "Epoch 12/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9004 - loss: 0.2204 - val_accuracy: 0.9208 - val_loss: 0.1381 - learning_rate: 1.0000e-04\n",
      "Epoch 13/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9228 - loss: 0.2102 - val_accuracy: 0.9250 - val_loss: 0.1308 - learning_rate: 1.0000e-04\n",
      "Epoch 14/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9154 - loss: 0.2105 - val_accuracy: 0.9458 - val_loss: 0.0948 - learning_rate: 1.0000e-04\n",
      "Epoch 15/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9140 - loss: 0.2051 - val_accuracy: 0.9167 - val_loss: 0.1666 - learning_rate: 1.0000e-04\n",
      "Epoch 16/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9217 - loss: 0.2110 - val_accuracy: 0.9521 - val_loss: 0.1007 - learning_rate: 1.0000e-04\n",
      "Epoch 17/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9235 - loss: 0.1969 - val_accuracy: 0.9312 - val_loss: 0.1233 - learning_rate: 1.0000e-04\n",
      "Epoch 18/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9099 - loss: 0.2031 - val_accuracy: 0.9708 - val_loss: 0.0769 - learning_rate: 1.0000e-04\n",
      "Epoch 19/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9324 - loss: 0.1818 - val_accuracy: 0.9375 - val_loss: 0.1191 - learning_rate: 1.0000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9173 - loss: 0.1983 - val_accuracy: 0.9458 - val_loss: 0.0951 - learning_rate: 1.0000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9202 - loss: 0.1852 - val_accuracy: 0.9292 - val_loss: 0.1361 - learning_rate: 1.0000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9287 - loss: 0.1863 - val_accuracy: 0.9625 - val_loss: 0.0741 - learning_rate: 1.0000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9162 - loss: 0.2027 - val_accuracy: 0.9417 - val_loss: 0.1129 - learning_rate: 1.0000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9276 - loss: 0.1761 - val_accuracy: 0.9542 - val_loss: 0.1020 - learning_rate: 1.0000e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9272 - loss: 0.1888 - val_accuracy: 0.9625 - val_loss: 0.0757 - learning_rate: 1.0000e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9272 - loss: 0.1799 - val_accuracy: 0.9438 - val_loss: 0.1169 - learning_rate: 1.0000e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9235 - loss: 0.1809 - val_accuracy: 0.9667 - val_loss: 0.0738 - learning_rate: 1.0000e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9298 - loss: 0.1815 - val_accuracy: 0.9729 - val_loss: 0.0604 - learning_rate: 1.0000e-04\n",
      "Epoch 29/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9243 - loss: 0.1901 - val_accuracy: 0.9729 - val_loss: 0.0649 - learning_rate: 1.0000e-04\n",
      "Epoch 30/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9261 - loss: 0.1924 - val_accuracy: 0.9563 - val_loss: 0.0833 - learning_rate: 1.0000e-04\n",
      "Epoch 31/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9287 - loss: 0.1732 - val_accuracy: 0.9458 - val_loss: 0.1143 - learning_rate: 1.0000e-04\n",
      "Epoch 32/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9353 - loss: 0.1663 - val_accuracy: 0.9625 - val_loss: 0.0666 - learning_rate: 1.0000e-04\n",
      "Epoch 33/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9412 - loss: 0.1697 - val_accuracy: 0.9542 - val_loss: 0.0874 - learning_rate: 1.0000e-04\n",
      "Epoch 34/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9360 - loss: 0.1746 - val_accuracy: 0.9646 - val_loss: 0.0787 - learning_rate: 1.0000e-04\n",
      "Epoch 35/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9283 - loss: 0.1810 - val_accuracy: 0.9604 - val_loss: 0.0845 - learning_rate: 1.0000e-04\n",
      "Epoch 36/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9335 - loss: 0.1817 - val_accuracy: 0.9708 - val_loss: 0.0649 - learning_rate: 1.0000e-04\n",
      "Epoch 37/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9438 - loss: 0.1648 - val_accuracy: 0.9625 - val_loss: 0.0779 - learning_rate: 6.0000e-05\n",
      "Epoch 38/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9379 - loss: 0.1637 - val_accuracy: 0.9708 - val_loss: 0.0549 - learning_rate: 6.0000e-05\n",
      "Epoch 39/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9401 - loss: 0.1684 - val_accuracy: 0.9750 - val_loss: 0.0509 - learning_rate: 6.0000e-05\n",
      "Epoch 40/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9375 - loss: 0.1657 - val_accuracy: 0.9750 - val_loss: 0.0607 - learning_rate: 6.0000e-05\n",
      "Epoch 41/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9360 - loss: 0.1669 - val_accuracy: 0.9729 - val_loss: 0.0580 - learning_rate: 6.0000e-05\n",
      "Epoch 42/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9441 - loss: 0.1611 - val_accuracy: 0.9771 - val_loss: 0.0473 - learning_rate: 6.0000e-05\n",
      "Epoch 43/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9401 - loss: 0.1683 - val_accuracy: 0.9750 - val_loss: 0.0591 - learning_rate: 6.0000e-05\n",
      "Epoch 44/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9338 - loss: 0.1678 - val_accuracy: 0.9792 - val_loss: 0.0509 - learning_rate: 6.0000e-05\n",
      "Epoch 45/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9298 - loss: 0.1678 - val_accuracy: 0.9688 - val_loss: 0.0601 - learning_rate: 6.0000e-05\n",
      "Epoch 46/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9445 - loss: 0.1664 - val_accuracy: 0.9646 - val_loss: 0.0594 - learning_rate: 6.0000e-05\n",
      "Epoch 47/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9390 - loss: 0.1724 - val_accuracy: 0.9667 - val_loss: 0.0681 - learning_rate: 6.0000e-05\n",
      "Epoch 48/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9379 - loss: 0.1625 - val_accuracy: 0.9646 - val_loss: 0.0755 - learning_rate: 6.0000e-05\n",
      "Epoch 49/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9412 - loss: 0.1534 - val_accuracy: 0.9708 - val_loss: 0.0564 - learning_rate: 6.0000e-05\n",
      "Epoch 50/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9415 - loss: 0.1621 - val_accuracy: 0.9750 - val_loss: 0.0469 - learning_rate: 6.0000e-05\n",
      "Epoch 51/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9441 - loss: 0.1541 - val_accuracy: 0.9688 - val_loss: 0.0578 - learning_rate: 6.0000e-05\n",
      "Epoch 52/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9382 - loss: 0.1716 - val_accuracy: 0.9625 - val_loss: 0.0834 - learning_rate: 6.0000e-05\n",
      "Epoch 53/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9371 - loss: 0.1589 - val_accuracy: 0.9646 - val_loss: 0.0611 - learning_rate: 6.0000e-05\n",
      "Epoch 54/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9390 - loss: 0.1584 - val_accuracy: 0.9708 - val_loss: 0.0693 - learning_rate: 6.0000e-05\n",
      "Epoch 55/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9357 - loss: 0.1644 - val_accuracy: 0.9729 - val_loss: 0.0629 - learning_rate: 6.0000e-05\n",
      "Epoch 56/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9390 - loss: 0.1627 - val_accuracy: 0.9771 - val_loss: 0.0460 - learning_rate: 6.0000e-05\n",
      "Epoch 57/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9445 - loss: 0.1628 - val_accuracy: 0.9542 - val_loss: 0.0836 - learning_rate: 6.0000e-05\n",
      "Epoch 58/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9452 - loss: 0.1627 - val_accuracy: 0.9688 - val_loss: 0.0705 - learning_rate: 6.0000e-05\n",
      "Epoch 59/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9460 - loss: 0.1639 - val_accuracy: 0.9729 - val_loss: 0.0586 - learning_rate: 6.0000e-05\n",
      "Epoch 60/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9412 - loss: 0.1575 - val_accuracy: 0.9708 - val_loss: 0.0527 - learning_rate: 6.0000e-05\n",
      "Epoch 61/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9463 - loss: 0.1481 - val_accuracy: 0.9625 - val_loss: 0.0615 - learning_rate: 6.0000e-05\n",
      "Epoch 62/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9460 - loss: 0.1588 - val_accuracy: 0.9750 - val_loss: 0.0575 - learning_rate: 6.0000e-05\n",
      "Epoch 63/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9426 - loss: 0.1558 - val_accuracy: 0.9729 - val_loss: 0.0601 - learning_rate: 6.0000e-05\n",
      "Epoch 64/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9467 - loss: 0.1533 - val_accuracy: 0.9625 - val_loss: 0.0569 - learning_rate: 6.0000e-05\n",
      "Epoch 65/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9419 - loss: 0.1453 - val_accuracy: 0.9750 - val_loss: 0.0501 - learning_rate: 3.6000e-05\n",
      "Epoch 66/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9474 - loss: 0.1584 - val_accuracy: 0.9750 - val_loss: 0.0462 - learning_rate: 3.6000e-05\n",
      "Epoch 67/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9493 - loss: 0.1520 - val_accuracy: 0.9771 - val_loss: 0.0528 - learning_rate: 3.6000e-05\n",
      "Epoch 68/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9441 - loss: 0.1539 - val_accuracy: 0.9688 - val_loss: 0.0477 - learning_rate: 3.6000e-05\n",
      "Epoch 69/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9566 - loss: 0.1470 - val_accuracy: 0.9688 - val_loss: 0.0530 - learning_rate: 3.6000e-05\n",
      "Epoch 70/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9474 - loss: 0.1539 - val_accuracy: 0.9771 - val_loss: 0.0612 - learning_rate: 3.6000e-05\n",
      "Epoch 71/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9522 - loss: 0.1406 - val_accuracy: 0.9750 - val_loss: 0.0519 - learning_rate: 3.6000e-05\n",
      "Epoch 72/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9357 - loss: 0.1631 - val_accuracy: 0.9771 - val_loss: 0.0543 - learning_rate: 3.6000e-05\n",
      "Epoch 73/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9430 - loss: 0.1561 - val_accuracy: 0.9729 - val_loss: 0.0510 - learning_rate: 2.1600e-05\n",
      "Epoch 74/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9415 - loss: 0.1597 - val_accuracy: 0.9729 - val_loss: 0.0529 - learning_rate: 2.1600e-05\n",
      "Epoch 75/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9537 - loss: 0.1474 - val_accuracy: 0.9792 - val_loss: 0.0475 - learning_rate: 2.1600e-05\n",
      "Epoch 76/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9489 - loss: 0.1506 - val_accuracy: 0.9750 - val_loss: 0.0532 - learning_rate: 2.1600e-05\n",
      "Epoch 77/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9478 - loss: 0.1443 - val_accuracy: 0.9708 - val_loss: 0.0546 - learning_rate: 2.1600e-05\n",
      "Epoch 78/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9423 - loss: 0.1541 - val_accuracy: 0.9792 - val_loss: 0.0432 - learning_rate: 2.1600e-05\n",
      "Epoch 79/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9474 - loss: 0.1467 - val_accuracy: 0.9729 - val_loss: 0.0581 - learning_rate: 2.1600e-05\n",
      "Epoch 80/80\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9507 - loss: 0.1492 - val_accuracy: 0.9729 - val_loss: 0.0608 - learning_rate: 2.1600e-05\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\n",
      "==============================\n",
      "TRAINING COMPLETED SUCCESSFULLY\n",
      "ALL RESULTS SAVED IN results/\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model # type: ignore\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dense, Dropout, BatchNormalization, MaxPooling1D, GlobalAveragePooling1D, LeakyReLU # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint # type: ignore\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "import tensorflow.keras.backend as K # type: ignore\n",
    "\n",
    "# ===================== GPU SETUP =====================\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print(\"Using GPU:\", gpus[0])\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")\n",
    "\n",
    "# ===================== PATHS =====================\n",
    "DATA_DIR = r\"D:/FCIS Content/Fourth year/GP/GP-Epileptic-seizures/Preprocessing_Updated_Kfold\"\n",
    "RESULTS_DIR = \"results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "N_FOLDS = 5\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "summary_path = os.path.join(RESULTS_DIR, \"accuracy_summary.txt\")\n",
    "with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Accuracy Summary per Fold\\n\")\n",
    "    f.write(\"=\"*40 + \"\\n\\n\")\n",
    "\n",
    "# ===================== DATA AUGMENTATION =====================\n",
    "def augment_signal(segment, prob=0.5):\n",
    "    if np.random.rand() > prob: return segment\n",
    "    aug_type = np.random.choice(['noise','scale','shift','time_shift'], p=[0.3,0.3,0.2,0.2])\n",
    "    if aug_type == 'noise': return segment + np.random.normal(0, np.random.uniform(0.01,0.05), segment.shape)\n",
    "    if aug_type == 'scale': return segment * np.random.uniform(0.9,1.1)\n",
    "    if aug_type == 'shift': return segment + np.random.uniform(-0.1,0.1)\n",
    "    if aug_type == 'time_shift': return np.roll(segment, np.random.randint(-20,20))\n",
    "    return segment\n",
    "\n",
    "def mixup(X1, y1, X2, y2, alpha=0.2):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    return lam*X1 + (1-lam)*X2, lam*y1 + (1-lam)*y2\n",
    "\n",
    "def augment_batch(X, y, prob=0.6):\n",
    "    X_aug = X.copy()\n",
    "    y_aug = y.copy()\n",
    "    for i in range(len(X_aug)):\n",
    "        p = prob * 1.5 if np.argmax(y_aug[i]) != 0 else prob\n",
    "        X_aug[i,:,0] = augment_signal(X_aug[i,:,0], p)\n",
    "    for i in range(len(X_aug)//2):\n",
    "        j = np.random.randint(len(X_aug))\n",
    "        X_aug[i,:,0], y_aug[i] = mixup(X_aug[i,:,0], y_aug[i], X_aug[j,:,0], y_aug[j])\n",
    "    return X_aug, y_aug\n",
    "\n",
    "class AugmentedGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X, y, batch_size=16, prob=0.6):\n",
    "        self.X, self.y = X, y\n",
    "        self.bs = batch_size\n",
    "        self.prob = prob\n",
    "        self.idx = np.arange(len(X))\n",
    "    def __len__(self): return int(np.ceil(len(self.X)/self.bs))\n",
    "    def on_epoch_end(self): np.random.shuffle(self.idx)\n",
    "    def __getitem__(self, i):\n",
    "        batch_idx = self.idx[i*self.bs:(i+1)*self.bs]\n",
    "        Xb, yb = self.X[batch_idx], self.y[batch_idx]\n",
    "        Xb, yb = augment_batch(Xb, yb, self.prob)\n",
    "        return Xb, yb\n",
    "\n",
    "# ===================== HYBRID FOCAL LOSS =====================\n",
    "def hybrid_focal_loss(alpha=[1,1.5,2], gamma=1.5):\n",
    "    alpha = K.constant(alpha, dtype=K.floatx())\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1-K.epsilon())\n",
    "        ce = -y_true * K.log(y_pred)\n",
    "        focal = (1 - y_pred) ** gamma\n",
    "        return K.mean(K.sum(alpha * focal * ce, axis=-1))\n",
    "    return loss\n",
    "\n",
    "# ===================== MODEL =====================\n",
    "def build_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for filters, k, d in [(64,7,0.3),(128,5,0.3),(256,3,0.4)]:\n",
    "        x = Conv1D(filters, k, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.1)(x)\n",
    "        x = MaxPooling1D(2)(x)\n",
    "        x = Dropout(d)(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# ===================== PAD SEGMENTS =====================\n",
    "def pad_segments(X_list):\n",
    "    \"\"\" Pad all segments in a fold to the same length \"\"\"\n",
    "    cleaned_segments = []\n",
    "    for x in X_list:\n",
    "        x = np.array(x)  # Ensure it's a numpy array\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(1, -1)  # Convert 1D to 2D (1, length)\n",
    "        cleaned_segments.append(x)\n",
    "    \n",
    "    # Find max length\n",
    "    max_len = max(seg.shape[1] for seg in cleaned_segments)\n",
    "    \n",
    "    # Pad each segment to max length\n",
    "    padded_segments = []\n",
    "    for seg in cleaned_segments:\n",
    "        pad_width = max_len - seg.shape[1]\n",
    "        if pad_width > 0:\n",
    "            seg_padded = np.pad(seg, ((0,0),(0,pad_width)), mode='constant')\n",
    "        else:\n",
    "            seg_padded = seg\n",
    "        padded_segments.append(seg_padded)\n",
    "    \n",
    "    return np.vstack(padded_segments)\n",
    "\n",
    "# ===================== TRAINING =====================\n",
    "acc_folds, auc_folds, conf_matrices = [], [], []\n",
    "fold_indices_list = []\n",
    "\n",
    "for fold in range(N_FOLDS):\n",
    "    print(f\"\\n===== Fold {fold+1}/{N_FOLDS} =====\")\n",
    "    \n",
    "    # Load data with allow_pickle\n",
    "    X_train = np.load(os.path.join(DATA_DIR,f\"fold_{fold}_X_train.npy\"), allow_pickle=True)\n",
    "    X_test  = np.load(os.path.join(DATA_DIR,f\"fold_{fold}_X_test.npy\"),  allow_pickle=True)\n",
    "    y_train = np.load(os.path.join(DATA_DIR,f\"fold_{fold}_y_train.npy\"), allow_pickle=True)\n",
    "    y_test  = np.load(os.path.join(DATA_DIR,f\"fold_{fold}_y_test.npy\"), allow_pickle=True)\n",
    "\n",
    "    # Pad segments to same length\n",
    "    X_train = pad_segments(X_train)[..., None].astype(np.float32)\n",
    "    X_test  = pad_segments(X_test)[..., None].astype(np.float32)\n",
    "\n",
    "    fold_indices_list.append((y_train.copy(), y_test.copy()))\n",
    "    \n",
    "    # One-hot encoding\n",
    "    y_train_cat = to_categorical(y_train, NUM_CLASSES)\n",
    "    y_test_cat  = to_categorical(y_test, NUM_CLASSES)\n",
    "    \n",
    "    # Train-validation split\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train_cat, test_size=0.15, stratify=y_train, random_state=42)\n",
    "    \n",
    "    # Class weights\n",
    "    cw = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "    class_weight = {i:w for i,w in enumerate(cw)}\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model((X_train.shape[1],1))\n",
    "    model.compile(Adam(1e-4), loss=hybrid_focal_loss(), metrics=['accuracy'])\n",
    "    \n",
    "    # Training\n",
    "    history = model.fit(\n",
    "        AugmentedGenerator(X_tr, y_tr),\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=80,\n",
    "        callbacks=[\n",
    "            EarlyStopping(patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(patience=8, factor=0.6, min_lr=1e-7),\n",
    "            ModelCheckpoint(f\"{RESULTS_DIR}/model_fold{fold+1}.weights.h5\", save_best_only=True, save_weights_only=True)\n",
    "        ],\n",
    "        class_weight=class_weight,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Load best weights\n",
    "    model.load_weights(f\"{RESULTS_DIR}/model_fold{fold+1}.weights.h5\")\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    \n",
    "    acc = np.mean(y_pred == y_test)\n",
    "    auc = roc_auc_score(y_test_cat, y_pred_prob, multi_class='ovr')\n",
    "    \n",
    "    acc_folds.append(acc)\n",
    "    auc_folds.append(auc)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrices.append(cm)\n",
    "    \n",
    "    # Plot fold confusion matrix\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Fold {fold+1} Confusion Matrix | ACC={acc:.3f}\")\n",
    "    plt.savefig(f\"{RESULTS_DIR}/confusion_fold{fold+1}.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    with open(summary_path,\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Fold {fold+1}: ACC={acc:.4f}, AUC={auc:.4f}\\n\")\n",
    "\n",
    "# ===================== TOTAL RESULTS =====================\n",
    "total_cm = np.sum(conf_matrices, axis=0)\n",
    "mean_acc = np.mean(acc_folds)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(total_cm, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(f\"Total Confusion Matrix | Mean ACC={mean_acc:.3f}\")\n",
    "plt.savefig(f\"{RESULTS_DIR}/confusion_total.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "with open(summary_path,\"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "    f.write(f\"Mean ACC: {mean_acc:.4f}\\n\")\n",
    "    f.write(f\"Mean AUC: {np.mean(auc_folds):.4f}\\n\")\n",
    "\n",
    "# Save fold indices\n",
    "np.save(os.path.join(RESULTS_DIR,\"fold_indices.npy\"), np.array(fold_indices_list, dtype=object))\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"TRAINING COMPLETED SUCCESSFULLY\")\n",
    "print(\"ALL RESULTS SAVED IN results/\")\n",
    "print(\"==============================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d9036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "No GPU detected. Using CPU.\n",
      "\n",
      "========== FOLD 1 ==========\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\M.Elwensh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 99ms/step - accuracy: 0.7890 - loss: 0.9466 - val_accuracy: 0.6000 - val_loss: 1.2878 - learning_rate: 2.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8062 - loss: 0.8736 - val_accuracy: 0.9229 - val_loss: 0.7926 - learning_rate: 2.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8305 - loss: 0.7981 - val_accuracy: 0.9479 - val_loss: 0.6649 - learning_rate: 2.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8309 - loss: 0.7804 - val_accuracy: 0.9500 - val_loss: 0.7459 - learning_rate: 2.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8199 - loss: 0.8169 - val_accuracy: 0.9688 - val_loss: 0.6746 - learning_rate: 2.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8265 - loss: 0.7844 - val_accuracy: 0.9646 - val_loss: 0.7332 - learning_rate: 2.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 131ms/step - accuracy: 0.8298 - loss: 0.7604 - val_accuracy: 0.8875 - val_loss: 0.8448 - learning_rate: 2.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8327 - loss: 0.7707 - val_accuracy: 0.9646 - val_loss: 0.4026 - learning_rate: 2.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8346 - loss: 0.7445 - val_accuracy: 0.8917 - val_loss: 0.7847 - learning_rate: 2.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8228 - loss: 0.7685 - val_accuracy: 0.9646 - val_loss: 0.5921 - learning_rate: 2.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8441 - loss: 0.7281 - val_accuracy: 0.9583 - val_loss: 0.6191 - learning_rate: 2.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8397 - loss: 0.7262 - val_accuracy: 0.9750 - val_loss: 0.3779 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8393 - loss: 0.7330 - val_accuracy: 0.9729 - val_loss: 0.5315 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8327 - loss: 0.7373 - val_accuracy: 0.9417 - val_loss: 0.5482 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8360 - loss: 0.7527 - val_accuracy: 0.9750 - val_loss: 0.4881 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8463 - loss: 0.7043 - val_accuracy: 0.8104 - val_loss: 0.9562 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8478 - loss: 0.6950 - val_accuracy: 0.9375 - val_loss: 0.5817 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8445 - loss: 0.7069 - val_accuracy: 0.9750 - val_loss: 0.4805 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8419 - loss: 0.6940 - val_accuracy: 0.9708 - val_loss: 0.5530 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8438 - loss: 0.7106 - val_accuracy: 0.9708 - val_loss: 0.5496 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8518 - loss: 0.6704 - val_accuracy: 0.9625 - val_loss: 0.4830 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8445 - loss: 0.6889 - val_accuracy: 0.9396 - val_loss: 0.5810 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8559 - loss: 0.6642 - val_accuracy: 0.9521 - val_loss: 0.5874 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8610 - loss: 0.6429 - val_accuracy: 0.9312 - val_loss: 0.6277 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8419 - loss: 0.6921 - val_accuracy: 0.9875 - val_loss: 0.4703 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8673 - loss: 0.6316 - val_accuracy: 0.9438 - val_loss: 0.5612 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8515 - loss: 0.6845 - val_accuracy: 0.9708 - val_loss: 0.5506 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8640 - loss: 0.6446 - val_accuracy: 0.9250 - val_loss: 0.6509 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8603 - loss: 0.6341 - val_accuracy: 0.9750 - val_loss: 0.4709 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8585 - loss: 0.6488 - val_accuracy: 0.8917 - val_loss: 0.7583 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8647 - loss: 0.6540 - val_accuracy: 0.9854 - val_loss: 0.5207 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8669 - loss: 0.6083 - val_accuracy: 0.9771 - val_loss: 0.4620 - learning_rate: 1.0000e-04\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "Fold 1 | ACC=0.9825 | AUC=0.9991\n",
      "\n",
      "========== FOLD 2 ==========\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\M.Elwensh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 77ms/step - accuracy: 0.7511 - loss: 1.0345 - val_accuracy: 0.6000 - val_loss: 1.2692 - learning_rate: 2.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.7963 - loss: 0.8903 - val_accuracy: 0.8813 - val_loss: 0.8925 - learning_rate: 2.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8279 - loss: 0.8156 - val_accuracy: 0.9146 - val_loss: 0.8607 - learning_rate: 2.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8287 - loss: 0.7685 - val_accuracy: 0.9604 - val_loss: 0.4309 - learning_rate: 2.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 143ms/step - accuracy: 0.8324 - loss: 0.7576 - val_accuracy: 0.9271 - val_loss: 0.7440 - learning_rate: 2.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 274ms/step - accuracy: 0.8316 - loss: 0.7621 - val_accuracy: 0.8958 - val_loss: 0.7896 - learning_rate: 2.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 279ms/step - accuracy: 0.8316 - loss: 0.7598 - val_accuracy: 0.9187 - val_loss: 0.6574 - learning_rate: 2.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 222ms/step - accuracy: 0.8434 - loss: 0.7196 - val_accuracy: 0.9312 - val_loss: 0.7137 - learning_rate: 2.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 0.8482 - loss: 0.7161 - val_accuracy: 0.8458 - val_loss: 1.1684 - learning_rate: 2.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8434 - loss: 0.7405 - val_accuracy: 0.9750 - val_loss: 0.4505 - learning_rate: 2.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8419 - loss: 0.7328 - val_accuracy: 0.9542 - val_loss: 0.5615 - learning_rate: 2.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8243 - loss: 0.7769 - val_accuracy: 0.9187 - val_loss: 0.6627 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8441 - loss: 0.7180 - val_accuracy: 0.7729 - val_loss: 1.0403 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8401 - loss: 0.7482 - val_accuracy: 0.9542 - val_loss: 0.4349 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8537 - loss: 0.6853 - val_accuracy: 0.8667 - val_loss: 0.8245 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8316 - loss: 0.7361 - val_accuracy: 0.9396 - val_loss: 0.5753 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8540 - loss: 0.6809 - val_accuracy: 0.9229 - val_loss: 0.6583 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8471 - loss: 0.6768 - val_accuracy: 0.9083 - val_loss: 0.6992 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8566 - loss: 0.6752 - val_accuracy: 0.9625 - val_loss: 0.5515 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8610 - loss: 0.6492 - val_accuracy: 0.7917 - val_loss: 1.0986 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8500 - loss: 0.6731 - val_accuracy: 0.8667 - val_loss: 0.8347 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8581 - loss: 0.6627 - val_accuracy: 0.8938 - val_loss: 0.8312 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8507 - loss: 0.6800 - val_accuracy: 0.7604 - val_loss: 1.3351 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8518 - loss: 0.6592 - val_accuracy: 0.7333 - val_loss: 1.4360 - learning_rate: 1.0000e-04\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "Fold 2 | ACC=0.9387 | AUC=0.9845\n",
      "\n",
      "========== FOLD 3 ==========\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\M.Elwensh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 77ms/step - accuracy: 0.7827 - loss: 0.9634 - val_accuracy: 0.6021 - val_loss: 1.2699 - learning_rate: 2.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8195 - loss: 0.8314 - val_accuracy: 0.9083 - val_loss: 0.9187 - learning_rate: 2.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8265 - loss: 0.7948 - val_accuracy: 0.9438 - val_loss: 0.7781 - learning_rate: 2.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8279 - loss: 0.7843 - val_accuracy: 0.7542 - val_loss: 1.4370 - learning_rate: 2.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8254 - loss: 0.7981 - val_accuracy: 0.9292 - val_loss: 0.7005 - learning_rate: 2.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8276 - loss: 0.7967 - val_accuracy: 0.9667 - val_loss: 0.4654 - learning_rate: 2.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8283 - loss: 0.7744 - val_accuracy: 0.9000 - val_loss: 0.8332 - learning_rate: 2.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8404 - loss: 0.7285 - val_accuracy: 0.9396 - val_loss: 0.6226 - learning_rate: 2.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8335 - loss: 0.7583 - val_accuracy: 0.9604 - val_loss: 0.5594 - learning_rate: 2.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8449 - loss: 0.7214 - val_accuracy: 0.8625 - val_loss: 0.9710 - learning_rate: 2.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8379 - loss: 0.7359 - val_accuracy: 0.9604 - val_loss: 0.5105 - learning_rate: 2.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8434 - loss: 0.7123 - val_accuracy: 0.8896 - val_loss: 0.8807 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8386 - loss: 0.7355 - val_accuracy: 0.9333 - val_loss: 0.6460 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8386 - loss: 0.7181 - val_accuracy: 0.9312 - val_loss: 0.6570 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8511 - loss: 0.6952 - val_accuracy: 0.9646 - val_loss: 0.3874 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8518 - loss: 0.6852 - val_accuracy: 0.9417 - val_loss: 0.7616 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8393 - loss: 0.7246 - val_accuracy: 0.8833 - val_loss: 0.8999 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8588 - loss: 0.6629 - val_accuracy: 0.9604 - val_loss: 0.5668 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8474 - loss: 0.7023 - val_accuracy: 0.9604 - val_loss: 0.4651 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8599 - loss: 0.6650 - val_accuracy: 0.9625 - val_loss: 0.4518 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8393 - loss: 0.6925 - val_accuracy: 0.9667 - val_loss: 0.5140 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 0.8482 - loss: 0.6956 - val_accuracy: 0.9354 - val_loss: 0.5959 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8522 - loss: 0.6813 - val_accuracy: 0.9646 - val_loss: 0.5825 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8415 - loss: 0.7174 - val_accuracy: 0.9187 - val_loss: 0.6387 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 79ms/step - accuracy: 0.8493 - loss: 0.6859 - val_accuracy: 0.9000 - val_loss: 0.6671 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m793s\u001b[0m 5s/step - accuracy: 0.8596 - loss: 0.6506 - val_accuracy: 0.9354 - val_loss: 0.6384 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 0.8493 - loss: 0.6815 - val_accuracy: 0.9229 - val_loss: 0.6905 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.8603 - loss: 0.6564 - val_accuracy: 0.9167 - val_loss: 0.7163 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.8669 - loss: 0.6300 - val_accuracy: 0.9708 - val_loss: 0.5009 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.8680 - loss: 0.6186 - val_accuracy: 0.9208 - val_loss: 0.7138 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 0.8676 - loss: 0.6214 - val_accuracy: 0.9333 - val_loss: 0.6236 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 0.8702 - loss: 0.6125 - val_accuracy: 0.9229 - val_loss: 0.6502 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 0.8562 - loss: 0.6458 - val_accuracy: 0.9854 - val_loss: 0.4489 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 0.8614 - loss: 0.6520 - val_accuracy: 0.8625 - val_loss: 0.8238 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8625 - loss: 0.6474 - val_accuracy: 0.9312 - val_loss: 0.5563 - learning_rate: 1.0000e-04\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "Fold 3 | ACC=0.9675 | AUC=0.9922\n",
      "\n",
      "========== FOLD 4 ==========\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\M.Elwensh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 76ms/step - accuracy: 0.7551 - loss: 1.0379 - val_accuracy: 0.6000 - val_loss: 1.2347 - learning_rate: 2.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8158 - loss: 0.8460 - val_accuracy: 0.9208 - val_loss: 0.9911 - learning_rate: 2.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8176 - loss: 0.8263 - val_accuracy: 0.9229 - val_loss: 0.8090 - learning_rate: 2.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8103 - loss: 0.8408 - val_accuracy: 0.8667 - val_loss: 0.8969 - learning_rate: 2.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8254 - loss: 0.8088 - val_accuracy: 0.9292 - val_loss: 0.5862 - learning_rate: 2.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8268 - loss: 0.7909 - val_accuracy: 0.8438 - val_loss: 0.8642 - learning_rate: 2.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8456 - loss: 0.7254 - val_accuracy: 0.8958 - val_loss: 0.7901 - learning_rate: 2.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8349 - loss: 0.7351 - val_accuracy: 0.9229 - val_loss: 0.6446 - learning_rate: 2.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8294 - loss: 0.7624 - val_accuracy: 0.9479 - val_loss: 0.6705 - learning_rate: 2.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8426 - loss: 0.7188 - val_accuracy: 0.8896 - val_loss: 0.8049 - learning_rate: 2.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8426 - loss: 0.7608 - val_accuracy: 0.9500 - val_loss: 0.6674 - learning_rate: 2.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 79ms/step - accuracy: 0.8360 - loss: 0.7237 - val_accuracy: 0.9646 - val_loss: 0.6640 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 79ms/step - accuracy: 0.8364 - loss: 0.7331 - val_accuracy: 0.9417 - val_loss: 0.6655 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 79ms/step - accuracy: 0.8463 - loss: 0.7172 - val_accuracy: 0.9187 - val_loss: 0.7421 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8478 - loss: 0.7218 - val_accuracy: 0.9604 - val_loss: 0.6572 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 3s/step - accuracy: 0.8526 - loss: 0.6770 - val_accuracy: 0.9438 - val_loss: 0.6666 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 166ms/step - accuracy: 0.8423 - loss: 0.7126 - val_accuracy: 0.8521 - val_loss: 0.9716 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 133ms/step - accuracy: 0.8559 - loss: 0.6620 - val_accuracy: 0.9125 - val_loss: 0.7093 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.8474 - loss: 0.6736 - val_accuracy: 0.8958 - val_loss: 0.8117 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8691 - loss: 0.6258 - val_accuracy: 0.9521 - val_loss: 0.5761 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8529 - loss: 0.6752 - val_accuracy: 0.9521 - val_loss: 0.6226 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8507 - loss: 0.6888 - val_accuracy: 0.9167 - val_loss: 0.7518 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 102ms/step - accuracy: 0.8610 - loss: 0.6364 - val_accuracy: 0.9583 - val_loss: 0.5587 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8507 - loss: 0.6626 - val_accuracy: 0.9438 - val_loss: 0.6867 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8515 - loss: 0.6619 - val_accuracy: 0.9479 - val_loss: 0.6543 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8614 - loss: 0.6523 - val_accuracy: 0.9417 - val_loss: 0.6681 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8570 - loss: 0.6785 - val_accuracy: 0.9667 - val_loss: 0.5354 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8596 - loss: 0.6537 - val_accuracy: 0.9729 - val_loss: 0.5893 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8713 - loss: 0.6131 - val_accuracy: 0.9708 - val_loss: 0.4852 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 0.8581 - loss: 0.6485 - val_accuracy: 0.9396 - val_loss: 0.6418 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.8496 - loss: 0.6817 - val_accuracy: 0.9438 - val_loss: 0.6966 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8651 - loss: 0.6266 - val_accuracy: 0.9104 - val_loss: 0.7459 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8518 - loss: 0.6764 - val_accuracy: 0.9771 - val_loss: 0.4951 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 0.8651 - loss: 0.6351 - val_accuracy: 0.9542 - val_loss: 0.5476 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8695 - loss: 0.6223 - val_accuracy: 0.9167 - val_loss: 0.6865 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 82ms/step - accuracy: 0.8636 - loss: 0.6282 - val_accuracy: 0.9438 - val_loss: 0.6505 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step - accuracy: 0.8526 - loss: 0.6492 - val_accuracy: 0.9500 - val_loss: 0.6725 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step - accuracy: 0.8618 - loss: 0.6265 - val_accuracy: 0.9667 - val_loss: 0.5275 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 82ms/step - accuracy: 0.8518 - loss: 0.6647 - val_accuracy: 0.9750 - val_loss: 0.5780 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step - accuracy: 0.8629 - loss: 0.6237 - val_accuracy: 0.9646 - val_loss: 0.6461 - learning_rate: 5.0000e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 82ms/step - accuracy: 0.8721 - loss: 0.6047 - val_accuracy: 0.9521 - val_loss: 0.5995 - learning_rate: 5.0000e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step - accuracy: 0.8768 - loss: 0.5893 - val_accuracy: 0.9688 - val_loss: 0.5665 - learning_rate: 5.0000e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 85ms/step - accuracy: 0.8827 - loss: 0.5663 - val_accuracy: 0.8833 - val_loss: 0.7968 - learning_rate: 5.0000e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 89ms/step - accuracy: 0.8779 - loss: 0.5692 - val_accuracy: 0.9500 - val_loss: 0.5641 - learning_rate: 5.0000e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 86ms/step - accuracy: 0.8813 - loss: 0.5914 - val_accuracy: 0.9688 - val_loss: 0.5382 - learning_rate: 5.0000e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 88ms/step - accuracy: 0.8809 - loss: 0.5639 - val_accuracy: 0.9229 - val_loss: 0.6706 - learning_rate: 5.0000e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 88ms/step - accuracy: 0.8603 - loss: 0.6375 - val_accuracy: 0.8646 - val_loss: 0.8832 - learning_rate: 5.0000e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 89ms/step - accuracy: 0.8640 - loss: 0.6155 - val_accuracy: 0.9458 - val_loss: 0.6133 - learning_rate: 5.0000e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.8732 - loss: 0.6057 - val_accuracy: 0.9479 - val_loss: 0.6093 - learning_rate: 5.0000e-05\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n",
      "Fold 4 | ACC=0.9888 | AUC=0.9988\n",
      "\n",
      "========== FOLD 5 ==========\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\M.Elwensh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.7651 - loss: 0.9992 - val_accuracy: 0.8188 - val_loss: 1.2642 - learning_rate: 2.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 88ms/step - accuracy: 0.8136 - loss: 0.8286 - val_accuracy: 0.9187 - val_loss: 1.0512 - learning_rate: 2.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 86ms/step - accuracy: 0.8243 - loss: 0.8083 - val_accuracy: 0.8375 - val_loss: 1.0184 - learning_rate: 2.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step - accuracy: 0.8140 - loss: 0.8047 - val_accuracy: 0.9062 - val_loss: 0.7664 - learning_rate: 2.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step - accuracy: 0.8371 - loss: 0.7314 - val_accuracy: 0.9312 - val_loss: 0.7075 - learning_rate: 2.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1192s\u001b[0m 7s/step - accuracy: 0.8320 - loss: 0.7560 - val_accuracy: 0.8188 - val_loss: 1.1019 - learning_rate: 2.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.8485 - loss: 0.7368 - val_accuracy: 0.8687 - val_loss: 0.9564 - learning_rate: 2.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8246 - loss: 0.7668 - val_accuracy: 0.8188 - val_loss: 1.0964 - learning_rate: 2.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8434 - loss: 0.7204 - val_accuracy: 0.9083 - val_loss: 0.8932 - learning_rate: 2.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8467 - loss: 0.6970 - val_accuracy: 0.8417 - val_loss: 0.9686 - learning_rate: 2.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8456 - loss: 0.7106 - val_accuracy: 0.9292 - val_loss: 0.7108 - learning_rate: 2.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8647 - loss: 0.6682 - val_accuracy: 0.9146 - val_loss: 0.7884 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8371 - loss: 0.7272 - val_accuracy: 0.9542 - val_loss: 0.6763 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8496 - loss: 0.6803 - val_accuracy: 0.8458 - val_loss: 0.9148 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8449 - loss: 0.6964 - val_accuracy: 0.9729 - val_loss: 0.4723 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8485 - loss: 0.6746 - val_accuracy: 0.8729 - val_loss: 0.8909 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8504 - loss: 0.6847 - val_accuracy: 0.9375 - val_loss: 0.7138 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8375 - loss: 0.7090 - val_accuracy: 0.8687 - val_loss: 0.9410 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8555 - loss: 0.6732 - val_accuracy: 0.7333 - val_loss: 1.2196 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8566 - loss: 0.6548 - val_accuracy: 0.8792 - val_loss: 0.8129 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8551 - loss: 0.6611 - val_accuracy: 0.9250 - val_loss: 0.6044 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8449 - loss: 0.6797 - val_accuracy: 0.9521 - val_loss: 0.6831 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8603 - loss: 0.6320 - val_accuracy: 0.9833 - val_loss: 0.4653 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8702 - loss: 0.6231 - val_accuracy: 0.9604 - val_loss: 0.5998 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8574 - loss: 0.6537 - val_accuracy: 0.9792 - val_loss: 0.4093 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 115ms/step - accuracy: 0.8632 - loss: 0.6424 - val_accuracy: 0.9021 - val_loss: 0.7574 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 114ms/step - accuracy: 0.8599 - loss: 0.6480 - val_accuracy: 0.9354 - val_loss: 0.6273 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8651 - loss: 0.6226 - val_accuracy: 0.9250 - val_loss: 0.7016 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8574 - loss: 0.6483 - val_accuracy: 0.9229 - val_loss: 0.6600 - learning_rate: 2.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8511 - loss: 0.6824 - val_accuracy: 0.9208 - val_loss: 0.6673 - learning_rate: 2.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8669 - loss: 0.6333 - val_accuracy: 0.9042 - val_loss: 0.6858 - learning_rate: 2.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.8621 - loss: 0.6553 - val_accuracy: 0.9812 - val_loss: 0.4375 - learning_rate: 2.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8676 - loss: 0.6262 - val_accuracy: 0.9417 - val_loss: 0.5518 - learning_rate: 2.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8599 - loss: 0.6304 - val_accuracy: 0.9604 - val_loss: 0.5290 - learning_rate: 2.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8695 - loss: 0.6054 - val_accuracy: 0.9438 - val_loss: 0.5548 - learning_rate: 2.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8643 - loss: 0.6229 - val_accuracy: 0.9729 - val_loss: 0.5435 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8820 - loss: 0.5784 - val_accuracy: 0.9604 - val_loss: 0.5749 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8750 - loss: 0.5911 - val_accuracy: 0.9667 - val_loss: 0.5486 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8776 - loss: 0.5768 - val_accuracy: 0.9583 - val_loss: 0.5578 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8732 - loss: 0.6010 - val_accuracy: 0.8479 - val_loss: 0.8845 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8831 - loss: 0.5802 - val_accuracy: 0.9500 - val_loss: 0.5735 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8724 - loss: 0.5865 - val_accuracy: 0.9688 - val_loss: 0.4861 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8695 - loss: 0.6002 - val_accuracy: 0.8854 - val_loss: 0.7741 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.8757 - loss: 0.5734 - val_accuracy: 0.9604 - val_loss: 0.5683 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.8849 - loss: 0.5513 - val_accuracy: 0.9646 - val_loss: 0.5442 - learning_rate: 1.0000e-04\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
      "Fold 5 | ACC=0.9275 | AUC=0.9776\n",
      "\n",
      "==============================\n",
      " BINARY TRAINING COMPLETED \n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model # type: ignore\n",
    "from tensorflow.keras.layers import ( # type: ignore\n",
    "    Input, Conv1D, Dense, Dropout, BatchNormalization,\n",
    "    MaxPooling1D, GlobalAveragePooling1D, Add, Activation\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint # type: ignore\n",
    "from tensorflow.keras.optimizers import AdamW # type: ignore\n",
    "\n",
    "# =============================================================\n",
    "#                 DEVICE INFO\n",
    "# =============================================================\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print(\"GPU detected:\", gpus)\n",
    "else:\n",
    "    print(\"No GPU detected. Using CPU.\")\n",
    "\n",
    "# =============================================================\n",
    "#                RESULTS DIRECTORY\n",
    "# =============================================================\n",
    "results_dir = \"results_binary_fixed\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "summary_path = os.path.join(results_dir, \"accuracy_summary.txt\")\n",
    "\n",
    "with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"BINARY (NORMAL vs ALL) – FIXED PREPROCESSING\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "\n",
    "# =============================================================\n",
    "#                  PAD SEGMENTS (FROM 3-CLASS CODE)\n",
    "# =============================================================\n",
    "def pad_segments(X_list):\n",
    "    cleaned = []\n",
    "    for x in X_list:\n",
    "        x = np.array(x)\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "        cleaned.append(x)\n",
    "\n",
    "    max_len = max(seg.shape[1] for seg in cleaned)\n",
    "\n",
    "    padded = []\n",
    "    for seg in cleaned:\n",
    "        pad_width = max_len - seg.shape[1]\n",
    "        if pad_width > 0:\n",
    "            seg = np.pad(seg, ((0,0),(0,pad_width)), mode=\"constant\")\n",
    "        padded.append(seg)\n",
    "\n",
    "    return np.vstack(padded)\n",
    "\n",
    "# =============================================================\n",
    "#                MULTI → BINARY LABELS (HELPERS)\n",
    "# =============================================================\n",
    "DATA_DIR = r\"Preprocessing_Updated_Kfold\"\n",
    "\n",
    "# =============================================================\n",
    "#                    DATA AUGMENTATION\n",
    "# =============================================================\n",
    "def augment_signal(seg, p=0.5):\n",
    "    if np.random.rand() > p:\n",
    "        return seg\n",
    "    choice = np.random.choice(['noise', 'scale', 'shift', 'roll'])\n",
    "    if choice == 'noise':\n",
    "        return seg + np.random.normal(0, np.random.uniform(0.01,0.05), seg.shape)\n",
    "    if choice == 'scale':\n",
    "        return seg * np.random.uniform(0.9, 1.1)\n",
    "    if choice == 'shift':\n",
    "        return seg + np.random.uniform(-0.1, 0.1)\n",
    "    if choice == 'roll':\n",
    "        return np.roll(seg, np.random.randint(-20,20))\n",
    "    return seg\n",
    "\n",
    "def mixup_binary(x1, y1, x2, y2, alpha=0.2):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    return lam*x1 + (1-lam)*x2, lam*y1 + (1-lam)*y2\n",
    "\n",
    "class AugGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X, y, batch=16, p=0.6):\n",
    "        self.X, self.y = X, y\n",
    "        self.batch = batch\n",
    "        self.p = p\n",
    "        self.idx = np.arange(len(X))\n",
    "        np.random.shuffle(self.idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X)/self.batch))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.idx)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        ids = self.idx[i*self.batch:(i+1)*self.batch]\n",
    "        Xb = self.X[ids].copy()\n",
    "        yb = self.y[ids].copy()\n",
    "\n",
    "        for k in range(len(Xb)):\n",
    "            prob = self.p*0.4 if yb[k]==0 else self.p*1.2\n",
    "            Xb[k,:,0] = augment_signal(Xb[k,:,0], prob)\n",
    "\n",
    "        for k in range(len(Xb)//2):\n",
    "            j = np.random.randint(len(Xb))\n",
    "            Xb[k,:,0], yb[k] = mixup_binary(\n",
    "                Xb[k,:,0], yb[k],\n",
    "                Xb[j,:,0], yb[j]\n",
    "            )\n",
    "\n",
    "        return Xb, yb\n",
    "\n",
    "# =============================================================\n",
    "#                    WEIGHTED BCE\n",
    "# =============================================================\n",
    "def weighted_bce(w_pos=2.8, w_neg=1.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        weights = y_true * w_pos + (1 - y_true) * w_neg\n",
    "        return tf.reduce_mean(weights * bce)\n",
    "    return loss\n",
    "\n",
    "# =============================================================\n",
    "#                    RESIDUAL MODEL\n",
    "# =============================================================\n",
    "def res_block(x, filters):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters,3,padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv1D(filters,3,padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters,1,padding=\"same\")(shortcut)\n",
    "\n",
    "    x = Add()([x, shortcut])\n",
    "    return Activation(\"relu\")(x)\n",
    "\n",
    "def build_model(input_shape):\n",
    "    inp = Input(input_shape)\n",
    "\n",
    "    x = Conv1D(64,7,padding=\"same\")(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    for f,d in [(64,0.3),(128,0.3),(256,0.4),(512,0.4)]:\n",
    "        x = res_block(x, f)\n",
    "        x = MaxPooling1D(2)(x)\n",
    "        x = Dropout(d)(x)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "    return Model(inp, out)\n",
    "\n",
    "# =============================================================\n",
    "#                    TRAINING LOOP\n",
    "# =============================================================\n",
    "acc_list, auc_list, confs = [], [], []\n",
    "\n",
    "for fold in range(5):\n",
    "    print(f\"\\n========== FOLD {fold+1} ==========\")\n",
    "    start = time.time()\n",
    "\n",
    "    # LOAD DATA LIKE THE SECOND CODE\n",
    "    X_tr_val = np.load(os.path.join(DATA_DIR, f\"fold_{fold}_X_train.npy\"), allow_pickle=True)\n",
    "    X_te = np.load(os.path.join(DATA_DIR, f\"fold_{fold}_X_test.npy\"),  allow_pickle=True)\n",
    "    y_tr_val = np.load(os.path.join(DATA_DIR, f\"fold_{fold}_y_train.npy\"), allow_pickle=True)\n",
    "    y_te = np.load(os.path.join(DATA_DIR, f\"fold_{fold}_y_test.npy\"),  allow_pickle=True)\n",
    "\n",
    "    # PAD AND RESHAPE\n",
    "    X_tr_val = pad_segments(X_tr_val).astype(np.float32)\n",
    "    X_te = pad_segments(X_te).astype(np.float32)\n",
    "    \n",
    "    # BINARY LABELS\n",
    "    y_tr_val_bin = np.where(y_tr_val == 0, 0, 1).astype(np.int64)\n",
    "    y_te_bin = np.where(y_te == 0, 0, 1).astype(np.int64)\n",
    "\n",
    "    # Conv1D shape (N, T, 1)\n",
    "    X_tr_val = X_tr_val[..., None]\n",
    "    X_te = X_te[..., None]\n",
    "\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_tr_val, y_tr_val_bin,\n",
    "        test_size=0.15,\n",
    "        stratify=y_tr_val_bin,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # CLASS WEIGHTS\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.unique(y_tr),\n",
    "        y=y_tr\n",
    "    )\n",
    "    class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "\n",
    "    model = build_model((X_tr.shape[1], 1))\n",
    "    model.compile(\n",
    "        optimizer=AdamW(2e-4, weight_decay=1e-5),\n",
    "        loss=weighted_bce(2.8,1.0),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        AugGen(X_tr, y_tr),\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[\n",
    "            EarlyStopping(patience=20, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(patience=10, factor=0.5, min_lr=1e-7),\n",
    "            ModelCheckpoint(\n",
    "                os.path.join(results_dir, f\"model_fold{fold+1}.weights.h5\"),\n",
    "                save_best_only=True,\n",
    "                save_weights_only=True\n",
    "            )\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    model.load_weights(os.path.join(results_dir, f\"model_fold{fold+1}.weights.h5\"))\n",
    "\n",
    "    prob = model.predict(X_te).flatten()\n",
    "    pred = (prob > 0.5).astype(int)\n",
    "\n",
    "    acc = np.mean(pred == y_te_bin)\n",
    "    auc = roc_auc_score(y_te_bin, prob)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "    print(f\"Fold {fold+1} | ACC={acc:.4f} | AUC={auc:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_te_bin, pred)\n",
    "    confs.append(cm)\n",
    "\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"Normal\",\"Abnormal\"],\n",
    "                yticklabels=[\"Normal\",\"Abnormal\"])\n",
    "    plt.title(f\"Fold {fold+1} Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, f\"confusion_fold{fold+1}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    with open(summary_path,\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Fold {fold+1}: ACC={acc:.4f}, AUC={auc:.4f}\\n\")\n",
    "\n",
    "# =============================================================\n",
    "#                    OVERALL RESULTS\n",
    "# =============================================================\n",
    "total_cm = np.sum(confs, axis=0)\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_auc = np.mean(auc_list)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(\n",
    "    total_cm, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
    "    xticklabels=[\"Normal\",\"Abnormal\"],\n",
    "    yticklabels=[\"Normal\",\"Abnormal\"]\n",
    ")\n",
    "plt.title(f\"Overall Confusion Matrix | Mean ACC={mean_acc:.4f}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, \"confusion_overall.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "with open(summary_path,\"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\"+\"=\"*70+\"\\n\")\n",
    "    f.write(f\"Mean ACC = {mean_acc:.4f}\\n\")\n",
    "    f.write(f\"Mean AUC = {mean_auc:.4f}\\n\")\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\" BINARY TRAINING COMPLETED \")\n",
    "print(\"==============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359dee6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== FOLD 1 ==========\n",
      "Epoch 1/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - accuracy: 0.5269 - loss: 0.7375 - val_accuracy: 0.2000 - val_loss: 0.8794 - learning_rate: 1.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.6898 - loss: 0.4922 - val_accuracy: 0.2354 - val_loss: 0.9795 - learning_rate: 1.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.8171 - loss: 0.3301 - val_accuracy: 0.6396 - val_loss: 0.5903 - learning_rate: 1.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.8950 - loss: 0.2404 - val_accuracy: 0.9333 - val_loss: 0.2595 - learning_rate: 1.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.9081 - loss: 0.2038 - val_accuracy: 0.9688 - val_loss: 0.1077 - learning_rate: 1.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9322 - loss: 0.1669 - val_accuracy: 0.9771 - val_loss: 0.0835 - learning_rate: 1.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9451 - loss: 0.1530 - val_accuracy: 0.9854 - val_loss: 0.0686 - learning_rate: 1.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 104ms/step - accuracy: 0.9449 - loss: 0.1372 - val_accuracy: 0.9854 - val_loss: 0.0554 - learning_rate: 1.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - accuracy: 0.9529 - loss: 0.1203 - val_accuracy: 0.9792 - val_loss: 0.0594 - learning_rate: 1.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9543 - loss: 0.1081 - val_accuracy: 0.9875 - val_loss: 0.0429 - learning_rate: 1.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9616 - loss: 0.1052 - val_accuracy: 0.9812 - val_loss: 0.0482 - learning_rate: 1.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9625 - loss: 0.0905 - val_accuracy: 0.9750 - val_loss: 0.0578 - learning_rate: 1.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9644 - loss: 0.0919 - val_accuracy: 0.9854 - val_loss: 0.0443 - learning_rate: 1.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9706 - loss: 0.0739 - val_accuracy: 0.9417 - val_loss: 0.1189 - learning_rate: 1.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9713 - loss: 0.0831 - val_accuracy: 0.9875 - val_loss: 0.0334 - learning_rate: 1.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.9750 - loss: 0.0747 - val_accuracy: 0.9604 - val_loss: 0.0978 - learning_rate: 1.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9729 - loss: 0.0740 - val_accuracy: 0.9875 - val_loss: 0.0374 - learning_rate: 1.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.9717 - loss: 0.0746 - val_accuracy: 0.9896 - val_loss: 0.0301 - learning_rate: 1.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9761 - loss: 0.0689 - val_accuracy: 0.9917 - val_loss: 0.0228 - learning_rate: 1.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9756 - loss: 0.0656 - val_accuracy: 0.9896 - val_loss: 0.0231 - learning_rate: 1.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9736 - loss: 0.0621 - val_accuracy: 0.9896 - val_loss: 0.0359 - learning_rate: 1.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9763 - loss: 0.0556 - val_accuracy: 0.9875 - val_loss: 0.0334 - learning_rate: 1.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9773 - loss: 0.0607 - val_accuracy: 0.9812 - val_loss: 0.0523 - learning_rate: 1.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9828 - loss: 0.0535 - val_accuracy: 0.9750 - val_loss: 0.0582 - learning_rate: 1.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9805 - loss: 0.0566 - val_accuracy: 0.9896 - val_loss: 0.0315 - learning_rate: 1.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9786 - loss: 0.0575 - val_accuracy: 0.9771 - val_loss: 0.0622 - learning_rate: 1.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9835 - loss: 0.0403 - val_accuracy: 0.9896 - val_loss: 0.0179 - learning_rate: 1.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.9830 - loss: 0.0509 - val_accuracy: 0.9958 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9809 - loss: 0.0513 - val_accuracy: 0.9917 - val_loss: 0.0188 - learning_rate: 1.0000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9853 - loss: 0.0423 - val_accuracy: 0.9833 - val_loss: 0.0451 - learning_rate: 1.0000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9858 - loss: 0.0394 - val_accuracy: 0.9917 - val_loss: 0.0213 - learning_rate: 1.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9789 - loss: 0.0540 - val_accuracy: 0.9896 - val_loss: 0.0374 - learning_rate: 1.0000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9830 - loss: 0.0466 - val_accuracy: 0.9896 - val_loss: 0.0252 - learning_rate: 1.0000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9807 - loss: 0.0506 - val_accuracy: 0.9917 - val_loss: 0.0239 - learning_rate: 1.0000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9846 - loss: 0.0449 - val_accuracy: 0.9937 - val_loss: 0.0152 - learning_rate: 1.0000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9844 - loss: 0.0430 - val_accuracy: 0.9896 - val_loss: 0.0240 - learning_rate: 1.0000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9860 - loss: 0.0373 - val_accuracy: 0.9917 - val_loss: 0.0172 - learning_rate: 5.0000e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9860 - loss: 0.0365 - val_accuracy: 0.9896 - val_loss: 0.0243 - learning_rate: 5.0000e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9894 - loss: 0.0316 - val_accuracy: 0.9917 - val_loss: 0.0276 - learning_rate: 5.0000e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9839 - loss: 0.0422 - val_accuracy: 0.9854 - val_loss: 0.0400 - learning_rate: 5.0000e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9871 - loss: 0.0315 - val_accuracy: 0.9917 - val_loss: 0.0235 - learning_rate: 5.0000e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9874 - loss: 0.0365 - val_accuracy: 0.9896 - val_loss: 0.0182 - learning_rate: 5.0000e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9878 - loss: 0.0334 - val_accuracy: 0.9917 - val_loss: 0.0196 - learning_rate: 5.0000e-05\n",
      "Epoch 44/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9839 - loss: 0.0412 - val_accuracy: 0.9917 - val_loss: 0.0230 - learning_rate: 5.0000e-05\n",
      "Epoch 45/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9876 - loss: 0.0322 - val_accuracy: 0.9917 - val_loss: 0.0190 - learning_rate: 2.5000e-05\n",
      "Epoch 46/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9892 - loss: 0.0316 - val_accuracy: 0.9917 - val_loss: 0.0150 - learning_rate: 2.5000e-05\n",
      "Epoch 47/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9874 - loss: 0.0337 - val_accuracy: 0.9917 - val_loss: 0.0231 - learning_rate: 2.5000e-05\n",
      "Epoch 48/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9885 - loss: 0.0300 - val_accuracy: 0.9896 - val_loss: 0.0169 - learning_rate: 2.5000e-05\n",
      "Epoch 49/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9881 - loss: 0.0343 - val_accuracy: 0.9917 - val_loss: 0.0129 - learning_rate: 2.5000e-05\n",
      "Epoch 50/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9869 - loss: 0.0336 - val_accuracy: 0.9917 - val_loss: 0.0275 - learning_rate: 2.5000e-05\n",
      "Epoch 51/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9876 - loss: 0.0314 - val_accuracy: 0.9917 - val_loss: 0.0192 - learning_rate: 2.5000e-05\n",
      "Epoch 52/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9883 - loss: 0.0303 - val_accuracy: 0.9917 - val_loss: 0.0205 - learning_rate: 2.5000e-05\n",
      "Epoch 53/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9894 - loss: 0.0289 - val_accuracy: 0.9937 - val_loss: 0.0138 - learning_rate: 2.5000e-05\n",
      "Epoch 54/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9892 - loss: 0.0294 - val_accuracy: 0.9937 - val_loss: 0.0106 - learning_rate: 2.5000e-05\n",
      "Epoch 55/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9885 - loss: 0.0315 - val_accuracy: 0.9917 - val_loss: 0.0200 - learning_rate: 2.5000e-05\n",
      "Epoch 56/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9929 - loss: 0.0222 - val_accuracy: 0.9937 - val_loss: 0.0124 - learning_rate: 2.5000e-05\n",
      "Epoch 57/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9862 - loss: 0.0394 - val_accuracy: 0.9917 - val_loss: 0.0115 - learning_rate: 2.5000e-05\n",
      "Epoch 58/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9867 - loss: 0.0348 - val_accuracy: 0.9917 - val_loss: 0.0172 - learning_rate: 2.5000e-05\n",
      "Epoch 59/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9908 - loss: 0.0265 - val_accuracy: 0.9917 - val_loss: 0.0198 - learning_rate: 2.5000e-05\n",
      "Epoch 60/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9901 - loss: 0.0235 - val_accuracy: 0.9958 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Fold 1 | ACC=0.9838 | AUC=0.9997\n",
      "\n",
      "========== FOLD 2 ==========\n",
      "Epoch 1/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - accuracy: 0.5310 - loss: 0.7439 - val_accuracy: 0.2042 - val_loss: 0.8370 - learning_rate: 1.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.7229 - loss: 0.4527 - val_accuracy: 0.2208 - val_loss: 1.2601 - learning_rate: 1.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.8382 - loss: 0.3158 - val_accuracy: 0.7688 - val_loss: 0.4768 - learning_rate: 1.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9014 - loss: 0.2315 - val_accuracy: 0.9688 - val_loss: 0.1872 - learning_rate: 1.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.9253 - loss: 0.1927 - val_accuracy: 0.9458 - val_loss: 0.1177 - learning_rate: 1.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9320 - loss: 0.1614 - val_accuracy: 0.9771 - val_loss: 0.0808 - learning_rate: 1.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9446 - loss: 0.1416 - val_accuracy: 0.9792 - val_loss: 0.0634 - learning_rate: 1.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.9444 - loss: 0.1386 - val_accuracy: 0.9396 - val_loss: 0.1091 - learning_rate: 1.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9566 - loss: 0.1188 - val_accuracy: 0.9771 - val_loss: 0.0590 - learning_rate: 1.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9584 - loss: 0.1148 - val_accuracy: 0.9646 - val_loss: 0.0842 - learning_rate: 1.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9637 - loss: 0.0988 - val_accuracy: 0.9396 - val_loss: 0.1324 - learning_rate: 1.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9704 - loss: 0.0876 - val_accuracy: 0.9604 - val_loss: 0.0856 - learning_rate: 1.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9651 - loss: 0.0925 - val_accuracy: 0.9563 - val_loss: 0.0939 - learning_rate: 1.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9667 - loss: 0.0899 - val_accuracy: 0.9708 - val_loss: 0.0687 - learning_rate: 1.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9699 - loss: 0.0804 - val_accuracy: 0.9604 - val_loss: 0.0825 - learning_rate: 1.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9761 - loss: 0.0724 - val_accuracy: 0.9812 - val_loss: 0.0423 - learning_rate: 1.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9724 - loss: 0.0747 - val_accuracy: 0.9812 - val_loss: 0.0395 - learning_rate: 1.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9759 - loss: 0.0715 - val_accuracy: 0.9708 - val_loss: 0.0774 - learning_rate: 1.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9800 - loss: 0.0634 - val_accuracy: 0.9667 - val_loss: 0.0791 - learning_rate: 1.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9832 - loss: 0.0577 - val_accuracy: 0.9771 - val_loss: 0.0633 - learning_rate: 1.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9740 - loss: 0.0667 - val_accuracy: 0.9792 - val_loss: 0.0370 - learning_rate: 1.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9793 - loss: 0.0568 - val_accuracy: 0.9792 - val_loss: 0.0494 - learning_rate: 1.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9793 - loss: 0.0577 - val_accuracy: 0.9792 - val_loss: 0.0475 - learning_rate: 1.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9773 - loss: 0.0601 - val_accuracy: 0.9750 - val_loss: 0.0545 - learning_rate: 1.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9828 - loss: 0.0530 - val_accuracy: 0.9875 - val_loss: 0.0240 - learning_rate: 1.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9844 - loss: 0.0443 - val_accuracy: 0.9896 - val_loss: 0.0201 - learning_rate: 1.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9858 - loss: 0.0409 - val_accuracy: 0.9812 - val_loss: 0.0353 - learning_rate: 1.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9835 - loss: 0.0490 - val_accuracy: 0.9729 - val_loss: 0.0551 - learning_rate: 1.0000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9798 - loss: 0.0551 - val_accuracy: 0.9729 - val_loss: 0.0793 - learning_rate: 1.0000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9869 - loss: 0.0384 - val_accuracy: 0.9771 - val_loss: 0.0637 - learning_rate: 1.0000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9830 - loss: 0.0409 - val_accuracy: 0.9833 - val_loss: 0.0411 - learning_rate: 1.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9848 - loss: 0.0404 - val_accuracy: 0.9896 - val_loss: 0.0195 - learning_rate: 1.0000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9837 - loss: 0.0389 - val_accuracy: 0.9854 - val_loss: 0.0359 - learning_rate: 1.0000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9844 - loss: 0.0420 - val_accuracy: 0.9688 - val_loss: 0.0725 - learning_rate: 1.0000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9858 - loss: 0.0372 - val_accuracy: 0.9875 - val_loss: 0.0367 - learning_rate: 1.0000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9878 - loss: 0.0359 - val_accuracy: 0.9896 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9883 - loss: 0.0302 - val_accuracy: 0.9812 - val_loss: 0.0294 - learning_rate: 1.0000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9897 - loss: 0.0338 - val_accuracy: 0.9604 - val_loss: 0.1163 - learning_rate: 1.0000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9809 - loss: 0.0468 - val_accuracy: 0.9854 - val_loss: 0.0310 - learning_rate: 1.0000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9910 - loss: 0.0269 - val_accuracy: 0.9812 - val_loss: 0.0703 - learning_rate: 1.0000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9878 - loss: 0.0298 - val_accuracy: 0.9688 - val_loss: 0.0668 - learning_rate: 1.0000e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9855 - loss: 0.0368 - val_accuracy: 0.9917 - val_loss: 0.0282 - learning_rate: 1.0000e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9867 - loss: 0.0381 - val_accuracy: 0.9917 - val_loss: 0.0188 - learning_rate: 1.0000e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9864 - loss: 0.0370 - val_accuracy: 0.9729 - val_loss: 0.0565 - learning_rate: 1.0000e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9901 - loss: 0.0272 - val_accuracy: 0.9896 - val_loss: 0.0207 - learning_rate: 5.0000e-05\n",
      "Epoch 46/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9920 - loss: 0.0264 - val_accuracy: 0.9917 - val_loss: 0.0183 - learning_rate: 5.0000e-05\n",
      "Epoch 47/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9885 - loss: 0.0302 - val_accuracy: 0.9833 - val_loss: 0.0474 - learning_rate: 5.0000e-05\n",
      "Epoch 48/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9890 - loss: 0.0284 - val_accuracy: 0.9875 - val_loss: 0.0283 - learning_rate: 5.0000e-05\n",
      "Epoch 49/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9876 - loss: 0.0289 - val_accuracy: 0.9917 - val_loss: 0.0135 - learning_rate: 5.0000e-05\n",
      "Epoch 50/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.9913 - loss: 0.0274 - val_accuracy: 0.9875 - val_loss: 0.0282 - learning_rate: 5.0000e-05\n",
      "Epoch 51/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9903 - loss: 0.0267 - val_accuracy: 0.9937 - val_loss: 0.0160 - learning_rate: 5.0000e-05\n",
      "Epoch 52/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9892 - loss: 0.0287 - val_accuracy: 0.9896 - val_loss: 0.0189 - learning_rate: 5.0000e-05\n",
      "Epoch 53/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9926 - loss: 0.0191 - val_accuracy: 0.9937 - val_loss: 0.0123 - learning_rate: 5.0000e-05\n",
      "Epoch 54/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9913 - loss: 0.0251 - val_accuracy: 0.9896 - val_loss: 0.0160 - learning_rate: 5.0000e-05\n",
      "Epoch 55/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9917 - loss: 0.0260 - val_accuracy: 0.9917 - val_loss: 0.0209 - learning_rate: 5.0000e-05\n",
      "Epoch 56/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9933 - loss: 0.0191 - val_accuracy: 0.9854 - val_loss: 0.0233 - learning_rate: 5.0000e-05\n",
      "Epoch 57/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9894 - loss: 0.0258 - val_accuracy: 0.9896 - val_loss: 0.0317 - learning_rate: 5.0000e-05\n",
      "Epoch 58/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9897 - loss: 0.0287 - val_accuracy: 0.9854 - val_loss: 0.0370 - learning_rate: 5.0000e-05\n",
      "Epoch 59/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9903 - loss: 0.0242 - val_accuracy: 0.9854 - val_loss: 0.0310 - learning_rate: 5.0000e-05\n",
      "Epoch 60/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9933 - loss: 0.0221 - val_accuracy: 0.9937 - val_loss: 0.0148 - learning_rate: 5.0000e-05\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Fold 2 | ACC=0.9888 | AUC=0.9988\n",
      "\n",
      "========== FOLD 3 ==========\n",
      "Epoch 1/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.5508 - loss: 0.7086 - val_accuracy: 0.2188 - val_loss: 0.7836 - learning_rate: 1.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.7790 - loss: 0.4032 - val_accuracy: 0.3917 - val_loss: 0.8467 - learning_rate: 1.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8713 - loss: 0.2751 - val_accuracy: 0.7104 - val_loss: 0.5118 - learning_rate: 1.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.9148 - loss: 0.2076 - val_accuracy: 0.9667 - val_loss: 0.1766 - learning_rate: 1.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9226 - loss: 0.1813 - val_accuracy: 0.9688 - val_loss: 0.1007 - learning_rate: 1.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9407 - loss: 0.1579 - val_accuracy: 0.8979 - val_loss: 0.1865 - learning_rate: 1.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9421 - loss: 0.1455 - val_accuracy: 0.9604 - val_loss: 0.1046 - learning_rate: 1.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9469 - loss: 0.1345 - val_accuracy: 0.9854 - val_loss: 0.0613 - learning_rate: 1.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9577 - loss: 0.1169 - val_accuracy: 0.9750 - val_loss: 0.0686 - learning_rate: 1.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.9632 - loss: 0.0999 - val_accuracy: 0.9729 - val_loss: 0.0785 - learning_rate: 1.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9616 - loss: 0.1024 - val_accuracy: 0.9708 - val_loss: 0.0873 - learning_rate: 1.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.9637 - loss: 0.0964 - val_accuracy: 0.9708 - val_loss: 0.0963 - learning_rate: 1.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9678 - loss: 0.0869 - val_accuracy: 0.9833 - val_loss: 0.0574 - learning_rate: 1.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9699 - loss: 0.0813 - val_accuracy: 0.9729 - val_loss: 0.0780 - learning_rate: 1.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9692 - loss: 0.0813 - val_accuracy: 0.9771 - val_loss: 0.0694 - learning_rate: 1.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9733 - loss: 0.0734 - val_accuracy: 0.9833 - val_loss: 0.0468 - learning_rate: 1.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9754 - loss: 0.0650 - val_accuracy: 0.9750 - val_loss: 0.0747 - learning_rate: 1.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.9722 - loss: 0.0668 - val_accuracy: 0.9771 - val_loss: 0.0685 - learning_rate: 1.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.9766 - loss: 0.0612 - val_accuracy: 0.9646 - val_loss: 0.1077 - learning_rate: 1.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.9775 - loss: 0.0639 - val_accuracy: 0.9792 - val_loss: 0.0724 - learning_rate: 1.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.9766 - loss: 0.0642 - val_accuracy: 0.9812 - val_loss: 0.0542 - learning_rate: 1.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9770 - loss: 0.0609 - val_accuracy: 0.9812 - val_loss: 0.0650 - learning_rate: 1.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9770 - loss: 0.0609 - val_accuracy: 0.9812 - val_loss: 0.0486 - learning_rate: 1.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9821 - loss: 0.0509 - val_accuracy: 0.9812 - val_loss: 0.0444 - learning_rate: 1.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9800 - loss: 0.0545 - val_accuracy: 0.9625 - val_loss: 0.1092 - learning_rate: 1.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.9841 - loss: 0.0473 - val_accuracy: 0.9771 - val_loss: 0.0664 - learning_rate: 1.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9807 - loss: 0.0502 - val_accuracy: 0.9833 - val_loss: 0.0456 - learning_rate: 1.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9846 - loss: 0.0428 - val_accuracy: 0.9812 - val_loss: 0.0650 - learning_rate: 1.0000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9848 - loss: 0.0428 - val_accuracy: 0.9792 - val_loss: 0.0591 - learning_rate: 1.0000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9860 - loss: 0.0399 - val_accuracy: 0.9812 - val_loss: 0.0564 - learning_rate: 1.0000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9835 - loss: 0.0459 - val_accuracy: 0.9792 - val_loss: 0.0561 - learning_rate: 1.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9818 - loss: 0.0480 - val_accuracy: 0.9833 - val_loss: 0.0561 - learning_rate: 1.0000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9885 - loss: 0.0352 - val_accuracy: 0.9854 - val_loss: 0.0617 - learning_rate: 5.0000e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9853 - loss: 0.0416 - val_accuracy: 0.9833 - val_loss: 0.0403 - learning_rate: 5.0000e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9876 - loss: 0.0345 - val_accuracy: 0.9750 - val_loss: 0.0893 - learning_rate: 5.0000e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9832 - loss: 0.0419 - val_accuracy: 0.9812 - val_loss: 0.0634 - learning_rate: 5.0000e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9862 - loss: 0.0366 - val_accuracy: 0.9875 - val_loss: 0.0372 - learning_rate: 5.0000e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9874 - loss: 0.0347 - val_accuracy: 0.9771 - val_loss: 0.0661 - learning_rate: 5.0000e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9874 - loss: 0.0337 - val_accuracy: 0.9792 - val_loss: 0.0746 - learning_rate: 5.0000e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9830 - loss: 0.0431 - val_accuracy: 0.9875 - val_loss: 0.0329 - learning_rate: 5.0000e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9867 - loss: 0.0365 - val_accuracy: 0.9854 - val_loss: 0.0461 - learning_rate: 5.0000e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9887 - loss: 0.0343 - val_accuracy: 0.9854 - val_loss: 0.0510 - learning_rate: 5.0000e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9885 - loss: 0.0312 - val_accuracy: 0.9854 - val_loss: 0.0455 - learning_rate: 5.0000e-05\n",
      "Epoch 44/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9876 - loss: 0.0348 - val_accuracy: 0.9812 - val_loss: 0.0742 - learning_rate: 5.0000e-05\n",
      "Epoch 45/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9899 - loss: 0.0321 - val_accuracy: 0.9875 - val_loss: 0.0232 - learning_rate: 5.0000e-05\n",
      "Epoch 46/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9901 - loss: 0.0289 - val_accuracy: 0.9854 - val_loss: 0.0561 - learning_rate: 5.0000e-05\n",
      "Epoch 47/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9887 - loss: 0.0303 - val_accuracy: 0.9854 - val_loss: 0.0518 - learning_rate: 5.0000e-05\n",
      "Epoch 48/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.9908 - loss: 0.0279 - val_accuracy: 0.9750 - val_loss: 0.0782 - learning_rate: 5.0000e-05\n",
      "Epoch 49/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9915 - loss: 0.0267 - val_accuracy: 0.9854 - val_loss: 0.0568 - learning_rate: 5.0000e-05\n",
      "Epoch 50/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.9901 - loss: 0.0253 - val_accuracy: 0.9833 - val_loss: 0.0427 - learning_rate: 5.0000e-05\n",
      "Epoch 51/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9878 - loss: 0.0333 - val_accuracy: 0.9833 - val_loss: 0.0567 - learning_rate: 5.0000e-05\n",
      "Epoch 52/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9892 - loss: 0.0298 - val_accuracy: 0.9812 - val_loss: 0.0408 - learning_rate: 5.0000e-05\n",
      "Epoch 53/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9892 - loss: 0.0291 - val_accuracy: 0.9833 - val_loss: 0.0406 - learning_rate: 5.0000e-05\n",
      "Epoch 54/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9897 - loss: 0.0269 - val_accuracy: 0.9833 - val_loss: 0.0575 - learning_rate: 2.5000e-05\n",
      "Epoch 55/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9940 - loss: 0.0239 - val_accuracy: 0.9854 - val_loss: 0.0306 - learning_rate: 2.5000e-05\n",
      "Epoch 56/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9899 - loss: 0.0301 - val_accuracy: 0.9854 - val_loss: 0.0366 - learning_rate: 2.5000e-05\n",
      "Epoch 57/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9899 - loss: 0.0258 - val_accuracy: 0.9833 - val_loss: 0.0389 - learning_rate: 2.5000e-05\n",
      "Epoch 58/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9883 - loss: 0.0304 - val_accuracy: 0.9854 - val_loss: 0.0374 - learning_rate: 2.5000e-05\n",
      "Epoch 59/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9878 - loss: 0.0335 - val_accuracy: 0.9833 - val_loss: 0.0389 - learning_rate: 2.5000e-05\n",
      "Epoch 60/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.9926 - loss: 0.0204 - val_accuracy: 0.9833 - val_loss: 0.0310 - learning_rate: 2.5000e-05\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Fold 3 | ACC=0.9938 | AUC=0.9999\n",
      "\n",
      "========== FOLD 4 ==========\n",
      "Epoch 1/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.5267 - loss: 0.7077 - val_accuracy: 0.2000 - val_loss: 1.0390 - learning_rate: 1.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6953 - loss: 0.4711 - val_accuracy: 0.2104 - val_loss: 1.3241 - learning_rate: 1.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.8419 - loss: 0.3083 - val_accuracy: 0.2917 - val_loss: 1.2069 - learning_rate: 1.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.8892 - loss: 0.2414 - val_accuracy: 0.9479 - val_loss: 0.2301 - learning_rate: 1.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9239 - loss: 0.1843 - val_accuracy: 0.9812 - val_loss: 0.1241 - learning_rate: 1.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9290 - loss: 0.1728 - val_accuracy: 0.9875 - val_loss: 0.0749 - learning_rate: 1.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9472 - loss: 0.1425 - val_accuracy: 0.9812 - val_loss: 0.0707 - learning_rate: 1.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - accuracy: 0.9524 - loss: 0.1276 - val_accuracy: 0.9875 - val_loss: 0.0518 - learning_rate: 1.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9524 - loss: 0.1205 - val_accuracy: 0.9750 - val_loss: 0.0771 - learning_rate: 1.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9614 - loss: 0.1043 - val_accuracy: 0.9833 - val_loss: 0.0565 - learning_rate: 1.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9644 - loss: 0.1010 - val_accuracy: 0.9875 - val_loss: 0.0568 - learning_rate: 1.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9674 - loss: 0.0897 - val_accuracy: 0.9854 - val_loss: 0.0478 - learning_rate: 1.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9674 - loss: 0.0930 - val_accuracy: 0.9917 - val_loss: 0.0323 - learning_rate: 1.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9628 - loss: 0.0956 - val_accuracy: 0.9937 - val_loss: 0.0349 - learning_rate: 1.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9740 - loss: 0.0739 - val_accuracy: 0.9917 - val_loss: 0.0342 - learning_rate: 1.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9733 - loss: 0.0733 - val_accuracy: 0.9917 - val_loss: 0.0314 - learning_rate: 1.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9738 - loss: 0.0689 - val_accuracy: 0.9521 - val_loss: 0.1010 - learning_rate: 1.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9750 - loss: 0.0678 - val_accuracy: 0.9896 - val_loss: 0.0395 - learning_rate: 1.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9759 - loss: 0.0640 - val_accuracy: 0.9812 - val_loss: 0.0486 - learning_rate: 1.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9750 - loss: 0.0745 - val_accuracy: 0.9896 - val_loss: 0.0334 - learning_rate: 1.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9775 - loss: 0.0640 - val_accuracy: 0.9937 - val_loss: 0.0242 - learning_rate: 1.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9793 - loss: 0.0539 - val_accuracy: 0.9896 - val_loss: 0.0314 - learning_rate: 1.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9738 - loss: 0.0667 - val_accuracy: 0.9937 - val_loss: 0.0203 - learning_rate: 1.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9795 - loss: 0.0551 - val_accuracy: 0.9937 - val_loss: 0.0177 - learning_rate: 1.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9789 - loss: 0.0554 - val_accuracy: 0.9917 - val_loss: 0.0248 - learning_rate: 1.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9841 - loss: 0.0468 - val_accuracy: 0.9896 - val_loss: 0.0300 - learning_rate: 1.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9825 - loss: 0.0477 - val_accuracy: 0.9958 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.9841 - loss: 0.0433 - val_accuracy: 0.9937 - val_loss: 0.0189 - learning_rate: 1.0000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9795 - loss: 0.0572 - val_accuracy: 0.9937 - val_loss: 0.0224 - learning_rate: 1.0000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9802 - loss: 0.0521 - val_accuracy: 0.9875 - val_loss: 0.0306 - learning_rate: 1.0000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9869 - loss: 0.0397 - val_accuracy: 0.9958 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9816 - loss: 0.0479 - val_accuracy: 0.9937 - val_loss: 0.0196 - learning_rate: 1.0000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9860 - loss: 0.0393 - val_accuracy: 0.9937 - val_loss: 0.0179 - learning_rate: 1.0000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9860 - loss: 0.0406 - val_accuracy: 0.9958 - val_loss: 0.0163 - learning_rate: 1.0000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9858 - loss: 0.0386 - val_accuracy: 0.9958 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9867 - loss: 0.0360 - val_accuracy: 0.9937 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9862 - loss: 0.0373 - val_accuracy: 0.9937 - val_loss: 0.0185 - learning_rate: 1.0000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9823 - loss: 0.0454 - val_accuracy: 0.9896 - val_loss: 0.0181 - learning_rate: 1.0000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9867 - loss: 0.0362 - val_accuracy: 0.9958 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9878 - loss: 0.0344 - val_accuracy: 0.9958 - val_loss: 0.0122 - learning_rate: 5.0000e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9899 - loss: 0.0316 - val_accuracy: 0.9958 - val_loss: 0.0143 - learning_rate: 5.0000e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9881 - loss: 0.0350 - val_accuracy: 0.9958 - val_loss: 0.0121 - learning_rate: 5.0000e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9874 - loss: 0.0350 - val_accuracy: 0.9979 - val_loss: 0.0135 - learning_rate: 5.0000e-05\n",
      "Epoch 44/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9862 - loss: 0.0377 - val_accuracy: 0.9958 - val_loss: 0.0124 - learning_rate: 5.0000e-05\n",
      "Epoch 45/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9908 - loss: 0.0297 - val_accuracy: 0.9958 - val_loss: 0.0132 - learning_rate: 5.0000e-05\n",
      "Epoch 46/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9915 - loss: 0.0261 - val_accuracy: 0.9917 - val_loss: 0.0211 - learning_rate: 5.0000e-05\n",
      "Epoch 47/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9883 - loss: 0.0324 - val_accuracy: 0.9958 - val_loss: 0.0179 - learning_rate: 5.0000e-05\n",
      "Epoch 48/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9874 - loss: 0.0336 - val_accuracy: 0.9958 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 49/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9883 - loss: 0.0322 - val_accuracy: 0.9958 - val_loss: 0.0146 - learning_rate: 5.0000e-05\n",
      "Epoch 50/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9867 - loss: 0.0318 - val_accuracy: 0.9958 - val_loss: 0.0128 - learning_rate: 5.0000e-05\n",
      "Epoch 51/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9897 - loss: 0.0316 - val_accuracy: 0.9958 - val_loss: 0.0147 - learning_rate: 5.0000e-05\n",
      "Epoch 52/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9883 - loss: 0.0319 - val_accuracy: 0.9958 - val_loss: 0.0116 - learning_rate: 5.0000e-05\n",
      "Epoch 53/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9903 - loss: 0.0274 - val_accuracy: 0.9958 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 54/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9897 - loss: 0.0299 - val_accuracy: 0.9958 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 55/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9878 - loss: 0.0340 - val_accuracy: 0.9896 - val_loss: 0.0270 - learning_rate: 5.0000e-05\n",
      "Epoch 56/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9901 - loss: 0.0257 - val_accuracy: 0.9958 - val_loss: 0.0125 - learning_rate: 5.0000e-05\n",
      "Epoch 57/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9899 - loss: 0.0271 - val_accuracy: 0.9958 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 58/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9881 - loss: 0.0320 - val_accuracy: 0.9958 - val_loss: 0.0118 - learning_rate: 5.0000e-05\n",
      "Epoch 59/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9887 - loss: 0.0298 - val_accuracy: 0.9958 - val_loss: 0.0135 - learning_rate: 5.0000e-05\n",
      "Epoch 60/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9906 - loss: 0.0281 - val_accuracy: 0.9917 - val_loss: 0.0214 - learning_rate: 5.0000e-05\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Fold 4 | ACC=0.9862 | AUC=0.9997\n",
      "\n",
      "========== FOLD 5 ==========\n",
      "Epoch 1/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.5177 - loss: 0.7396 - val_accuracy: 0.8333 - val_loss: 0.6352 - learning_rate: 1.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.7254 - loss: 0.4455 - val_accuracy: 0.3125 - val_loss: 0.8079 - learning_rate: 1.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.8635 - loss: 0.2790 - val_accuracy: 0.7042 - val_loss: 0.4936 - learning_rate: 1.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9125 - loss: 0.2033 - val_accuracy: 0.9708 - val_loss: 0.1813 - learning_rate: 1.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9352 - loss: 0.1614 - val_accuracy: 0.9812 - val_loss: 0.0949 - learning_rate: 1.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9384 - loss: 0.1439 - val_accuracy: 0.9812 - val_loss: 0.0691 - learning_rate: 1.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9591 - loss: 0.1137 - val_accuracy: 0.9771 - val_loss: 0.0709 - learning_rate: 1.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9616 - loss: 0.1082 - val_accuracy: 0.9750 - val_loss: 0.0707 - learning_rate: 1.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9690 - loss: 0.0870 - val_accuracy: 0.9812 - val_loss: 0.0584 - learning_rate: 1.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9674 - loss: 0.0899 - val_accuracy: 0.9625 - val_loss: 0.0875 - learning_rate: 1.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9722 - loss: 0.0776 - val_accuracy: 0.9646 - val_loss: 0.0914 - learning_rate: 1.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9779 - loss: 0.0716 - val_accuracy: 0.9771 - val_loss: 0.0606 - learning_rate: 1.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9784 - loss: 0.0609 - val_accuracy: 0.9729 - val_loss: 0.0706 - learning_rate: 1.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9802 - loss: 0.0605 - val_accuracy: 0.9833 - val_loss: 0.0622 - learning_rate: 1.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9825 - loss: 0.0550 - val_accuracy: 0.9875 - val_loss: 0.0482 - learning_rate: 1.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9779 - loss: 0.0573 - val_accuracy: 0.9812 - val_loss: 0.0507 - learning_rate: 1.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9786 - loss: 0.0608 - val_accuracy: 0.9667 - val_loss: 0.0732 - learning_rate: 1.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9837 - loss: 0.0520 - val_accuracy: 0.9917 - val_loss: 0.0298 - learning_rate: 1.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9823 - loss: 0.0444 - val_accuracy: 0.9792 - val_loss: 0.0544 - learning_rate: 1.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9848 - loss: 0.0469 - val_accuracy: 0.9625 - val_loss: 0.0859 - learning_rate: 1.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9841 - loss: 0.0400 - val_accuracy: 0.9875 - val_loss: 0.0458 - learning_rate: 1.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9853 - loss: 0.0421 - val_accuracy: 0.9896 - val_loss: 0.0355 - learning_rate: 1.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9860 - loss: 0.0375 - val_accuracy: 0.9854 - val_loss: 0.0425 - learning_rate: 1.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9830 - loss: 0.0473 - val_accuracy: 0.9750 - val_loss: 0.0585 - learning_rate: 1.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9853 - loss: 0.0419 - val_accuracy: 0.9875 - val_loss: 0.0429 - learning_rate: 1.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9883 - loss: 0.0336 - val_accuracy: 0.9750 - val_loss: 0.0586 - learning_rate: 1.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9899 - loss: 0.0297 - val_accuracy: 0.9896 - val_loss: 0.0360 - learning_rate: 5.0000e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9883 - loss: 0.0384 - val_accuracy: 0.9583 - val_loss: 0.1095 - learning_rate: 5.0000e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9885 - loss: 0.0315 - val_accuracy: 0.9896 - val_loss: 0.0362 - learning_rate: 5.0000e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9881 - loss: 0.0316 - val_accuracy: 0.9896 - val_loss: 0.0340 - learning_rate: 5.0000e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9871 - loss: 0.0348 - val_accuracy: 0.9896 - val_loss: 0.0306 - learning_rate: 5.0000e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9910 - loss: 0.0258 - val_accuracy: 0.9854 - val_loss: 0.0424 - learning_rate: 5.0000e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9901 - loss: 0.0268 - val_accuracy: 0.9875 - val_loss: 0.0413 - learning_rate: 5.0000e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9922 - loss: 0.0240 - val_accuracy: 0.9917 - val_loss: 0.0337 - learning_rate: 5.0000e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9913 - loss: 0.0246 - val_accuracy: 0.9875 - val_loss: 0.0393 - learning_rate: 2.5000e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9894 - loss: 0.0299 - val_accuracy: 0.9833 - val_loss: 0.0465 - learning_rate: 2.5000e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9906 - loss: 0.0273 - val_accuracy: 0.9896 - val_loss: 0.0357 - learning_rate: 2.5000e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9878 - loss: 0.0311 - val_accuracy: 0.9937 - val_loss: 0.0306 - learning_rate: 2.5000e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9926 - loss: 0.0246 - val_accuracy: 0.9833 - val_loss: 0.0478 - learning_rate: 2.5000e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9897 - loss: 0.0278 - val_accuracy: 0.9854 - val_loss: 0.0491 - learning_rate: 2.5000e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9915 - loss: 0.0258 - val_accuracy: 0.9833 - val_loss: 0.0430 - learning_rate: 2.5000e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9897 - loss: 0.0254 - val_accuracy: 0.9917 - val_loss: 0.0338 - learning_rate: 2.5000e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9913 - loss: 0.0263 - val_accuracy: 0.9896 - val_loss: 0.0347 - learning_rate: 1.2500e-05\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Fold 5 | ACC=0.9725 | AUC=0.9958\n",
      "\n",
      "==============================\n",
      " BINARY TRAINING COMPLETED \n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model # type: ignore\n",
    "from tensorflow.keras.layers import ( # type: ignore\n",
    "    Input, Conv1D, Dense, Dropout, BatchNormalization,\n",
    "    MaxPooling1D, GlobalAveragePooling1D, Activation\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam # pyright: ignore[reportMissingImports]\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint # type: ignore\n",
    "\n",
    "# =============================================================\n",
    "#                    PATHS\n",
    "# =============================================================\n",
    "DATA_DIR = r\"Preprocessing_Updated_Kfold\"\n",
    "RESULTS_DIR = \"results_ictal_binary_fixed\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "summary_path = os.path.join(RESULTS_DIR, \"accuracy_summary.txt\")\n",
    "with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"ICTAL vs NON-ICTAL (Binary) – Fixed Preprocessing\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "\n",
    "# =============================================================\n",
    "#                PAD SEGMENTS (IMPORTANT)\n",
    "# =============================================================\n",
    "def pad_segments(X_list):\n",
    "    cleaned = []\n",
    "    for x in X_list:\n",
    "        x = np.array(x)\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "        cleaned.append(x)\n",
    "\n",
    "    max_len = max(seg.shape[1] for seg in cleaned)\n",
    "\n",
    "    padded = []\n",
    "    for seg in cleaned:\n",
    "        pad_width = max_len - seg.shape[1]\n",
    "        if pad_width > 0:\n",
    "            seg = np.pad(seg, ((0,0),(0,pad_width)), mode=\"constant\")\n",
    "        padded.append(seg)\n",
    "\n",
    "    return np.vstack(padded)\n",
    "\n",
    "# =============================================================\n",
    "#                  DATA AUGMENTATION\n",
    "# =============================================================\n",
    "def augment(seg, p=0.6):\n",
    "    if np.random.random() > p:\n",
    "        return seg\n",
    "\n",
    "    L = len(seg)\n",
    "    op = np.random.choice([\"noise\",\"scale\",\"shift\",\"stretch\",\"roll\"])\n",
    "\n",
    "    if op == \"noise\":\n",
    "        augmented = seg + np.random.normal(0, 0.03, seg.shape)\n",
    "    elif op == \"scale\":\n",
    "        augmented = seg * np.random.uniform(0.85, 1.15)\n",
    "    elif op == \"shift\":\n",
    "        augmented = seg + np.random.uniform(-0.1, 0.1)\n",
    "    elif op == \"roll\":\n",
    "        augmented = np.roll(seg, np.random.randint(-30, 30))\n",
    "    elif op == \"stretch\":\n",
    "        factor = np.random.uniform(0.9, 1.1)\n",
    "        stretched = np.interp(\n",
    "            np.arange(0, L, factor),\n",
    "            np.arange(L),\n",
    "            seg\n",
    "        )\n",
    "        augmented = stretched\n",
    "    else:\n",
    "        augmented = seg\n",
    "\n",
    "    if len(augmented) > L:\n",
    "        augmented = augmented[:L]\n",
    "    elif len(augmented) < L:\n",
    "        augmented = np.pad(augmented, (0, L - len(augmented)))\n",
    "\n",
    "    return augmented\n",
    "\n",
    "# =============================================================\n",
    "#              OVERSAMPLE ICTAL\n",
    "# =============================================================\n",
    "def oversample_ictal(X, y, factor=3):\n",
    "    X_pos = X[y == 1]\n",
    "    X_aug_list = []\n",
    "\n",
    "    for _ in range(factor):\n",
    "        for seg in X_pos:\n",
    "            new_seg = augment(seg[:,0], p=1.0)\n",
    "            X_aug_list.append(new_seg.reshape(-1,1))\n",
    "\n",
    "    X_aug = np.array(X_aug_list)\n",
    "    y_aug = np.ones(len(X_aug))\n",
    "\n",
    "    X_new = np.concatenate([X, X_aug])\n",
    "    y_new = np.concatenate([y, y_aug])\n",
    "\n",
    "    return X_new, y_new\n",
    "\n",
    "# =============================================================\n",
    "#                    CNN MODEL\n",
    "# =============================================================\n",
    "def build_model(input_shape):\n",
    "    inp = Input(input_shape)\n",
    "\n",
    "    x = Conv1D(64, 7, padding=\"same\")(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv1D(128, 5, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv1D(256, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "    return Model(inp, out)\n",
    "\n",
    "# =============================================================\n",
    "#                    TRAINING\n",
    "# =============================================================\n",
    "acc_list, auc_list, confs = [], [], []\n",
    "\n",
    "for fold in range(5):\n",
    "    print(f\"\\n========== FOLD {fold+1} ==========\")\n",
    "\n",
    "    # =============================\n",
    "    # LOAD PREPROCESSED FILES\n",
    "    # =============================\n",
    "    X_tr_val = np.load(\n",
    "        os.path.join(DATA_DIR, f\"fold_{fold}_X_train.npy\"),\n",
    "        allow_pickle=True\n",
    "    )\n",
    "    X_te = np.load(\n",
    "        os.path.join(DATA_DIR, f\"fold_{fold}_X_test.npy\"),\n",
    "        allow_pickle=True\n",
    "    )\n",
    "    y_tr_val = np.load(\n",
    "        os.path.join(DATA_DIR, f\"fold_{fold}_y_train.npy\"),\n",
    "        allow_pickle=True\n",
    "    )\n",
    "    y_te = np.load(\n",
    "        os.path.join(DATA_DIR, f\"fold_{fold}_y_test.npy\"),\n",
    "        allow_pickle=True\n",
    "    )\n",
    "\n",
    "    # =============================\n",
    "    # PAD + SHAPE\n",
    "    # =============================\n",
    "    X_tr_val = pad_segments(X_tr_val).astype(np.float32)\n",
    "    X_te = pad_segments(X_te).astype(np.float32)\n",
    "\n",
    "    # =============================\n",
    "    # MULTI → BINARY\n",
    "    # (ICTAL=1 , NORMAL+INTERICTAL=0)\n",
    "    # =============================\n",
    "    y_tr_val = np.where(y_tr_val == 2, 1, 0)\n",
    "    y_te = np.where(y_te == 2, 1, 0)\n",
    "\n",
    "    X_tr_val = X_tr_val[..., None]\n",
    "    X_te = X_te[..., None]\n",
    "\n",
    "    # =============================\n",
    "    # TRAIN / VAL SPLIT\n",
    "    # =============================\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_tr_val,\n",
    "        y_tr_val,\n",
    "        test_size=0.15,\n",
    "        stratify=y_tr_val,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # =============================\n",
    "    # CLASS WEIGHTS\n",
    "    # =============================\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.unique(y_tr),\n",
    "        y=y_tr\n",
    "    )\n",
    "    class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "\n",
    "    # =============================\n",
    "    # OVERSAMPLING\n",
    "    # =============================\n",
    "    X_tr, y_tr = oversample_ictal(X_tr, y_tr, factor=3)\n",
    "\n",
    "    # =============================\n",
    "    # MODEL\n",
    "    # =============================\n",
    "    model = build_model((X_tr.shape[1], 1))\n",
    "    model.compile(\n",
    "        optimizer=Adam(1e-4),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_tr, y_tr,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=60,\n",
    "        batch_size=32,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[\n",
    "            EarlyStopping(patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(patience=8, factor=0.5),\n",
    "            ModelCheckpoint(\n",
    "                os.path.join(RESULTS_DIR, f\"model_fold{fold+1}.weights.h5\"),\n",
    "                save_best_only=True,\n",
    "                save_weights_only=True\n",
    "            )\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # =============================\n",
    "    # EVALUATION\n",
    "    # =============================\n",
    "    model.load_weights(\n",
    "        os.path.join(RESULTS_DIR, f\"model_fold{fold+1}.weights.h5\")\n",
    "    )\n",
    "\n",
    "    prob = model.predict(X_te).flatten()\n",
    "    pred = (prob > 0.5).astype(int)\n",
    "\n",
    "    acc = np.mean(pred == y_te)\n",
    "    auc = roc_auc_score(y_te, prob)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "    cm = confusion_matrix(y_te, pred)\n",
    "    confs.append(cm)\n",
    "\n",
    "    print(f\"Fold {fold+1} | ACC={acc:.4f} | AUC={auc:.4f}\")\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Fold {fold+1} Confusion Matrix\")\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, f\"confusion_fold{fold+1}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    with open(summary_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Fold {fold+1}: ACC={acc:.4f}, AUC={auc:.4f}\\n\")\n",
    "\n",
    "# =============================================================\n",
    "#                OVERALL RESULTS\n",
    "# =============================================================\n",
    "total_cm = np.sum(confs, axis=0)\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_auc = np.mean(auc_list)\n",
    "\n",
    "sns.heatmap(total_cm, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
    "plt.title(f\"Overall CM | Mean ACC={mean_acc:.4f}\")\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"confusion_overall.png\"))\n",
    "plt.close()\n",
    "\n",
    "with open(summary_path, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    f.write(f\"Mean ACC = {mean_acc:.4f}\\n\")\n",
    "    f.write(f\"Mean AUC = {mean_auc:.4f}\\n\")\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\" BINARY TRAINING COMPLETED \")\n",
    "print(\"==============================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
