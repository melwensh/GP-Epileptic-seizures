{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37df3167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Fold 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 276ms/step - accuracy: 0.8899 - loss: 0.3347 - val_accuracy: 0.4437 - val_loss: 0.9253 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 275ms/step - accuracy: 0.9426 - loss: 0.1393 - val_accuracy: 0.4187 - val_loss: 1.2147 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 287ms/step - accuracy: 0.9572 - loss: 0.0979 - val_accuracy: 0.5833 - val_loss: 0.9956 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 278ms/step - accuracy: 0.9599 - loss: 0.0904 - val_accuracy: 0.7604 - val_loss: 0.7169 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 288ms/step - accuracy: 0.9654 - loss: 0.0812 - val_accuracy: 0.8583 - val_loss: 0.4169 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 278ms/step - accuracy: 0.9597 - loss: 0.1042 - val_accuracy: 0.9187 - val_loss: 0.2170 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 268ms/step - accuracy: 0.9713 - loss: 0.0612 - val_accuracy: 0.9563 - val_loss: 0.1229 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 262ms/step - accuracy: 0.9761 - loss: 0.0533 - val_accuracy: 0.9854 - val_loss: 0.0515 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 267ms/step - accuracy: 0.9770 - loss: 0.0520 - val_accuracy: 0.9875 - val_loss: 0.0407 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 262ms/step - accuracy: 0.9835 - loss: 0.0365 - val_accuracy: 0.9896 - val_loss: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 263ms/step - accuracy: 0.9886 - loss: 0.0267 - val_accuracy: 0.9896 - val_loss: 0.0346 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 268ms/step - accuracy: 0.9858 - loss: 0.0343 - val_accuracy: 0.9812 - val_loss: 0.0463 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9845 - loss: 0.0340\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 264ms/step - accuracy: 0.9835 - loss: 0.0381 - val_accuracy: 0.9875 - val_loss: 0.0394 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 265ms/step - accuracy: 0.9943 - loss: 0.0150 - val_accuracy: 0.9937 - val_loss: 0.0161 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 264ms/step - accuracy: 0.9978 - loss: 0.0085 - val_accuracy: 0.9875 - val_loss: 0.0255 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 265ms/step - accuracy: 0.9982 - loss: 0.0069 - val_accuracy: 0.9937 - val_loss: 0.0124 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 262ms/step - accuracy: 0.9982 - loss: 0.0058 - val_accuracy: 0.9896 - val_loss: 0.0302 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 264ms/step - accuracy: 0.9963 - loss: 0.0076 - val_accuracy: 0.9979 - val_loss: 0.0122 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 263ms/step - accuracy: 0.9983 - loss: 0.0037 - val_accuracy: 0.9937 - val_loss: 0.0205 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 263ms/step - accuracy: 0.9983 - loss: 0.0041 - val_accuracy: 0.9979 - val_loss: 0.0095 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 261ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9958 - val_loss: 0.0208 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 262ms/step - accuracy: 0.9982 - loss: 0.0064 - val_accuracy: 0.9958 - val_loss: 0.0121 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9898 - loss: 0.0272\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 262ms/step - accuracy: 0.9928 - loss: 0.0174 - val_accuracy: 0.9875 - val_loss: 0.0302 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 262ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9958 - val_loss: 0.0161 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 263ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9917 - val_loss: 0.0182 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9998 - loss: 0.0013\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 270ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9875 - val_loss: 0.0267 - learning_rate: 2.5000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 262ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9958 - val_loss: 0.0114 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 262ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9958 - val_loss: 0.0141 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9998 - loss: 9.5784e-04\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 265ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9937 - val_loss: 0.0147 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 264ms/step - accuracy: 0.9998 - loss: 9.2513e-04 - val_accuracy: 0.9979 - val_loss: 0.0112 - learning_rate: 6.2500e-05\n",
      "\n",
      "ğŸš€ Fold 2/5\n",
      "Epoch 1/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 273ms/step - accuracy: 0.8936 - loss: 0.3383 - val_accuracy: 0.4625 - val_loss: 1.0293 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 268ms/step - accuracy: 0.9528 - loss: 0.1194 - val_accuracy: 0.4125 - val_loss: 1.4262 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 269ms/step - accuracy: 0.9594 - loss: 0.0992 - val_accuracy: 0.5104 - val_loss: 1.6097 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9638 - loss: 0.0933\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 267ms/step - accuracy: 0.9619 - loss: 0.0900 - val_accuracy: 0.7208 - val_loss: 1.0703 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 269ms/step - accuracy: 0.9713 - loss: 0.0645 - val_accuracy: 0.8083 - val_loss: 0.7148 - learning_rate: 5.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 268ms/step - accuracy: 0.9757 - loss: 0.0537 - val_accuracy: 0.9375 - val_loss: 0.1683 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 266ms/step - accuracy: 0.9805 - loss: 0.0447 - val_accuracy: 0.9708 - val_loss: 0.0642 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 265ms/step - accuracy: 0.9803 - loss: 0.0474 - val_accuracy: 0.9812 - val_loss: 0.0426 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 266ms/step - accuracy: 0.9851 - loss: 0.0385 - val_accuracy: 0.9812 - val_loss: 0.0522 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 265ms/step - accuracy: 0.9842 - loss: 0.0485 - val_accuracy: 0.9812 - val_loss: 0.0494 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9894 - loss: 0.0253\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 265ms/step - accuracy: 0.9893 - loss: 0.0260 - val_accuracy: 0.9750 - val_loss: 0.0623 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 265ms/step - accuracy: 0.9892 - loss: 0.0238 - val_accuracy: 0.9792 - val_loss: 0.0418 - learning_rate: 2.5000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 263ms/step - accuracy: 0.9921 - loss: 0.0183 - val_accuracy: 0.9875 - val_loss: 0.0285 - learning_rate: 2.5000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 262ms/step - accuracy: 0.9950 - loss: 0.0149 - val_accuracy: 0.9833 - val_loss: 0.0362 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 264ms/step - accuracy: 0.9965 - loss: 0.0116 - val_accuracy: 0.9896 - val_loss: 0.0269 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 273ms/step - accuracy: 0.9967 - loss: 0.0101 - val_accuracy: 0.9917 - val_loss: 0.0188 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 268ms/step - accuracy: 0.9976 - loss: 0.0077 - val_accuracy: 0.9854 - val_loss: 0.0442 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 264ms/step - accuracy: 0.9939 - loss: 0.0138 - val_accuracy: 0.9917 - val_loss: 0.0298 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9970 - loss: 0.0078\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 274ms/step - accuracy: 0.9958 - loss: 0.0096 - val_accuracy: 0.9917 - val_loss: 0.0270 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 293ms/step - accuracy: 0.9989 - loss: 0.0050 - val_accuracy: 0.9937 - val_loss: 0.0228 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 285ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9833 - val_loss: 0.0453 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.9984 - loss: 0.0043\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 284ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.9937 - val_loss: 0.0215 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 279ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9917 - val_loss: 0.0233 - learning_rate: 6.2500e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 279ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.9937 - val_loss: 0.0224 - learning_rate: 6.2500e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.9991 - loss: 0.0025\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 277ms/step - accuracy: 0.9987 - loss: 0.0027 - val_accuracy: 0.9917 - val_loss: 0.0314 - learning_rate: 6.2500e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 281ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9896 - val_loss: 0.0320 - learning_rate: 3.1250e-05\n",
      "\n",
      "ğŸš€ Fold 3/5\n",
      "Epoch 1/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 291ms/step - accuracy: 0.8950 - loss: 0.3324 - val_accuracy: 0.4771 - val_loss: 0.9517 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 290ms/step - accuracy: 0.9513 - loss: 0.1330 - val_accuracy: 0.4104 - val_loss: 1.3325 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 282ms/step - accuracy: 0.9597 - loss: 0.1040 - val_accuracy: 0.5896 - val_loss: 1.1876 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9674 - loss: 0.0799\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 269ms/step - accuracy: 0.9656 - loss: 0.0801 - val_accuracy: 0.6354 - val_loss: 1.2158 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 269ms/step - accuracy: 0.9691 - loss: 0.0739 - val_accuracy: 0.7854 - val_loss: 0.7666 - learning_rate: 5.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 268ms/step - accuracy: 0.9761 - loss: 0.0592 - val_accuracy: 0.8604 - val_loss: 0.5313 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 268ms/step - accuracy: 0.9732 - loss: 0.0588 - val_accuracy: 0.9583 - val_loss: 0.1060 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 267ms/step - accuracy: 0.9774 - loss: 0.0490 - val_accuracy: 0.9625 - val_loss: 0.1004 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 268ms/step - accuracy: 0.9801 - loss: 0.0435 - val_accuracy: 0.9771 - val_loss: 0.0597 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 269ms/step - accuracy: 0.9847 - loss: 0.0332 - val_accuracy: 0.9771 - val_loss: 0.0656 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 268ms/step - accuracy: 0.9849 - loss: 0.0367 - val_accuracy: 0.9667 - val_loss: 0.0731 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9845 - loss: 0.0377\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 268ms/step - accuracy: 0.9857 - loss: 0.0330 - val_accuracy: 0.9750 - val_loss: 0.0739 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 268ms/step - accuracy: 0.9923 - loss: 0.0224 - val_accuracy: 0.9854 - val_loss: 0.0413 - learning_rate: 2.5000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 269ms/step - accuracy: 0.9932 - loss: 0.0195 - val_accuracy: 0.9896 - val_loss: 0.0366 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 273ms/step - accuracy: 0.9947 - loss: 0.0160 - val_accuracy: 0.9833 - val_loss: 0.0425 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 267ms/step - accuracy: 0.9921 - loss: 0.0183 - val_accuracy: 0.9875 - val_loss: 0.0490 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9945 - loss: 0.0143\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 268ms/step - accuracy: 0.9961 - loss: 0.0113 - val_accuracy: 0.9833 - val_loss: 0.0404 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 266ms/step - accuracy: 0.9969 - loss: 0.0089 - val_accuracy: 0.9896 - val_loss: 0.0417 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 266ms/step - accuracy: 0.9961 - loss: 0.0103 - val_accuracy: 0.9854 - val_loss: 0.0356 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 266ms/step - accuracy: 0.9971 - loss: 0.0089 - val_accuracy: 0.9854 - val_loss: 0.0363 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 269ms/step - accuracy: 0.9976 - loss: 0.0080 - val_accuracy: 0.9875 - val_loss: 0.0335 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 268ms/step - accuracy: 0.9974 - loss: 0.0079 - val_accuracy: 0.9896 - val_loss: 0.0303 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 267ms/step - accuracy: 0.9989 - loss: 0.0052 - val_accuracy: 0.9896 - val_loss: 0.0299 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 266ms/step - accuracy: 0.9983 - loss: 0.0047 - val_accuracy: 0.9875 - val_loss: 0.0359 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 267ms/step - accuracy: 0.9993 - loss: 0.0038 - val_accuracy: 0.9896 - val_loss: 0.0314 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9975 - loss: 0.0067\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 266ms/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.9896 - val_loss: 0.0314 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 265ms/step - accuracy: 0.9994 - loss: 0.0036 - val_accuracy: 0.9875 - val_loss: 0.0322 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 266ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.9896 - val_loss: 0.0333 - learning_rate: 6.2500e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 266ms/step - accuracy: 0.9978 - loss: 0.0064 - val_accuracy: 0.9937 - val_loss: 0.0273 - learning_rate: 6.2500e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 267ms/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 0.9937 - val_loss: 0.0235 - learning_rate: 6.2500e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 264ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.9896 - val_loss: 0.0275 - learning_rate: 6.2500e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 265ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9896 - val_loss: 0.0275 - learning_rate: 6.2500e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9997 - loss: 0.0021\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 266ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.9937 - val_loss: 0.0259 - learning_rate: 6.2500e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 273ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9917 - val_loss: 0.0266 - learning_rate: 3.1250e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 263ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9937 - val_loss: 0.0263 - learning_rate: 3.1250e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9999 - loss: 0.0020\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 267ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9896 - val_loss: 0.0290 - learning_rate: 3.1250e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 308ms/step - accuracy: 0.9998 - loss: 0.0018 - val_accuracy: 0.9896 - val_loss: 0.0294 - learning_rate: 1.5625e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 317ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9896 - val_loss: 0.0295 - learning_rate: 1.5625e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 291ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9896 - val_loss: 0.0315 - learning_rate: 1.5625e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 318ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9896 - val_loss: 0.0292 - learning_rate: 7.8125e-06\n",
      "\n",
      "ğŸš€ Fold 4/5\n",
      "Epoch 1/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 327ms/step - accuracy: 0.8936 - loss: 0.3232 - val_accuracy: 0.4042 - val_loss: 0.9578 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 362ms/step - accuracy: 0.9528 - loss: 0.1155 - val_accuracy: 0.4042 - val_loss: 1.1444 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 439ms/step - accuracy: 0.9555 - loss: 0.1069 - val_accuracy: 0.5750 - val_loss: 0.9516 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 432ms/step - accuracy: 0.9651 - loss: 0.0768 - val_accuracy: 0.6771 - val_loss: 0.9227 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 449ms/step - accuracy: 0.9671 - loss: 0.0713 - val_accuracy: 0.8500 - val_loss: 0.3530 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 434ms/step - accuracy: 0.9689 - loss: 0.0688 - val_accuracy: 0.9229 - val_loss: 0.2057 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 444ms/step - accuracy: 0.9728 - loss: 0.0557 - val_accuracy: 0.9646 - val_loss: 0.1026 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 440ms/step - accuracy: 0.9744 - loss: 0.0551 - val_accuracy: 0.9771 - val_loss: 0.0800 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 457ms/step - accuracy: 0.9835 - loss: 0.0382 - val_accuracy: 0.9667 - val_loss: 0.0930 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 422ms/step - accuracy: 0.9829 - loss: 0.0404 - val_accuracy: 0.9833 - val_loss: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 420ms/step - accuracy: 0.9855 - loss: 0.0364 - val_accuracy: 0.9812 - val_loss: 0.0723 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 420ms/step - accuracy: 0.9836 - loss: 0.0443 - val_accuracy: 0.9792 - val_loss: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.9869 - loss: 0.0298\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 417ms/step - accuracy: 0.9888 - loss: 0.0251 - val_accuracy: 0.9708 - val_loss: 0.0743 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 419ms/step - accuracy: 0.9934 - loss: 0.0154 - val_accuracy: 0.9875 - val_loss: 0.0236 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 429ms/step - accuracy: 0.9980 - loss: 0.0095 - val_accuracy: 0.9896 - val_loss: 0.0238 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 432ms/step - accuracy: 0.9947 - loss: 0.0116 - val_accuracy: 0.9896 - val_loss: 0.0233 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 409ms/step - accuracy: 0.9961 - loss: 0.0093 - val_accuracy: 0.9833 - val_loss: 0.0452 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 398ms/step - accuracy: 0.9991 - loss: 0.0047 - val_accuracy: 0.9937 - val_loss: 0.0248 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.9983 - loss: 0.0049\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 399ms/step - accuracy: 0.9980 - loss: 0.0051 - val_accuracy: 0.9854 - val_loss: 0.0401 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 400ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9917 - val_loss: 0.0239 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 398ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9896 - val_loss: 0.0298 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 397ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9917 - val_loss: 0.0268 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 396ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9896 - val_loss: 0.0292 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 398ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9896 - val_loss: 0.0298 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.9991 - loss: 0.0018\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 396ms/step - accuracy: 0.9994 - loss: 0.0014 - val_accuracy: 0.9896 - val_loss: 0.0240 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 397ms/step - accuracy: 1.0000 - loss: 8.3131e-04 - val_accuracy: 0.9896 - val_loss: 0.0267 - learning_rate: 6.2500e-05\n",
      "\n",
      "ğŸš€ Fold 5/5\n",
      "Epoch 1/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 415ms/step - accuracy: 0.8998 - loss: 0.2974 - val_accuracy: 0.5396 - val_loss: 1.0782 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 400ms/step - accuracy: 0.9588 - loss: 0.1054 - val_accuracy: 0.5521 - val_loss: 1.1142 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 397ms/step - accuracy: 0.9640 - loss: 0.0878 - val_accuracy: 0.5813 - val_loss: 1.1817 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 397ms/step - accuracy: 0.9763 - loss: 0.0544 - val_accuracy: 0.7417 - val_loss: 0.7784 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 398ms/step - accuracy: 0.9754 - loss: 0.0592 - val_accuracy: 0.8854 - val_loss: 0.3306 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 399ms/step - accuracy: 0.9787 - loss: 0.0454 - val_accuracy: 0.9396 - val_loss: 0.1882 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 399ms/step - accuracy: 0.9838 - loss: 0.0386 - val_accuracy: 0.9750 - val_loss: 0.0728 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 395ms/step - accuracy: 0.9833 - loss: 0.0406 - val_accuracy: 0.9729 - val_loss: 0.0631 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 396ms/step - accuracy: 0.9844 - loss: 0.0350 - val_accuracy: 0.9729 - val_loss: 0.0528 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 395ms/step - accuracy: 0.9906 - loss: 0.0218 - val_accuracy: 0.9854 - val_loss: 0.0365 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 402ms/step - accuracy: 0.9939 - loss: 0.0137 - val_accuracy: 0.9896 - val_loss: 0.0397 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 408ms/step - accuracy: 0.9956 - loss: 0.0104 - val_accuracy: 0.9875 - val_loss: 0.0509 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 400ms/step - accuracy: 0.9926 - loss: 0.0228 - val_accuracy: 0.9917 - val_loss: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 399ms/step - accuracy: 0.9936 - loss: 0.0146 - val_accuracy: 0.9917 - val_loss: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 401ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 0.9896 - val_loss: 0.0532 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.9973 - loss: 0.0075\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 400ms/step - accuracy: 0.9976 - loss: 0.0067 - val_accuracy: 0.9896 - val_loss: 0.0338 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 400ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9854 - val_loss: 0.0461 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 396ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9875 - val_loss: 0.0433 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.9999 - loss: 7.8301e-04\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 398ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9833 - val_loss: 0.0401 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 397ms/step - accuracy: 1.0000 - loss: 6.3491e-04 - val_accuracy: 0.9875 - val_loss: 0.0419 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 397ms/step - accuracy: 1.0000 - loss: 9.0566e-04 - val_accuracy: 0.9896 - val_loss: 0.0575 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.9992 - loss: 0.0018\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 400ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.9896 - val_loss: 0.0388 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 399ms/step - accuracy: 1.0000 - loss: 7.4864e-04 - val_accuracy: 0.9917 - val_loss: 0.0425 - learning_rate: 1.2500e-04\n",
      "\n",
      "â­ FINAL ACCURACY: 0.9705 Â± 0.0193\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Conv1D, MaxPooling1D, LSTM, Dense, Dropout, \n",
    "                                     BatchNormalization, Bidirectional, Input, \n",
    "                                     Flatten, Concatenate, Layer, GlobalAveragePooling1D)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# -------------------- Configuration --------------------\n",
    "PREPROCESSING_DIR = r\"Preprocessing_Updated_Kfold\"\n",
    "N_FOLDS = 5\n",
    "RESULTS_DIR = \"results_3class_optimized\"\n",
    "NUM_CLASSES = 3\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------- Attention Layer --------------------\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                 initializer=\"zeros\")\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
    "        a = tf.keras.backend.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        return tf.keras.backend.sum(output, axis=1)\n",
    "\n",
    "# -------------------- Advanced Architecture --------------------\n",
    "def build_advanced_model(input_length, num_classes=3):\n",
    "    input_layer = Input(shape=(input_length, 1))\n",
    "\n",
    "    # Multi-Scale Feature Extraction (Parallel Convolutions)\n",
    "    conv_a = Conv1D(32, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "    conv_b = Conv1D(32, kernel_size=7, padding='same', activation='relu')(input_layer)\n",
    "    conv_c = Conv1D(32, kernel_size=11, padding='same', activation='relu')(input_layer)\n",
    "    \n",
    "    merged = Concatenate()([conv_a, conv_b, conv_c])\n",
    "    x = BatchNormalization()(merged)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Deep Feature Extraction\n",
    "    x = Conv1D(128, kernel_size=5, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    # Sequence Processing\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    \n",
    "    # Attention Focus\n",
    "    x = AttentionLayer()(x)\n",
    "\n",
    "    # Fully Connected\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# -------------------- Improved Augmentation --------------------\n",
    "def augment_signal(signal):\n",
    "    # Gaussian Noise\n",
    "    noise = np.random.normal(0, 0.003, signal.shape)\n",
    "    signal_noisy = signal + noise\n",
    "    # Random Shift\n",
    "    shift = np.random.randint(-10, 10)\n",
    "    signal_shifted = np.roll(signal_noisy, shift)\n",
    "    # Magnitude Scaling\n",
    "    scale = np.random.uniform(0.9, 1.1)\n",
    "    return signal_shifted * scale\n",
    "\n",
    "def augment_batch(X, y):\n",
    "    X_aug, y_aug = [], []\n",
    "    for i in range(len(X)):\n",
    "        X_aug.append(X[i])\n",
    "        y_aug.append(y[i])\n",
    "        # Add 2 augmented versions per sample for better generalization\n",
    "        X_aug.append(augment_signal(X[i]))\n",
    "        y_aug.append(y[i])\n",
    "    return np.array(X_aug), np.array(y_aug)\n",
    "\n",
    "# -------------------- Training Loop --------------------\n",
    "acc_per_fold = []\n",
    "conf_matrices = []\n",
    "\n",
    "for fold_no in range(N_FOLDS):\n",
    "    print(f\"\\nğŸš€ Fold {fold_no + 1}/{N_FOLDS}\")\n",
    "\n",
    "    # Load Data\n",
    "    X_train_full = np.load(os.path.join(PREPROCESSING_DIR, f\"fold_{fold_no}_X_train.npy\"), allow_pickle=True)\n",
    "    y_train_full = np.load(os.path.join(PREPROCESSING_DIR, f\"fold_{fold_no}_y_train.npy\"), allow_pickle=True)\n",
    "    X_test = np.load(os.path.join(PREPROCESSING_DIR, f\"fold_{fold_no}_X_test.npy\"), allow_pickle=True)\n",
    "    y_test = np.load(os.path.join(PREPROCESSING_DIR, f\"fold_{fold_no}_y_test.npy\"), allow_pickle=True)\n",
    "    \n",
    "    # Cleaning data types\n",
    "    X_train_full = np.vstack(X_train_full).astype(np.float32) if X_train_full.dtype == object else X_train_full.astype(np.float32)\n",
    "    X_test = np.vstack(X_test).astype(np.float32) if X_test.dtype == object else X_test.astype(np.float32)\n",
    "    \n",
    "    # Split for validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.15, stratify=y_train_full, random_state=42)\n",
    "\n",
    "    # Augment Training Set\n",
    "    X_train, y_train = augment_batch(X_train, y_train)\n",
    "\n",
    "    # Reshape\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_val = X_val[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "\n",
    "    # Labels\n",
    "    y_train_oh = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "    y_val_oh = tf.keras.utils.to_categorical(y_val, NUM_CLASSES)\n",
    "    y_test_oh = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "    # Class Weights\n",
    "    cw = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = dict(enumerate(cw))\n",
    "\n",
    "    # Model and Callbacks\n",
    "    model = build_advanced_model(X_train.shape[1], NUM_CLASSES)\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train_oh,\n",
    "        epochs=60,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_val, y_val_oh),\n",
    "        class_weight=class_weights,\n",
    "        callbacks=[reduce_lr, early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluation\n",
    "    _, test_acc = model.evaluate(X_test, y_test_oh, verbose=0)\n",
    "    acc_per_fold.append(test_acc)\n",
    "    \n",
    "    # Confusion Matrix Logic\n",
    "    y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
    "    conf_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Final Reporting\n",
    "print(f\"\\nâ­ FINAL ACCURACY: {np.mean(acc_per_fold):.4f} Â± {np.std(acc_per_fold):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
